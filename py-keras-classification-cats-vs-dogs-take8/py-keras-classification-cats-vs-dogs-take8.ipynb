{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Deep Learning Model for Cats and Dogs Using Keras Take 8\n",
    "### David Lowe\n",
    "### February 4, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The \"Cats and Dogs\" dataset is a binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: Web services are often protected with a challenge that's supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). ASIRRA (Animal Species Image Recognition for Restricting Access) is a HIP that works by asking users to identify photographs of cats and dogs. This task is difficult for computers, but studies have shown that people can accomplish it quickly and accurately.\n",
    "\n",
    "The current literature suggests that machine classifiers can score above 80% accuracy on this task. Therefore, ASIRRA is no longer considered safe from attack. Kaggle created a contest to benchmark the latest computer vision and deep learning approaches to this problem. The training archive contains 25,000 images of dogs and cats. We will need to train our algorithm on these files and predict the correct labels for the test dataset.\n",
    "\n",
    "In iteration Take1, we constructed a simple VGG convolutional model with 1 VGG block to classify the images. This model serves as the baseline for the future iterations of modeling.\n",
    "\n",
    "In iteration Take2, we constructed a simple VGG convolutional model with 2 VGG blocks to classify the images. The additional modeling enabled us to improve our baseline model.\n",
    "\n",
    "In iteration Take3, we constructed a simple VGG convolutional model with 3 VGG blocks to classify the images. The additional modeling enabled us to improve our baseline model further.\n",
    "\n",
    "In iteration Take4, we applied dropout to our VGG-3 model. The addition of the dropout layers improved our model.\n",
    "\n",
    "In iteration Take5, we applied image data augmentation to our VGG-3 model. The addition of the image data augmentation improved our model.\n",
    "\n",
    "In iteration Take6, we applied both dropout layers and image data augmentation to our VGG-3 model. The addition of both techniques improved our model but not much more from the previous VGG-3 models.\n",
    "\n",
    "In iteration Take7, we applied the transfer learning technique by incorporating the VGG-16 model into our classifier. The incorporation of the VGG-16 model brought our model's performance closer to the Kaggle results.\n",
    "\n",
    "In this iteration, we will take the TensorFlow/Keras model generated and saved from Take7 to make predictions on brand new images. We will upload the prediction to Kaggle and receive an accuracy score for our predictions.\n",
    "\n",
    "ANALYSIS: In iteration Take1, the performance of the Take1 model achieved an accuracy score of 95.55% after training for 20 epochs. The same model, however, processed the test dataset with an accuracy of only 72.99% after 20 epochs. Reviewing the plot, we can see that the model was starting to overfit the training dataset after only ten epochs. We will need to explore other modeling approaches to reduce the over-fitting.\n",
    "\n",
    "In iteration Take2, the performance of the Take2 model achieved an accuracy score of 97.94% after training for 20 epochs. The same model, however, processed the test dataset with an accuracy of only 75.67% after 20 epochs. Reviewing the plot, we can see that the model was starting to overfit the training dataset after only seven epochs. We will need to explore other modeling approaches to reduce the over-fitting.\n",
    "\n",
    "In iteration Take3, the performance of the Take3 model achieved an accuracy score of 97.14% after training for 20 epochs. The same model, however, processed the test dataset with an accuracy of only 80.19% after 20 epochs. Reviewing the plot, we can see that the model was starting to overfit the training dataset after only six epochs. We will need to explore other modeling approaches to reduce the over-fitting.\n",
    "\n",
    "In iteration Take4, the performance of the Take4 model achieved an accuracy score of 86.92% after training for 50 epochs. The same model, however, processed the test dataset with an accuracy of 81.04% after 50 epochs. By reviewing the plot, this iteration indicated to us that having dropout layers can be a good tactic to improve the model's predictive performance.\n",
    "\n",
    "In iteration Take5, the performance of the Take5 model achieved an accuracy score of 87.52% after training for 50 epochs. The same model, however, processed the test dataset with an accuracy of 85.12% after 50 epochs. By reviewing the plot, this iteration indicated to us that having image data augmentation can be a good tactic to improve the model's predictive performance.\n",
    "\n",
    "In iteration Take6, the performance of the Take6 model achieved an accuracy score of 88.60% after training for 200 epochs. The same model, however, processed the test dataset with an accuracy of 87.25% after 200 epochs. By reviewing the plot, this iteration indicated to us that having both dropout layers and image data augmentation can create a low-variance model that does not overfit too early in the modeling process.\n",
    "\n",
    "In iteration Take7, the performance of the Take7 model achieved an accuracy score of 99.99% after training for 10 epochs. The same model processed the test dataset with an accuracy of 97.77% after 10 epochs. This iteration indicated to us that a workable model will requie more layers and depth than having simply three VGG blocks.\n",
    "\n",
    "In this iteration, the VGG-16/Take7 model generated a submission file that can be submitted to Kaggle for further evaluation.\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using Keras and TensorFlow achieved a comparable result with the Kaggle competition. We can use this model to predict other previously unseen/processed pet images.\n",
    "\n",
    "Dataset Used: Cats and Dogs Dataset\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: https://www.microsoft.com/en-us/download/details.aspx?id=54765\n",
    "\n",
    "One potential source of performance benchmarks: https://www.kaggle.com/c/dogs-vs-cats/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose and debug flags to print detailed messages for debugging (setting True will activate!)\n",
    "verbose = False\n",
    "debug = False\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Image has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing Tasks to perform at this time\n",
    "# Extract/Unzip the Kaggle testing images Zip file (test1.zip) into a directory (e.g. test1/)\n",
    "# Copy the final model file (final_model_cats_and_dogs.h5) to the script subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(224, 224))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 224, 224, 3)\n",
    "\t# center pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img - [123.68, 116.779, 103.939]\n",
    "\treturn img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Image completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Load Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Load the Keras model for making predictions\n",
    "production_model = load_model('final_model_cats_and_dogs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Load Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Make Precitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Make Predictions has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image processed so far: 500\n",
      "Number of image processed so far: 1000\n",
      "Number of image processed so far: 1500\n",
      "Number of image processed so far: 2000\n",
      "Number of image processed so far: 2500\n",
      "Number of image processed so far: 3000\n",
      "Number of image processed so far: 3500\n",
      "Number of image processed so far: 4000\n",
      "Number of image processed so far: 4500\n",
      "Number of image processed so far: 5000\n",
      "Number of image processed so far: 5500\n",
      "Number of image processed so far: 6000\n",
      "Number of image processed so far: 6500\n",
      "Number of image processed so far: 7000\n",
      "Number of image processed so far: 7500\n",
      "Number of image processed so far: 8000\n",
      "Number of image processed so far: 8500\n",
      "Number of image processed so far: 9000\n",
      "Number of image processed so far: 9500\n",
      "Number of image processed so far: 10000\n",
      "Number of image processed so far: 10500\n",
      "Number of image processed so far: 11000\n",
      "Number of image processed so far: 11500\n",
      "Number of image processed so far: 12000\n",
      "Number of image processed so far: 12500\n",
      "Total number of image processed: 12500\n"
     ]
    }
   ],
   "source": [
    "# Set up the dataframe with the prediction results\n",
    "submission_df = pd.DataFrame(columns=['id','label'])\n",
    "i = 0\n",
    "\n",
    "# load an image and predict the class\n",
    "src_directory = 'test1/'\n",
    "for file_name in os.listdir(src_directory):\n",
    "    file_id = int(os.path.splitext(file_name)[0])\n",
    "    if (verbose): print('Processing image', file_name, 'as file ID:', file_id)\n",
    "    # load the image\n",
    "    img_file = src_directory + file_name\n",
    "    img = load_image(img_file)\n",
    "    if (verbose): print('Finished pre-processing of image', img_file)\n",
    "    # predict the class\n",
    "    result = production_model.predict(img)\n",
    "    pet_label = int(result[0])\n",
    "    submission_df.loc[i] = [file_id, pet_label]\n",
    "    i = i + 1\n",
    "    if ((i % 500)==0): print('Number of image processed so far:', i)\n",
    "print('Total number of image processed:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pb01NDTS44-"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Make Predictions completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Produce Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Produce Output has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id label\n",
      "0       1     1\n",
      "1      10     0\n",
      "2     100     0\n",
      "3    1000     1\n",
      "4   10000     1\n",
      "5   10001     0\n",
      "6   10002     0\n",
      "7   10003     1\n",
      "8   10004     1\n",
      "9   10005     0\n",
      "10  10006     0\n",
      "11  10007     0\n",
      "12  10008     0\n",
      "13  10009     0\n",
      "14   1001     0\n",
      "15  10010     1\n",
      "16  10011     1\n",
      "17  10012     0\n",
      "18  10013     0\n",
      "19  10014     0\n"
     ]
    }
   ],
   "source": [
    "# Perform a quick check of the dataframe content\n",
    "print(submission_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not required for this iteration of the project\n",
    "out_file = submission_df.to_csv(header=True, index=False)\n",
    "filename = 'submission_' + datetime.now().strftime('%Y%m%d-%H%M') + '.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Produce Output completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 1:09:22.235330\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
