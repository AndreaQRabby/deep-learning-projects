{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Deep Learning Model for CIFAR-10 Object Recognition Using Keras Take 8\n",
    "### David Lowe\n",
    "### January 16, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The CIFAR-10 dataset is a multi-class classification situation where we are trying to predict one of several (more than two) possible outcomes.\n",
    "\n",
    "INTRODUCTION: The CIFAR-10 is a labeled subset of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10,000 images. The test batch contains exactly 1,000 randomly selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5,000 images from each class.\n",
    "\n",
    "In iteration Take1, we constructed a simple VGG convolutional model with 1 VGG block to classify the images. This model serves as the baseline for the future iterations of modeling.\n",
    "\n",
    "In iteration Take2, we constructed a few more VGG convolutional models with 2 and 3 VGG blocks to classify the images. The additional models enabled us to choose a final baseline model before applying other performance-enhancing techniques.\n",
    "\n",
    "In iteration Take3, we tuned the VGG-3 model with various hyperparameters and selected the best model.\n",
    "\n",
    "In iteration Take4, we added some dropout layers as a regularization technique to reduce over-fitting.\n",
    "\n",
    "In iteration Take5, we applied data augmentation to the dataset as a regularization technique to reduce over-fitting.\n",
    "\n",
    "In iteration Take6, we applied both dropout layers and data augmentation to the dataset for reducing over-fitting.\n",
    "\n",
    "In iteration Take7, we applied dropout layers, data augmentation, and batch normalization to the dataset for reducing over-fitting.\n",
    "\n",
    "In this iteration, we will tune the Take7 model further by experimenting with different optimizers and different learning rates.\n",
    "\n",
    "ANALYSIS: In iteration Take1, the performance of the Take1 model with the default parameters achieved an accuracy score of 66.39% on the validation dataset after training for 50 epochs. After tuning the hyperparameters, the Take1 model with the best hyperparameters processed the training dataset with an accuracy of 100.00%. The same model, however, processed the test dataset with an accuracy of only 67.01%. We will need to explore other modeling approaches to make a better model that reduces over-fitting.\n",
    "\n",
    "In iteration Take2, the performance of the VGG-1 model with the default parameters achieved an accuracy score of 66.69% on the validation dataset after training for 50 epochs. The VGG-2 model achieved an accuracy score of 71.35% on the validation dataset after training for 50 epochs. The VGG-3 model achieved an accuracy score of 73.81% on the validation dataset after training for 50 epochs. The additional VGG blocks helped the model, but we still need to explore other modeling approaches to make a better model that reduces over-fitting.\n",
    "\n",
    "In iteration Take3, the performance of the VGG-3 Take3 model with the default parameters achieved a maximum accuracy score of 73.43% on the validation dataset after training for 50 epochs. After tuning the hyperparameters, the Take1 model with the best hyperparameters processed the training dataset with an accuracy of 98.09%. The same model, however, processed the test dataset with an accuracy of only 73.44%. Even with VGG-3 and hyperparameter tuning, we still have an over-fitting problem with the model.\n",
    "\n",
    "In iteration Take4, the performance of the Take4 model with the default parameters achieved a maximum accuracy score of 76.96% on the validation dataset after training for 50 epochs. We can see from the graph that the accuracy and loss curves for the training and validation sets were moving in the same direction and converged well. After increasing the number of epochs, the Take4 model processed the training dataset with an accuracy of 82.22% after 100 epochs. The same model processed the test dataset with an accuracy of 82.35%. This iteration indicated to us that having dropout layers can be a good tactic to improve the model's predictive performance.\n",
    "\n",
    "In iteration Take5, the performance of the Take5 model with the default parameters achieved a maximum accuracy score of 81.41% on the validation dataset after training for 50 epochs. We can see from the graph that the accuracy and loss curves for the training and validation sets were moving in the same direction and converged well. After increasing the number of epochs, the Take5 model processed the training dataset with an accuracy of 91.60% after 100 epochs. The same model processed the test dataset with an accuracy of 84.43%. This iteration indicated to us that applying data augmentation can be a good tactic to improve the model's predictive performance.\n",
    "\n",
    "In iteration Take6, the performance of the Take6 model with the default parameters achieved a maximum accuracy score of 84.12% on the validation dataset after training for 100 epochs. We can see from the graph that the accuracy and loss curves for the training and validation sets were moving in the same direction and converged well. After increasing the number of epochs, the Take6 model processed the training dataset with an accuracy of 87.21% after 200 epochs. The same model processed the test dataset with an accuracy of 85.79%. This iteration indicated to us that applying dropout layers and data augmentation together can be a good tactic to improve the model's predictive performance.\n",
    "\n",
    "In iteration Take7, the performance of the Take7 model with the default parameters achieved a maximum accuracy score of 87.15% on the validation dataset after training for 200 epochs. We can see from the graph that the accuracy and loss curves for the training and validation sets were moving in the same direction and converged well. After increasing the number of epochs, the Take7 model processed the training dataset with an accuracy of 90.15% after 400 epochs. The same model processed the test dataset with an accuracy of 89.02%. This iteration indicated to us that applying dropout layers, data augmentation, and batch normalization together can be a good tactic to improve the model's predictive performance.\n",
    "\n",
    "In this iteration, the performance of the Take8 model with the default parameters achieved a maximum accuracy score of 88.35% on the validation dataset after training for 400 epochs. After trying out different optimizers and settings, the best Take8 model processed the training dataset with an accuracy of 92.92%. The same model processed the test dataset with an accuracy of 90.36%. This iteration indicated to us that using RMSprop optimizer can be a good option to improve the model's predictive performance for this dataset.\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using Keras and TensorFlow achieved a satisfactory result and should be considered for future modeling activities.\n",
    "\n",
    "Dataset Used: The CIFAR-10 Dataset\n",
    "\n",
    "Dataset ML Model: Multi-class classification with numerical attributes\n",
    "\n",
    "Dataset Reference: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "One potential source of performance benchmarks: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about six major tasks:\n",
    "\n",
    "0. Prepare Environment\n",
    "1. Load Data\n",
    "2. Define Model\n",
    "3. Fit and Evaluate Model\n",
    "4. Optimize Model\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the warning message filter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seedNum)\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose flag to print detailed messages for debugging (setting to True will activate)\n",
    "# verbose = True\n",
    "# tf.debugging.set_log_device_placement(verbose)\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "n_jobs = -1\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "n_folds = 5\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_loss = 'categorical_crossentropy'\n",
    "default_metrics = ['accuracy']\n",
    "default_optimizer = tf.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "default_kernel_init = tf.initializers.he_uniform(seed=seedNum)\n",
    "default_epoch = 400\n",
    "default_batch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Multi-Class Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the random number generators\n",
    "def reset_random(seedNum):\n",
    "    random.seed(seedNum)\n",
    "    np.random.seed(seedNum)\n",
    "    tf.random.set_seed(seedNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test Shape: X=(10000, 32, 32, 3), y=(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, y_train),(X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Summarize loaded datasets\n",
    "print('Train Shape: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
    "print('Test Shape: X=%s, y=%s' % (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not required for this iteration of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c) Feature Scaling and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data as [samples][width][height][channels]\n",
    "# X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "# X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# Apply feature scaling and transformation\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d) Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: X=(50000, 32, 32, 3), y=(50000, 10)\n",
      "Test Shape: X=(10000, 32, 32, 3), y=(10000, 10)\n",
      "Number of pixels: 1024\n",
      "Number of classes: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "train_transformed = encoder.transform(y_train)\n",
    "test_transformed = encoder.transform(y_test)\n",
    "y_train = tf.keras.utils.to_categorical(train_transformed)\n",
    "y_test = tf.keras.utils.to_categorical(test_transformed)\n",
    "\n",
    "print('Train Shape: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
    "print('Test Shape: X=%s, y=%s' % (X_test.shape, y_test.shape))\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "print('Number of pixels:', num_pixels)\n",
    "num_classes = y_train.shape[1]\n",
    "print('Number of classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model for baseline measurement\n",
    "def create_default_model():\n",
    "    default_model = Sequential()\n",
    "    default_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer=default_kernel_init, padding='same', input_shape=(32, 32, 3)))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer=default_kernel_init, padding='same'))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(MaxPooling2D((2, 2)))\n",
    "    default_model.add(Dropout(0.2))\n",
    "    default_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=default_kernel_init, padding='same'))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=default_kernel_init, padding='same'))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(MaxPooling2D((2, 2)))\n",
    "    default_model.add(Dropout(0.3))\n",
    "    default_model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer=default_kernel_init, padding='same'))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer=default_kernel_init, padding='same'))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(MaxPooling2D((2, 2)))\n",
    "    default_model.add(Dropout(0.4))\n",
    "    default_model.add(Flatten())\n",
    "    default_model.add(Dense(128, activation='relu', kernel_initializer=default_kernel_init))\n",
    "    default_model.add(BatchNormalization())\n",
    "    default_model.add(Dropout(0.5))\n",
    "    default_model.add(Dense(num_classes, activation='softmax', kernel_initializer=default_kernel_init))\n",
    "    default_model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 2.1969 - accuracy: 0.2870 - val_loss: 1.5371 - val_accuracy: 0.4440\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.6586 - accuracy: 0.3974 - val_loss: 1.4362 - val_accuracy: 0.4879\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.5163 - accuracy: 0.4440 - val_loss: 1.4448 - val_accuracy: 0.4769\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.4317 - accuracy: 0.4787 - val_loss: 1.5912 - val_accuracy: 0.4458\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.3540 - accuracy: 0.5063 - val_loss: 1.3318 - val_accuracy: 0.5176\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.3001 - accuracy: 0.5288 - val_loss: 1.2999 - val_accuracy: 0.5278\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.2500 - accuracy: 0.5485 - val_loss: 1.4960 - val_accuracy: 0.4782\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 1.2091 - accuracy: 0.5638 - val_loss: 1.1815 - val_accuracy: 0.5730\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.1761 - accuracy: 0.5774 - val_loss: 1.1728 - val_accuracy: 0.5775\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.1356 - accuracy: 0.5943 - val_loss: 1.1571 - val_accuracy: 0.5867\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.1123 - accuracy: 0.6045 - val_loss: 1.0938 - val_accuracy: 0.6056\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0834 - accuracy: 0.6143 - val_loss: 1.0905 - val_accuracy: 0.6024\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0626 - accuracy: 0.6216 - val_loss: 1.1078 - val_accuracy: 0.6050\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0407 - accuracy: 0.6303 - val_loss: 1.0481 - val_accuracy: 0.6269\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0204 - accuracy: 0.6385 - val_loss: 1.0230 - val_accuracy: 0.6343\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.0024 - accuracy: 0.6427 - val_loss: 0.9820 - val_accuracy: 0.6517\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9841 - accuracy: 0.6506 - val_loss: 0.9634 - val_accuracy: 0.6565\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9668 - accuracy: 0.6599 - val_loss: 0.9930 - val_accuracy: 0.6441\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9506 - accuracy: 0.6643 - val_loss: 0.8794 - val_accuracy: 0.6862\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9394 - accuracy: 0.6680 - val_loss: 0.8650 - val_accuracy: 0.6886\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9238 - accuracy: 0.6738 - val_loss: 0.9082 - val_accuracy: 0.6763\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9168 - accuracy: 0.6796 - val_loss: 0.8860 - val_accuracy: 0.6866\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9026 - accuracy: 0.6826 - val_loss: 0.8995 - val_accuracy: 0.6820\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8908 - accuracy: 0.6884 - val_loss: 0.8157 - val_accuracy: 0.7140\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.8796 - accuracy: 0.6920 - val_loss: 0.8594 - val_accuracy: 0.6969\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8673 - accuracy: 0.6938 - val_loss: 0.9105 - val_accuracy: 0.6773\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8641 - accuracy: 0.7001 - val_loss: 0.8295 - val_accuracy: 0.7055\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8493 - accuracy: 0.7015 - val_loss: 0.9474 - val_accuracy: 0.6691\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8443 - accuracy: 0.7053 - val_loss: 0.7985 - val_accuracy: 0.7189\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8350 - accuracy: 0.7071 - val_loss: 0.8472 - val_accuracy: 0.6977\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8233 - accuracy: 0.7115 - val_loss: 0.8216 - val_accuracy: 0.7111\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8223 - accuracy: 0.7103 - val_loss: 0.7226 - val_accuracy: 0.7516\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8063 - accuracy: 0.7170 - val_loss: 0.7775 - val_accuracy: 0.7280\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8118 - accuracy: 0.7163 - val_loss: 0.8472 - val_accuracy: 0.7030\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7906 - accuracy: 0.7233 - val_loss: 0.8024 - val_accuracy: 0.7203\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7953 - accuracy: 0.7194 - val_loss: 0.8752 - val_accuracy: 0.7017\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7785 - accuracy: 0.7261 - val_loss: 0.8741 - val_accuracy: 0.6963\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7754 - accuracy: 0.7294 - val_loss: 0.7823 - val_accuracy: 0.7267\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7662 - accuracy: 0.7318 - val_loss: 0.8498 - val_accuracy: 0.7046\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7604 - accuracy: 0.7340 - val_loss: 0.7658 - val_accuracy: 0.7317\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7610 - accuracy: 0.7330 - val_loss: 0.6958 - val_accuracy: 0.7557\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7494 - accuracy: 0.7388 - val_loss: 0.7328 - val_accuracy: 0.7441\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7460 - accuracy: 0.7377 - val_loss: 0.7239 - val_accuracy: 0.7462\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7454 - accuracy: 0.7392 - val_loss: 0.7273 - val_accuracy: 0.7442\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7301 - accuracy: 0.7460 - val_loss: 0.6830 - val_accuracy: 0.7646\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7310 - accuracy: 0.7469 - val_loss: 0.8205 - val_accuracy: 0.7170\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7205 - accuracy: 0.7484 - val_loss: 0.6750 - val_accuracy: 0.7635\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7140 - accuracy: 0.7527 - val_loss: 0.7636 - val_accuracy: 0.7379\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7137 - accuracy: 0.7531 - val_loss: 0.7105 - val_accuracy: 0.7547\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7067 - accuracy: 0.7545 - val_loss: 0.7098 - val_accuracy: 0.7528\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6968 - accuracy: 0.7584 - val_loss: 0.6909 - val_accuracy: 0.7589\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7005 - accuracy: 0.7566 - val_loss: 0.6749 - val_accuracy: 0.7631\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.6914 - accuracy: 0.7594 - val_loss: 0.6571 - val_accuracy: 0.7669\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6884 - accuracy: 0.7598 - val_loss: 0.7806 - val_accuracy: 0.7336\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6841 - accuracy: 0.7607 - val_loss: 0.6463 - val_accuracy: 0.7752\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6787 - accuracy: 0.7639 - val_loss: 0.6807 - val_accuracy: 0.7642\n",
      "Epoch 57/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6736 - accuracy: 0.7642 - val_loss: 0.6990 - val_accuracy: 0.7581\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6711 - accuracy: 0.7685 - val_loss: 0.6849 - val_accuracy: 0.7658\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.6681 - accuracy: 0.7674 - val_loss: 0.6520 - val_accuracy: 0.7748\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6588 - accuracy: 0.7698 - val_loss: 0.6626 - val_accuracy: 0.7705\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6535 - accuracy: 0.7724 - val_loss: 0.6123 - val_accuracy: 0.7920\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6543 - accuracy: 0.7728 - val_loss: 0.6410 - val_accuracy: 0.7786\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.6455 - accuracy: 0.7755 - val_loss: 0.6262 - val_accuracy: 0.7814\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6430 - accuracy: 0.7762 - val_loss: 0.6025 - val_accuracy: 0.7937\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6352 - accuracy: 0.7803 - val_loss: 0.5908 - val_accuracy: 0.7984\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6326 - accuracy: 0.7825 - val_loss: 0.6118 - val_accuracy: 0.7900\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6284 - accuracy: 0.7828 - val_loss: 0.5754 - val_accuracy: 0.8042\n",
      "Epoch 68/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6298 - accuracy: 0.7819 - val_loss: 0.6124 - val_accuracy: 0.7878\n",
      "Epoch 69/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6262 - accuracy: 0.7830 - val_loss: 0.6684 - val_accuracy: 0.7762\n",
      "Epoch 70/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.6224 - accuracy: 0.7843 - val_loss: 0.6682 - val_accuracy: 0.7737\n",
      "Epoch 71/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6172 - accuracy: 0.7848 - val_loss: 0.6180 - val_accuracy: 0.7884\n",
      "Epoch 72/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6146 - accuracy: 0.7867 - val_loss: 0.5894 - val_accuracy: 0.7957\n",
      "Epoch 73/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6126 - accuracy: 0.7883 - val_loss: 0.5538 - val_accuracy: 0.8091\n",
      "Epoch 74/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6062 - accuracy: 0.7895 - val_loss: 0.5736 - val_accuracy: 0.8052\n",
      "Epoch 75/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6036 - accuracy: 0.7915 - val_loss: 0.5499 - val_accuracy: 0.8112\n",
      "Epoch 76/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6023 - accuracy: 0.7926 - val_loss: 0.5859 - val_accuracy: 0.8016\n",
      "Epoch 77/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5967 - accuracy: 0.7941 - val_loss: 0.5557 - val_accuracy: 0.8100\n",
      "Epoch 78/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5907 - accuracy: 0.7965 - val_loss: 0.5780 - val_accuracy: 0.8032\n",
      "Epoch 79/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5910 - accuracy: 0.7968 - val_loss: 0.5790 - val_accuracy: 0.8047\n",
      "Epoch 80/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5924 - accuracy: 0.7969 - val_loss: 0.6469 - val_accuracy: 0.7781\n",
      "Epoch 81/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5813 - accuracy: 0.7998 - val_loss: 0.5710 - val_accuracy: 0.8055\n",
      "Epoch 82/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5848 - accuracy: 0.7981 - val_loss: 0.6074 - val_accuracy: 0.7933\n",
      "Epoch 83/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5766 - accuracy: 0.8007 - val_loss: 0.5527 - val_accuracy: 0.8103\n",
      "Epoch 84/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5742 - accuracy: 0.8044 - val_loss: 0.5371 - val_accuracy: 0.8168\n",
      "Epoch 85/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.5689 - accuracy: 0.8034 - val_loss: 0.5614 - val_accuracy: 0.8102\n",
      "Epoch 86/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.5752 - accuracy: 0.8004 - val_loss: 0.5638 - val_accuracy: 0.8086\n",
      "Epoch 87/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5734 - accuracy: 0.8018 - val_loss: 0.5301 - val_accuracy: 0.8176\n",
      "Epoch 88/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5732 - accuracy: 0.8027 - val_loss: 0.5402 - val_accuracy: 0.8182\n",
      "Epoch 89/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5686 - accuracy: 0.8025 - val_loss: 0.5265 - val_accuracy: 0.8206\n",
      "Epoch 90/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5552 - accuracy: 0.8084 - val_loss: 0.5334 - val_accuracy: 0.8186\n",
      "Epoch 91/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5578 - accuracy: 0.8077 - val_loss: 0.5790 - val_accuracy: 0.8028\n",
      "Epoch 92/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5552 - accuracy: 0.8085 - val_loss: 0.5491 - val_accuracy: 0.8113\n",
      "Epoch 93/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5552 - accuracy: 0.8089 - val_loss: 0.5510 - val_accuracy: 0.8134\n",
      "Epoch 94/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5482 - accuracy: 0.8123 - val_loss: 0.5562 - val_accuracy: 0.8077\n",
      "Epoch 95/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5542 - accuracy: 0.8089 - val_loss: 0.5172 - val_accuracy: 0.8250\n",
      "Epoch 96/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5403 - accuracy: 0.8137 - val_loss: 0.5294 - val_accuracy: 0.8205\n",
      "Epoch 97/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5408 - accuracy: 0.8145 - val_loss: 0.5282 - val_accuracy: 0.8221\n",
      "Epoch 98/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.5438 - accuracy: 0.8111 - val_loss: 0.5316 - val_accuracy: 0.8187\n",
      "Epoch 99/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5369 - accuracy: 0.8145 - val_loss: 0.5111 - val_accuracy: 0.8247\n",
      "Epoch 100/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.5310 - accuracy: 0.8185 - val_loss: 0.5257 - val_accuracy: 0.8197\n",
      "Epoch 101/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5320 - accuracy: 0.8172 - val_loss: 0.5115 - val_accuracy: 0.8266\n",
      "Epoch 102/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.5340 - accuracy: 0.8176 - val_loss: 0.5760 - val_accuracy: 0.8051\n",
      "Epoch 103/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5271 - accuracy: 0.8192 - val_loss: 0.5232 - val_accuracy: 0.8243\n",
      "Epoch 104/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5245 - accuracy: 0.8197 - val_loss: 0.4936 - val_accuracy: 0.8345\n",
      "Epoch 105/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5247 - accuracy: 0.8196 - val_loss: 0.5475 - val_accuracy: 0.8165\n",
      "Epoch 106/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5217 - accuracy: 0.8203 - val_loss: 0.5390 - val_accuracy: 0.8149\n",
      "Epoch 107/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5211 - accuracy: 0.8196 - val_loss: 0.4949 - val_accuracy: 0.8322\n",
      "Epoch 108/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5182 - accuracy: 0.8201 - val_loss: 0.4894 - val_accuracy: 0.8311\n",
      "Epoch 109/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5177 - accuracy: 0.8214 - val_loss: 0.5069 - val_accuracy: 0.8297\n",
      "Epoch 110/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5101 - accuracy: 0.8264 - val_loss: 0.5041 - val_accuracy: 0.8297\n",
      "Epoch 111/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5140 - accuracy: 0.8238 - val_loss: 0.5136 - val_accuracy: 0.8290\n",
      "Epoch 112/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5087 - accuracy: 0.8265 - val_loss: 0.5028 - val_accuracy: 0.8289\n",
      "Epoch 113/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5024 - accuracy: 0.8258 - val_loss: 0.4889 - val_accuracy: 0.8354\n",
      "Epoch 114/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5020 - accuracy: 0.8273 - val_loss: 0.4852 - val_accuracy: 0.8379\n",
      "Epoch 115/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5033 - accuracy: 0.8263 - val_loss: 0.4869 - val_accuracy: 0.8373\n",
      "Epoch 116/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5007 - accuracy: 0.8274 - val_loss: 0.5025 - val_accuracy: 0.8334\n",
      "Epoch 117/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4984 - accuracy: 0.8287 - val_loss: 0.5158 - val_accuracy: 0.8261\n",
      "Epoch 118/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4971 - accuracy: 0.8273 - val_loss: 0.5162 - val_accuracy: 0.8265\n",
      "Epoch 119/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4956 - accuracy: 0.8290 - val_loss: 0.4948 - val_accuracy: 0.8311\n",
      "Epoch 120/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4948 - accuracy: 0.8281 - val_loss: 0.4914 - val_accuracy: 0.8347\n",
      "Epoch 121/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4873 - accuracy: 0.8334 - val_loss: 0.4917 - val_accuracy: 0.8329\n",
      "Epoch 122/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4893 - accuracy: 0.8315 - val_loss: 0.4542 - val_accuracy: 0.8469\n",
      "Epoch 123/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4885 - accuracy: 0.8328 - val_loss: 0.5116 - val_accuracy: 0.8322\n",
      "Epoch 124/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4824 - accuracy: 0.8349 - val_loss: 0.4759 - val_accuracy: 0.8392\n",
      "Epoch 125/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4838 - accuracy: 0.8332 - val_loss: 0.4730 - val_accuracy: 0.8426\n",
      "Epoch 126/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4801 - accuracy: 0.8371 - val_loss: 0.4836 - val_accuracy: 0.8403\n",
      "Epoch 127/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4799 - accuracy: 0.8329 - val_loss: 0.5139 - val_accuracy: 0.8283\n",
      "Epoch 128/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4780 - accuracy: 0.8363 - val_loss: 0.4936 - val_accuracy: 0.8370\n",
      "Epoch 129/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4781 - accuracy: 0.8354 - val_loss: 0.5163 - val_accuracy: 0.8278\n",
      "Epoch 130/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4754 - accuracy: 0.8360 - val_loss: 0.5392 - val_accuracy: 0.8188\n",
      "Epoch 131/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4755 - accuracy: 0.8359 - val_loss: 0.4842 - val_accuracy: 0.8393\n",
      "Epoch 132/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4709 - accuracy: 0.8402 - val_loss: 0.5059 - val_accuracy: 0.8302\n",
      "Epoch 133/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4665 - accuracy: 0.8389 - val_loss: 0.4504 - val_accuracy: 0.8517\n",
      "Epoch 134/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4712 - accuracy: 0.8368 - val_loss: 0.5035 - val_accuracy: 0.8330\n",
      "Epoch 135/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4658 - accuracy: 0.8404 - val_loss: 0.4765 - val_accuracy: 0.8405\n",
      "Epoch 136/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4726 - accuracy: 0.8385 - val_loss: 0.4717 - val_accuracy: 0.8400\n",
      "Epoch 137/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4641 - accuracy: 0.8407 - val_loss: 0.4660 - val_accuracy: 0.8432\n",
      "Epoch 138/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4598 - accuracy: 0.8420 - val_loss: 0.4579 - val_accuracy: 0.8444\n",
      "Epoch 139/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4660 - accuracy: 0.8408 - val_loss: 0.4617 - val_accuracy: 0.8429\n",
      "Epoch 140/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4557 - accuracy: 0.8422 - val_loss: 0.4424 - val_accuracy: 0.8497\n",
      "Epoch 141/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4586 - accuracy: 0.8427 - val_loss: 0.4519 - val_accuracy: 0.8475\n",
      "Epoch 142/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4582 - accuracy: 0.8432 - val_loss: 0.4568 - val_accuracy: 0.8455\n",
      "Epoch 143/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4525 - accuracy: 0.8447 - val_loss: 0.4597 - val_accuracy: 0.8433\n",
      "Epoch 144/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4544 - accuracy: 0.8454 - val_loss: 0.4345 - val_accuracy: 0.8557\n",
      "Epoch 145/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4522 - accuracy: 0.8443 - val_loss: 0.4493 - val_accuracy: 0.8475\n",
      "Epoch 146/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4470 - accuracy: 0.8466 - val_loss: 0.4732 - val_accuracy: 0.8435\n",
      "Epoch 147/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4465 - accuracy: 0.8465 - val_loss: 0.4836 - val_accuracy: 0.8413\n",
      "Epoch 148/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4474 - accuracy: 0.8455 - val_loss: 0.4524 - val_accuracy: 0.8496\n",
      "Epoch 149/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4445 - accuracy: 0.8471 - val_loss: 0.4604 - val_accuracy: 0.8468\n",
      "Epoch 150/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4418 - accuracy: 0.8473 - val_loss: 0.4465 - val_accuracy: 0.8496\n",
      "Epoch 151/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4492 - accuracy: 0.8449 - val_loss: 0.4192 - val_accuracy: 0.8586\n",
      "Epoch 152/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4463 - accuracy: 0.8461 - val_loss: 0.4427 - val_accuracy: 0.8539\n",
      "Epoch 153/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4415 - accuracy: 0.8466 - val_loss: 0.4486 - val_accuracy: 0.8489\n",
      "Epoch 154/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4395 - accuracy: 0.8484 - val_loss: 0.4495 - val_accuracy: 0.8519\n",
      "Epoch 155/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4401 - accuracy: 0.8478 - val_loss: 0.4689 - val_accuracy: 0.8446\n",
      "Epoch 156/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4386 - accuracy: 0.8494 - val_loss: 0.4995 - val_accuracy: 0.8395\n",
      "Epoch 157/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4335 - accuracy: 0.8490 - val_loss: 0.4829 - val_accuracy: 0.8401\n",
      "Epoch 158/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4360 - accuracy: 0.8504 - val_loss: 0.4176 - val_accuracy: 0.8612\n",
      "Epoch 159/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4341 - accuracy: 0.8516 - val_loss: 0.4386 - val_accuracy: 0.8510\n",
      "Epoch 160/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4344 - accuracy: 0.8514 - val_loss: 0.4362 - val_accuracy: 0.8539\n",
      "Epoch 161/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4313 - accuracy: 0.8528 - val_loss: 0.4326 - val_accuracy: 0.8560\n",
      "Epoch 162/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4283 - accuracy: 0.8544 - val_loss: 0.4409 - val_accuracy: 0.8561\n",
      "Epoch 163/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4324 - accuracy: 0.8517 - val_loss: 0.4394 - val_accuracy: 0.8528\n",
      "Epoch 164/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4290 - accuracy: 0.8523 - val_loss: 0.4217 - val_accuracy: 0.8598\n",
      "Epoch 165/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4233 - accuracy: 0.8567 - val_loss: 0.4447 - val_accuracy: 0.8541\n",
      "Epoch 166/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4251 - accuracy: 0.8530 - val_loss: 0.4422 - val_accuracy: 0.8531\n",
      "Epoch 167/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4318 - accuracy: 0.8526 - val_loss: 0.4391 - val_accuracy: 0.8548\n",
      "Epoch 168/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4257 - accuracy: 0.8542 - val_loss: 0.4563 - val_accuracy: 0.8499\n",
      "Epoch 169/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4257 - accuracy: 0.8531 - val_loss: 0.4319 - val_accuracy: 0.8556\n",
      "Epoch 170/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4218 - accuracy: 0.8530 - val_loss: 0.4894 - val_accuracy: 0.8424\n",
      "Epoch 171/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4170 - accuracy: 0.8559 - val_loss: 0.4189 - val_accuracy: 0.8594\n",
      "Epoch 172/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4175 - accuracy: 0.8563 - val_loss: 0.4636 - val_accuracy: 0.8485\n",
      "Epoch 173/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4160 - accuracy: 0.8571 - val_loss: 0.5005 - val_accuracy: 0.8357\n",
      "Epoch 174/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4114 - accuracy: 0.8560 - val_loss: 0.4337 - val_accuracy: 0.8543\n",
      "Epoch 175/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4116 - accuracy: 0.8570 - val_loss: 0.4516 - val_accuracy: 0.8519\n",
      "Epoch 176/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4143 - accuracy: 0.8582 - val_loss: 0.4424 - val_accuracy: 0.8562\n",
      "Epoch 177/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4142 - accuracy: 0.8573 - val_loss: 0.4451 - val_accuracy: 0.8545\n",
      "Epoch 178/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4151 - accuracy: 0.8576 - val_loss: 0.4180 - val_accuracy: 0.8615\n",
      "Epoch 179/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4104 - accuracy: 0.8574 - val_loss: 0.4343 - val_accuracy: 0.8552\n",
      "Epoch 180/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4095 - accuracy: 0.8601 - val_loss: 0.4588 - val_accuracy: 0.8518\n",
      "Epoch 181/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4067 - accuracy: 0.8603 - val_loss: 0.4327 - val_accuracy: 0.8556\n",
      "Epoch 182/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4067 - accuracy: 0.8609 - val_loss: 0.4088 - val_accuracy: 0.8650\n",
      "Epoch 183/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4063 - accuracy: 0.8601 - val_loss: 0.4420 - val_accuracy: 0.8561\n",
      "Epoch 184/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4038 - accuracy: 0.8602 - val_loss: 0.4468 - val_accuracy: 0.8531\n",
      "Epoch 185/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4047 - accuracy: 0.8613 - val_loss: 0.4269 - val_accuracy: 0.8595\n",
      "Epoch 186/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4034 - accuracy: 0.8617 - val_loss: 0.4378 - val_accuracy: 0.8557\n",
      "Epoch 187/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4041 - accuracy: 0.8596 - val_loss: 0.4172 - val_accuracy: 0.8618\n",
      "Epoch 188/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3991 - accuracy: 0.8624 - val_loss: 0.4145 - val_accuracy: 0.8629\n",
      "Epoch 189/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3968 - accuracy: 0.8631 - val_loss: 0.4193 - val_accuracy: 0.8589\n",
      "Epoch 190/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3986 - accuracy: 0.8636 - val_loss: 0.4399 - val_accuracy: 0.8568\n",
      "Epoch 191/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3947 - accuracy: 0.8628 - val_loss: 0.4462 - val_accuracy: 0.8532\n",
      "Epoch 192/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4002 - accuracy: 0.8625 - val_loss: 0.4057 - val_accuracy: 0.8647\n",
      "Epoch 193/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3960 - accuracy: 0.8643 - val_loss: 0.4373 - val_accuracy: 0.8590\n",
      "Epoch 194/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3947 - accuracy: 0.8644 - val_loss: 0.4326 - val_accuracy: 0.8591\n",
      "Epoch 195/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3939 - accuracy: 0.8654 - val_loss: 0.4156 - val_accuracy: 0.8621\n",
      "Epoch 196/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3958 - accuracy: 0.8630 - val_loss: 0.4485 - val_accuracy: 0.8578\n",
      "Epoch 197/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3898 - accuracy: 0.8668 - val_loss: 0.4117 - val_accuracy: 0.8648\n",
      "Epoch 198/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3915 - accuracy: 0.8653 - val_loss: 0.4260 - val_accuracy: 0.8610\n",
      "Epoch 199/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3900 - accuracy: 0.8647 - val_loss: 0.4671 - val_accuracy: 0.8505\n",
      "Epoch 200/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3912 - accuracy: 0.8663 - val_loss: 0.4398 - val_accuracy: 0.8568\n",
      "Epoch 201/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3910 - accuracy: 0.8662 - val_loss: 0.4117 - val_accuracy: 0.8662\n",
      "Epoch 202/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3916 - accuracy: 0.8648 - val_loss: 0.4173 - val_accuracy: 0.8617\n",
      "Epoch 203/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3893 - accuracy: 0.8668 - val_loss: 0.4220 - val_accuracy: 0.8615\n",
      "Epoch 204/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3882 - accuracy: 0.8659 - val_loss: 0.4167 - val_accuracy: 0.8637\n",
      "Epoch 205/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3889 - accuracy: 0.8669 - val_loss: 0.4681 - val_accuracy: 0.8472\n",
      "Epoch 206/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3821 - accuracy: 0.8683 - val_loss: 0.4212 - val_accuracy: 0.8623\n",
      "Epoch 207/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3848 - accuracy: 0.8684 - val_loss: 0.4049 - val_accuracy: 0.8674\n",
      "Epoch 208/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3843 - accuracy: 0.8677 - val_loss: 0.3990 - val_accuracy: 0.8654\n",
      "Epoch 209/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3779 - accuracy: 0.8698 - val_loss: 0.4026 - val_accuracy: 0.8657\n",
      "Epoch 210/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3806 - accuracy: 0.8686 - val_loss: 0.4716 - val_accuracy: 0.8493\n",
      "Epoch 211/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3844 - accuracy: 0.8688 - val_loss: 0.4049 - val_accuracy: 0.8672\n",
      "Epoch 212/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3740 - accuracy: 0.8708 - val_loss: 0.4225 - val_accuracy: 0.8646\n",
      "Epoch 213/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3768 - accuracy: 0.8693 - val_loss: 0.4146 - val_accuracy: 0.8636\n",
      "Epoch 214/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3785 - accuracy: 0.8693 - val_loss: 0.4168 - val_accuracy: 0.8653\n",
      "Epoch 215/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3774 - accuracy: 0.8703 - val_loss: 0.4306 - val_accuracy: 0.8587\n",
      "Epoch 216/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3757 - accuracy: 0.8702 - val_loss: 0.4219 - val_accuracy: 0.8640\n",
      "Epoch 217/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3764 - accuracy: 0.8696 - val_loss: 0.4049 - val_accuracy: 0.8673\n",
      "Epoch 218/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3756 - accuracy: 0.8709 - val_loss: 0.4681 - val_accuracy: 0.8464\n",
      "Epoch 219/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3765 - accuracy: 0.8703 - val_loss: 0.4028 - val_accuracy: 0.8686\n",
      "Epoch 220/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3729 - accuracy: 0.8729 - val_loss: 0.4802 - val_accuracy: 0.8467\n",
      "Epoch 221/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3786 - accuracy: 0.8700 - val_loss: 0.4136 - val_accuracy: 0.8655\n",
      "Epoch 222/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3728 - accuracy: 0.8713 - val_loss: 0.4213 - val_accuracy: 0.8637\n",
      "Epoch 223/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3695 - accuracy: 0.8715 - val_loss: 0.4159 - val_accuracy: 0.8645\n",
      "Epoch 224/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3675 - accuracy: 0.8739 - val_loss: 0.4271 - val_accuracy: 0.8631\n",
      "Epoch 225/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3674 - accuracy: 0.8736 - val_loss: 0.4247 - val_accuracy: 0.8590\n",
      "Epoch 226/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3631 - accuracy: 0.8751 - val_loss: 0.4319 - val_accuracy: 0.8607\n",
      "Epoch 227/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3725 - accuracy: 0.8728 - val_loss: 0.3780 - val_accuracy: 0.8775\n",
      "Epoch 228/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3662 - accuracy: 0.8737 - val_loss: 0.3934 - val_accuracy: 0.8713\n",
      "Epoch 229/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3689 - accuracy: 0.8719 - val_loss: 0.3958 - val_accuracy: 0.8695\n",
      "Epoch 230/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3622 - accuracy: 0.8746 - val_loss: 0.4132 - val_accuracy: 0.8644\n",
      "Epoch 231/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3638 - accuracy: 0.8742 - val_loss: 0.3971 - val_accuracy: 0.8701\n",
      "Epoch 232/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3629 - accuracy: 0.8750 - val_loss: 0.3955 - val_accuracy: 0.8707\n",
      "Epoch 233/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3622 - accuracy: 0.8762 - val_loss: 0.4138 - val_accuracy: 0.8645\n",
      "Epoch 234/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3658 - accuracy: 0.8728 - val_loss: 0.3807 - val_accuracy: 0.8770\n",
      "Epoch 235/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3669 - accuracy: 0.8731 - val_loss: 0.3918 - val_accuracy: 0.8718\n",
      "Epoch 236/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3634 - accuracy: 0.8726 - val_loss: 0.3996 - val_accuracy: 0.8707\n",
      "Epoch 237/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3607 - accuracy: 0.8759 - val_loss: 0.3800 - val_accuracy: 0.8746\n",
      "Epoch 238/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3576 - accuracy: 0.8761 - val_loss: 0.3865 - val_accuracy: 0.8732\n",
      "Epoch 239/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3581 - accuracy: 0.8757 - val_loss: 0.3920 - val_accuracy: 0.8719\n",
      "Epoch 240/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3575 - accuracy: 0.8775 - val_loss: 0.3921 - val_accuracy: 0.8721\n",
      "Epoch 241/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3573 - accuracy: 0.8769 - val_loss: 0.4221 - val_accuracy: 0.8623\n",
      "Epoch 242/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3570 - accuracy: 0.8763 - val_loss: 0.3903 - val_accuracy: 0.8713\n",
      "Epoch 243/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3530 - accuracy: 0.8778 - val_loss: 0.4520 - val_accuracy: 0.8589\n",
      "Epoch 244/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3546 - accuracy: 0.8788 - val_loss: 0.3970 - val_accuracy: 0.8691\n",
      "Epoch 245/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3544 - accuracy: 0.8776 - val_loss: 0.4308 - val_accuracy: 0.8608\n",
      "Epoch 246/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3551 - accuracy: 0.8790 - val_loss: 0.3729 - val_accuracy: 0.8771\n",
      "Epoch 247/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3541 - accuracy: 0.8780 - val_loss: 0.3895 - val_accuracy: 0.8729\n",
      "Epoch 248/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3527 - accuracy: 0.8778 - val_loss: 0.3874 - val_accuracy: 0.8725\n",
      "Epoch 249/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3524 - accuracy: 0.8790 - val_loss: 0.3859 - val_accuracy: 0.8735\n",
      "Epoch 250/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3502 - accuracy: 0.8781 - val_loss: 0.3926 - val_accuracy: 0.8708\n",
      "Epoch 251/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3488 - accuracy: 0.8794 - val_loss: 0.3983 - val_accuracy: 0.8713\n",
      "Epoch 252/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3486 - accuracy: 0.8793 - val_loss: 0.3846 - val_accuracy: 0.8736\n",
      "Epoch 253/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3483 - accuracy: 0.8812 - val_loss: 0.3811 - val_accuracy: 0.8792\n",
      "Epoch 254/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3486 - accuracy: 0.8807 - val_loss: 0.3840 - val_accuracy: 0.8756\n",
      "Epoch 255/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3458 - accuracy: 0.8814 - val_loss: 0.3877 - val_accuracy: 0.8745\n",
      "Epoch 256/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3441 - accuracy: 0.8820 - val_loss: 0.3698 - val_accuracy: 0.8788\n",
      "Epoch 257/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3489 - accuracy: 0.8802 - val_loss: 0.3830 - val_accuracy: 0.8745\n",
      "Epoch 258/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3440 - accuracy: 0.8826 - val_loss: 0.3905 - val_accuracy: 0.8765\n",
      "Epoch 259/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3448 - accuracy: 0.8802 - val_loss: 0.3875 - val_accuracy: 0.8756\n",
      "Epoch 260/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3427 - accuracy: 0.8818 - val_loss: 0.3970 - val_accuracy: 0.8725\n",
      "Epoch 261/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3452 - accuracy: 0.8813 - val_loss: 0.3768 - val_accuracy: 0.8797\n",
      "Epoch 262/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3450 - accuracy: 0.8795 - val_loss: 0.3851 - val_accuracy: 0.8763\n",
      "Epoch 263/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3461 - accuracy: 0.8802 - val_loss: 0.3818 - val_accuracy: 0.8752\n",
      "Epoch 264/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3425 - accuracy: 0.8820 - val_loss: 0.3954 - val_accuracy: 0.8699\n",
      "Epoch 265/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3426 - accuracy: 0.8815 - val_loss: 0.3896 - val_accuracy: 0.8729\n",
      "Epoch 266/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3385 - accuracy: 0.8835 - val_loss: 0.4166 - val_accuracy: 0.8646\n",
      "Epoch 267/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3417 - accuracy: 0.8832 - val_loss: 0.3782 - val_accuracy: 0.8773\n",
      "Epoch 268/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3390 - accuracy: 0.8835 - val_loss: 0.4233 - val_accuracy: 0.8644\n",
      "Epoch 269/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3371 - accuracy: 0.8835 - val_loss: 0.4029 - val_accuracy: 0.8696\n",
      "Epoch 270/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3330 - accuracy: 0.8836 - val_loss: 0.3797 - val_accuracy: 0.8799\n",
      "Epoch 271/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3361 - accuracy: 0.8830 - val_loss: 0.3885 - val_accuracy: 0.8725\n",
      "Epoch 272/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3307 - accuracy: 0.8856 - val_loss: 0.3874 - val_accuracy: 0.8762\n",
      "Epoch 273/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3383 - accuracy: 0.8827 - val_loss: 0.3857 - val_accuracy: 0.8751\n",
      "Epoch 274/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3344 - accuracy: 0.8850 - val_loss: 0.4025 - val_accuracy: 0.8693\n",
      "Epoch 275/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3360 - accuracy: 0.8845 - val_loss: 0.4044 - val_accuracy: 0.8693\n",
      "Epoch 276/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3346 - accuracy: 0.8853 - val_loss: 0.3954 - val_accuracy: 0.8705\n",
      "Epoch 277/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3359 - accuracy: 0.8822 - val_loss: 0.3766 - val_accuracy: 0.8748\n",
      "Epoch 278/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3363 - accuracy: 0.8832 - val_loss: 0.3668 - val_accuracy: 0.8817\n",
      "Epoch 279/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3340 - accuracy: 0.8855 - val_loss: 0.3945 - val_accuracy: 0.8724\n",
      "Epoch 280/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3345 - accuracy: 0.8838 - val_loss: 0.3934 - val_accuracy: 0.8763\n",
      "Epoch 281/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3383 - accuracy: 0.8832 - val_loss: 0.3724 - val_accuracy: 0.8814\n",
      "Epoch 282/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3356 - accuracy: 0.8831 - val_loss: 0.3831 - val_accuracy: 0.8768\n",
      "Epoch 283/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3325 - accuracy: 0.8856 - val_loss: 0.3962 - val_accuracy: 0.8687\n",
      "Epoch 284/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3311 - accuracy: 0.8852 - val_loss: 0.3834 - val_accuracy: 0.8784\n",
      "Epoch 285/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3290 - accuracy: 0.8857 - val_loss: 0.3934 - val_accuracy: 0.8735\n",
      "Epoch 286/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3246 - accuracy: 0.8887 - val_loss: 0.3997 - val_accuracy: 0.8713\n",
      "Epoch 287/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3319 - accuracy: 0.8863 - val_loss: 0.3698 - val_accuracy: 0.8800\n",
      "Epoch 288/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3251 - accuracy: 0.8886 - val_loss: 0.3935 - val_accuracy: 0.8723\n",
      "Epoch 289/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3299 - accuracy: 0.8870 - val_loss: 0.3717 - val_accuracy: 0.8798\n",
      "Epoch 290/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3275 - accuracy: 0.8862 - val_loss: 0.3779 - val_accuracy: 0.8776\n",
      "Epoch 291/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3247 - accuracy: 0.8890 - val_loss: 0.3838 - val_accuracy: 0.8788\n",
      "Epoch 292/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3255 - accuracy: 0.8868 - val_loss: 0.3859 - val_accuracy: 0.8741\n",
      "Epoch 293/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3261 - accuracy: 0.8885 - val_loss: 0.3608 - val_accuracy: 0.8835\n",
      "Epoch 294/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3266 - accuracy: 0.8872 - val_loss: 0.3992 - val_accuracy: 0.8715\n",
      "Epoch 295/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3239 - accuracy: 0.8881 - val_loss: 0.3821 - val_accuracy: 0.8768\n",
      "Epoch 296/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3233 - accuracy: 0.8887 - val_loss: 0.3969 - val_accuracy: 0.8745\n",
      "Epoch 297/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3202 - accuracy: 0.8889 - val_loss: 0.3863 - val_accuracy: 0.8770\n",
      "Epoch 298/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3271 - accuracy: 0.8878 - val_loss: 0.3976 - val_accuracy: 0.8749\n",
      "Epoch 299/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3220 - accuracy: 0.8888 - val_loss: 0.4026 - val_accuracy: 0.8749\n",
      "Epoch 300/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3171 - accuracy: 0.8893 - val_loss: 0.3782 - val_accuracy: 0.8804\n",
      "Epoch 301/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3224 - accuracy: 0.8894 - val_loss: 0.3878 - val_accuracy: 0.8732\n",
      "Epoch 302/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3207 - accuracy: 0.8899 - val_loss: 0.3640 - val_accuracy: 0.8846\n",
      "Epoch 303/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3170 - accuracy: 0.8904 - val_loss: 0.3958 - val_accuracy: 0.8731\n",
      "Epoch 304/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3224 - accuracy: 0.8883 - val_loss: 0.3756 - val_accuracy: 0.8821\n",
      "Epoch 305/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3155 - accuracy: 0.8896 - val_loss: 0.3907 - val_accuracy: 0.8766\n",
      "Epoch 306/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3189 - accuracy: 0.8898 - val_loss: 0.3934 - val_accuracy: 0.8748\n",
      "Epoch 307/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3184 - accuracy: 0.8891 - val_loss: 0.3860 - val_accuracy: 0.8755\n",
      "Epoch 308/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3174 - accuracy: 0.8915 - val_loss: 0.3844 - val_accuracy: 0.8783\n",
      "Epoch 309/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3148 - accuracy: 0.8890 - val_loss: 0.3701 - val_accuracy: 0.8804\n",
      "Epoch 310/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3184 - accuracy: 0.8908 - val_loss: 0.3842 - val_accuracy: 0.8761\n",
      "Epoch 311/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3208 - accuracy: 0.8889 - val_loss: 0.3832 - val_accuracy: 0.8783\n",
      "Epoch 312/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3136 - accuracy: 0.8915 - val_loss: 0.3570 - val_accuracy: 0.8865\n",
      "Epoch 313/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3140 - accuracy: 0.8908 - val_loss: 0.3631 - val_accuracy: 0.8838\n",
      "Epoch 314/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3170 - accuracy: 0.8914 - val_loss: 0.3692 - val_accuracy: 0.8826\n",
      "Epoch 315/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3194 - accuracy: 0.8907 - val_loss: 0.3776 - val_accuracy: 0.8762\n",
      "Epoch 316/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3125 - accuracy: 0.8932 - val_loss: 0.3961 - val_accuracy: 0.8767\n",
      "Epoch 317/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3141 - accuracy: 0.8911 - val_loss: 0.3532 - val_accuracy: 0.8863\n",
      "Epoch 318/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3090 - accuracy: 0.8926 - val_loss: 0.3585 - val_accuracy: 0.8864\n",
      "Epoch 319/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3174 - accuracy: 0.8906 - val_loss: 0.3989 - val_accuracy: 0.8767\n",
      "Epoch 320/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3074 - accuracy: 0.8954 - val_loss: 0.3821 - val_accuracy: 0.8788\n",
      "Epoch 321/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3154 - accuracy: 0.8903 - val_loss: 0.3658 - val_accuracy: 0.8832\n",
      "Epoch 322/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3118 - accuracy: 0.8915 - val_loss: 0.3640 - val_accuracy: 0.8827\n",
      "Epoch 323/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3092 - accuracy: 0.8926 - val_loss: 0.3620 - val_accuracy: 0.8850\n",
      "Epoch 324/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3157 - accuracy: 0.8915 - val_loss: 0.3736 - val_accuracy: 0.8815\n",
      "Epoch 325/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3071 - accuracy: 0.8929 - val_loss: 0.4193 - val_accuracy: 0.8678\n",
      "Epoch 326/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3079 - accuracy: 0.8928 - val_loss: 0.4073 - val_accuracy: 0.8697\n",
      "Epoch 327/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3144 - accuracy: 0.8913 - val_loss: 0.3635 - val_accuracy: 0.8856\n",
      "Epoch 328/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3095 - accuracy: 0.8927 - val_loss: 0.3692 - val_accuracy: 0.8812\n",
      "Epoch 329/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3085 - accuracy: 0.8947 - val_loss: 0.3568 - val_accuracy: 0.8831\n",
      "Epoch 330/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3064 - accuracy: 0.8943 - val_loss: 0.3681 - val_accuracy: 0.8818\n",
      "Epoch 331/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3058 - accuracy: 0.8937 - val_loss: 0.3644 - val_accuracy: 0.8846\n",
      "Epoch 332/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3056 - accuracy: 0.8940 - val_loss: 0.3925 - val_accuracy: 0.8743\n",
      "Epoch 333/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3058 - accuracy: 0.8939 - val_loss: 0.3650 - val_accuracy: 0.8845\n",
      "Epoch 334/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3080 - accuracy: 0.8934 - val_loss: 0.3817 - val_accuracy: 0.8795\n",
      "Epoch 335/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3055 - accuracy: 0.8938 - val_loss: 0.3736 - val_accuracy: 0.8828\n",
      "Epoch 336/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3049 - accuracy: 0.8959 - val_loss: 0.3722 - val_accuracy: 0.8830\n",
      "Epoch 337/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3037 - accuracy: 0.8945 - val_loss: 0.3721 - val_accuracy: 0.8813\n",
      "Epoch 338/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3061 - accuracy: 0.8941 - val_loss: 0.3737 - val_accuracy: 0.8818\n",
      "Epoch 339/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3011 - accuracy: 0.8946 - val_loss: 0.3753 - val_accuracy: 0.8800\n",
      "Epoch 340/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3015 - accuracy: 0.8940 - val_loss: 0.3530 - val_accuracy: 0.8890\n",
      "Epoch 341/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3037 - accuracy: 0.8936 - val_loss: 0.3619 - val_accuracy: 0.8873\n",
      "Epoch 342/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2966 - accuracy: 0.8974 - val_loss: 0.3905 - val_accuracy: 0.8758\n",
      "Epoch 343/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3050 - accuracy: 0.8943 - val_loss: 0.3749 - val_accuracy: 0.8816\n",
      "Epoch 344/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3015 - accuracy: 0.8933 - val_loss: 0.3743 - val_accuracy: 0.8839\n",
      "Epoch 345/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3061 - accuracy: 0.8935 - val_loss: 0.3696 - val_accuracy: 0.8830\n",
      "Epoch 346/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3043 - accuracy: 0.8941 - val_loss: 0.3718 - val_accuracy: 0.8808\n",
      "Epoch 347/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3005 - accuracy: 0.8974 - val_loss: 0.3750 - val_accuracy: 0.8825\n",
      "Epoch 348/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3005 - accuracy: 0.8960 - val_loss: 0.3750 - val_accuracy: 0.8796\n",
      "Epoch 349/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2983 - accuracy: 0.8961 - val_loss: 0.4161 - val_accuracy: 0.8712\n",
      "Epoch 350/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2988 - accuracy: 0.8978 - val_loss: 0.3731 - val_accuracy: 0.8812\n",
      "Epoch 351/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3015 - accuracy: 0.8954 - val_loss: 0.3793 - val_accuracy: 0.8792\n",
      "Epoch 352/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3007 - accuracy: 0.8966 - val_loss: 0.3509 - val_accuracy: 0.8849\n",
      "Epoch 353/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2957 - accuracy: 0.8976 - val_loss: 0.3950 - val_accuracy: 0.8765\n",
      "Epoch 354/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3008 - accuracy: 0.8963 - val_loss: 0.3682 - val_accuracy: 0.8835\n",
      "Epoch 355/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.2972 - accuracy: 0.8968 - val_loss: 0.3796 - val_accuracy: 0.8814\n",
      "Epoch 356/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2945 - accuracy: 0.8982 - val_loss: 0.3687 - val_accuracy: 0.8829\n",
      "Epoch 357/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2968 - accuracy: 0.8973 - val_loss: 0.3731 - val_accuracy: 0.8832\n",
      "Epoch 358/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2939 - accuracy: 0.8990 - val_loss: 0.3651 - val_accuracy: 0.8862\n",
      "Epoch 359/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2937 - accuracy: 0.8977 - val_loss: 0.3584 - val_accuracy: 0.8853\n",
      "Epoch 360/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2919 - accuracy: 0.8975 - val_loss: 0.3984 - val_accuracy: 0.8726\n",
      "Epoch 361/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2931 - accuracy: 0.8990 - val_loss: 0.3760 - val_accuracy: 0.8816\n",
      "Epoch 362/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2896 - accuracy: 0.8997 - val_loss: 0.3582 - val_accuracy: 0.8874\n",
      "Epoch 363/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2880 - accuracy: 0.9000 - val_loss: 0.3553 - val_accuracy: 0.8856\n",
      "Epoch 364/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2946 - accuracy: 0.8980 - val_loss: 0.3711 - val_accuracy: 0.8805\n",
      "Epoch 365/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2944 - accuracy: 0.8973 - val_loss: 0.3648 - val_accuracy: 0.8848\n",
      "Epoch 366/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2909 - accuracy: 0.8976 - val_loss: 0.3630 - val_accuracy: 0.8880\n",
      "Epoch 367/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2875 - accuracy: 0.9003 - val_loss: 0.3628 - val_accuracy: 0.8871\n",
      "Epoch 368/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2929 - accuracy: 0.8994 - val_loss: 0.3695 - val_accuracy: 0.8838\n",
      "Epoch 369/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2873 - accuracy: 0.8999 - val_loss: 0.3590 - val_accuracy: 0.8873\n",
      "Epoch 370/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2899 - accuracy: 0.9007 - val_loss: 0.3711 - val_accuracy: 0.8810\n",
      "Epoch 371/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2922 - accuracy: 0.8980 - val_loss: 0.3868 - val_accuracy: 0.8752\n",
      "Epoch 372/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2907 - accuracy: 0.9004 - val_loss: 0.3769 - val_accuracy: 0.8829\n",
      "Epoch 373/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2880 - accuracy: 0.8987 - val_loss: 0.3606 - val_accuracy: 0.8863\n",
      "Epoch 374/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2880 - accuracy: 0.8989 - val_loss: 0.3803 - val_accuracy: 0.8800\n",
      "Epoch 375/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.2847 - accuracy: 0.9018 - val_loss: 0.3851 - val_accuracy: 0.8792\n",
      "Epoch 376/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2873 - accuracy: 0.8999 - val_loss: 0.3697 - val_accuracy: 0.8836\n",
      "Epoch 377/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2880 - accuracy: 0.8998 - val_loss: 0.3710 - val_accuracy: 0.8818\n",
      "Epoch 378/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2877 - accuracy: 0.8991 - val_loss: 0.3659 - val_accuracy: 0.8861\n",
      "Epoch 379/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2847 - accuracy: 0.9012 - val_loss: 0.3801 - val_accuracy: 0.8834\n",
      "Epoch 380/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2895 - accuracy: 0.9000 - val_loss: 0.3646 - val_accuracy: 0.8844\n",
      "Epoch 381/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2887 - accuracy: 0.8994 - val_loss: 0.3597 - val_accuracy: 0.8860\n",
      "Epoch 382/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2927 - accuracy: 0.8989 - val_loss: 0.3820 - val_accuracy: 0.8819\n",
      "Epoch 383/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2858 - accuracy: 0.9011 - val_loss: 0.3709 - val_accuracy: 0.8834\n",
      "Epoch 384/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2861 - accuracy: 0.9001 - val_loss: 0.3636 - val_accuracy: 0.8837\n",
      "Epoch 385/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2828 - accuracy: 0.9017 - val_loss: 0.3684 - val_accuracy: 0.8854\n",
      "Epoch 386/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2815 - accuracy: 0.9032 - val_loss: 0.3673 - val_accuracy: 0.8861\n",
      "Epoch 387/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2838 - accuracy: 0.9018 - val_loss: 0.3714 - val_accuracy: 0.8814\n",
      "Epoch 388/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2877 - accuracy: 0.9000 - val_loss: 0.3960 - val_accuracy: 0.8762\n",
      "Epoch 389/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2859 - accuracy: 0.9009 - val_loss: 0.3543 - val_accuracy: 0.8877\n",
      "Epoch 390/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2876 - accuracy: 0.9011 - val_loss: 0.3658 - val_accuracy: 0.8852\n",
      "Epoch 391/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2839 - accuracy: 0.9015 - val_loss: 0.3734 - val_accuracy: 0.8843\n",
      "Epoch 392/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2803 - accuracy: 0.9045 - val_loss: 0.3644 - val_accuracy: 0.8891\n",
      "Epoch 393/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2835 - accuracy: 0.9019 - val_loss: 0.3679 - val_accuracy: 0.8848\n",
      "Epoch 394/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2846 - accuracy: 0.9030 - val_loss: 0.3556 - val_accuracy: 0.8891\n",
      "Epoch 395/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2836 - accuracy: 0.9022 - val_loss: 0.3534 - val_accuracy: 0.8895\n",
      "Epoch 396/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2815 - accuracy: 0.9024 - val_loss: 0.3734 - val_accuracy: 0.8854\n",
      "Epoch 397/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2797 - accuracy: 0.9026 - val_loss: 0.3574 - val_accuracy: 0.8879\n",
      "Epoch 398/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2812 - accuracy: 0.9019 - val_loss: 0.3713 - val_accuracy: 0.8842\n",
      "Epoch 399/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2872 - accuracy: 0.9003 - val_loss: 0.3576 - val_accuracy: 0.8864\n",
      "Epoch 400/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2827 - accuracy: 0.9021 - val_loss: 0.3729 - val_accuracy: 0.8835\n",
      "Total time for creating the baseline model: 4:22:47.049212\n"
     ]
    }
   ],
   "source": [
    "# Initialize the baseline model\n",
    "startTimeModule = datetime.now()\n",
    "reset_random(seedNum)\n",
    "baseline_model = create_default_model()\n",
    "# Create data generator for augmentation\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "X_train_aug = datagen.flow(X_train, y_train, batch_size=64)\n",
    "steps = int(X_train.shape[0] / 64)\n",
    "baseline_hist = baseline_model.fit(X_train_aug, steps_per_epoch=steps, epochs=default_epoch, validation_data=(X_test, y_test), verbose=1)\n",
    "print('Total time for creating the baseline model:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the baseline model\n",
    "print(baseline_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential', 'layers': [{'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'batch_input_shape': (None, 32, 32, 3), 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.3, 'noise_shape': None, 'seed': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([1]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# Display the configuration of the baseline model\n",
    "print(baseline_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# List all data points in the baseline model training history\n",
    "print(baseline_hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry for accuracy and loss\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(baseline_hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_accuracy'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.subplot(212)\n",
    "plt.plot(baseline_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(baseline_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Baseline Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_customized_model(optimizer, kernel_init):\n",
    "    customized_model = Sequential()\n",
    "    customized_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_init, padding='same', input_shape=(32, 32, 3)))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_init, padding='same'))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(MaxPooling2D((2, 2)))\n",
    "    customized_model.add(Dropout(0.2))\n",
    "    customized_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_init, padding='same'))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_init, padding='same'))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(MaxPooling2D((2, 2)))\n",
    "    customized_model.add(Dropout(0.3))\n",
    "    customized_model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_init, padding='same'))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_init, padding='same'))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(MaxPooling2D((2, 2)))\n",
    "    customized_model.add(Dropout(0.4))\n",
    "    customized_model.add(Flatten())\n",
    "    customized_model.add(Dense(128, activation='relu', kernel_initializer=kernel_init))\n",
    "    customized_model.add(BatchNormalization())\n",
    "    customized_model.add(Dropout(0.5))\n",
    "    customized_model.add(Dense(num_classes, activation='softmax', kernel_initializer=kernel_init))\n",
    "    customized_model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return customized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer candidate #1 has the object ID of <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28fc2447b8>\n",
      "Optimizer candidate #2 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28fc29b1d0>\n",
      "Optimizer candidate #3 has the object ID of <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f28fc29bc50>\n",
      "Optimizer candidate #4 has the object ID of <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28fc2447b8>\n",
      "Optimizer candidate #5 has the object ID of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28fc29b1d0>\n",
      "Optimizer candidate #6 has the object ID of <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f28fc29bc50>\n",
      "Initializer candidate #1 has the object ID of <tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f28fc248a20>\n",
      "\n",
      "Forming the grid-search model #0 using: optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28fc2447b8>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f28fc248a20>, epochs=400, batch_size=64\n",
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 2.1407 - accuracy: 0.3028 - val_loss: 1.5632 - val_accuracy: 0.4393\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.6307 - accuracy: 0.4049 - val_loss: 1.5372 - val_accuracy: 0.4414\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 1.4946 - accuracy: 0.4524 - val_loss: 1.4267 - val_accuracy: 0.4805\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.4096 - accuracy: 0.4863 - val_loss: 1.5874 - val_accuracy: 0.4409\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.3367 - accuracy: 0.5149 - val_loss: 1.3389 - val_accuracy: 0.5217\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.2860 - accuracy: 0.5340 - val_loss: 1.3127 - val_accuracy: 0.5288\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.2453 - accuracy: 0.5514 - val_loss: 1.3288 - val_accuracy: 0.5319\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.2108 - accuracy: 0.5642 - val_loss: 1.2501 - val_accuracy: 0.5481\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.1734 - accuracy: 0.5795 - val_loss: 1.2235 - val_accuracy: 0.5584\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.1422 - accuracy: 0.5918 - val_loss: 1.2237 - val_accuracy: 0.5598\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.1251 - accuracy: 0.5964 - val_loss: 1.2500 - val_accuracy: 0.5540\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.1024 - accuracy: 0.6057 - val_loss: 1.2055 - val_accuracy: 0.5741\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 1.0798 - accuracy: 0.6161 - val_loss: 1.1364 - val_accuracy: 0.5916\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0595 - accuracy: 0.6220 - val_loss: 1.1208 - val_accuracy: 0.6009\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0316 - accuracy: 0.6345 - val_loss: 1.1107 - val_accuracy: 0.6032\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0133 - accuracy: 0.6390 - val_loss: 1.0882 - val_accuracy: 0.6134\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9975 - accuracy: 0.6462 - val_loss: 0.9936 - val_accuracy: 0.6454\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9827 - accuracy: 0.6525 - val_loss: 1.0633 - val_accuracy: 0.6256\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9653 - accuracy: 0.6581 - val_loss: 0.9612 - val_accuracy: 0.6568\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9499 - accuracy: 0.6639 - val_loss: 0.9308 - val_accuracy: 0.6717\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9337 - accuracy: 0.6687 - val_loss: 1.0450 - val_accuracy: 0.6358\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9194 - accuracy: 0.6756 - val_loss: 0.9546 - val_accuracy: 0.6638\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9112 - accuracy: 0.6789 - val_loss: 0.9729 - val_accuracy: 0.6512\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9018 - accuracy: 0.6811 - val_loss: 0.8720 - val_accuracy: 0.6899\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8878 - accuracy: 0.6869 - val_loss: 0.8732 - val_accuracy: 0.6940\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8780 - accuracy: 0.6915 - val_loss: 0.8957 - val_accuracy: 0.6831\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8577 - accuracy: 0.6974 - val_loss: 0.9077 - val_accuracy: 0.6868\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8505 - accuracy: 0.6999 - val_loss: 0.8637 - val_accuracy: 0.6988\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8447 - accuracy: 0.7029 - val_loss: 0.8464 - val_accuracy: 0.7003\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8360 - accuracy: 0.7044 - val_loss: 0.8820 - val_accuracy: 0.6898\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8313 - accuracy: 0.7080 - val_loss: 0.8614 - val_accuracy: 0.7026\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8244 - accuracy: 0.7091 - val_loss: 0.8522 - val_accuracy: 0.7045\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8085 - accuracy: 0.7160 - val_loss: 0.7606 - val_accuracy: 0.7292\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8045 - accuracy: 0.7180 - val_loss: 0.8088 - val_accuracy: 0.7187\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8005 - accuracy: 0.7181 - val_loss: 0.7671 - val_accuracy: 0.7309\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7873 - accuracy: 0.7236 - val_loss: 0.7475 - val_accuracy: 0.7400\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7799 - accuracy: 0.7253 - val_loss: 0.8116 - val_accuracy: 0.7178\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7721 - accuracy: 0.7287 - val_loss: 0.7509 - val_accuracy: 0.7412\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7682 - accuracy: 0.7314 - val_loss: 0.7848 - val_accuracy: 0.7266\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7607 - accuracy: 0.7342 - val_loss: 0.7477 - val_accuracy: 0.7398\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7539 - accuracy: 0.7345 - val_loss: 0.7720 - val_accuracy: 0.7307\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7518 - accuracy: 0.7367 - val_loss: 0.8121 - val_accuracy: 0.7190\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7471 - accuracy: 0.7408 - val_loss: 0.7354 - val_accuracy: 0.7442\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7365 - accuracy: 0.7437 - val_loss: 0.7013 - val_accuracy: 0.7554\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.7300 - accuracy: 0.7444 - val_loss: 0.6961 - val_accuracy: 0.7567\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7257 - accuracy: 0.7458 - val_loss: 0.7198 - val_accuracy: 0.7497\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7217 - accuracy: 0.7469 - val_loss: 0.6952 - val_accuracy: 0.7557\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7113 - accuracy: 0.7524 - val_loss: 0.6746 - val_accuracy: 0.7658\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7071 - accuracy: 0.7543 - val_loss: 0.7720 - val_accuracy: 0.7338\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7056 - accuracy: 0.7537 - val_loss: 0.7038 - val_accuracy: 0.7571\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6973 - accuracy: 0.7562 - val_loss: 0.8349 - val_accuracy: 0.7190\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6943 - accuracy: 0.7571 - val_loss: 0.6910 - val_accuracy: 0.7648\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6864 - accuracy: 0.7586 - val_loss: 0.7519 - val_accuracy: 0.7420\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6845 - accuracy: 0.7629 - val_loss: 0.6285 - val_accuracy: 0.7804\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6745 - accuracy: 0.7655 - val_loss: 0.6280 - val_accuracy: 0.7810\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6794 - accuracy: 0.7655 - val_loss: 0.6438 - val_accuracy: 0.7790\n",
      "Epoch 57/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6717 - accuracy: 0.7647 - val_loss: 0.6897 - val_accuracy: 0.7640\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6676 - accuracy: 0.7700 - val_loss: 0.7666 - val_accuracy: 0.7419\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6647 - accuracy: 0.7711 - val_loss: 0.6862 - val_accuracy: 0.7637\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6595 - accuracy: 0.7705 - val_loss: 0.6985 - val_accuracy: 0.7602\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6551 - accuracy: 0.7725 - val_loss: 0.5976 - val_accuracy: 0.7954\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6553 - accuracy: 0.7732 - val_loss: 0.7092 - val_accuracy: 0.7576\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6468 - accuracy: 0.7760 - val_loss: 0.6665 - val_accuracy: 0.7671\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6410 - accuracy: 0.7778 - val_loss: 0.6566 - val_accuracy: 0.7751\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6424 - accuracy: 0.7776 - val_loss: 0.5916 - val_accuracy: 0.7950\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6324 - accuracy: 0.7792 - val_loss: 0.6122 - val_accuracy: 0.7912\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6321 - accuracy: 0.7825 - val_loss: 0.6258 - val_accuracy: 0.7842\n",
      "Epoch 68/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6292 - accuracy: 0.7817 - val_loss: 0.6597 - val_accuracy: 0.7784\n",
      "Epoch 69/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6307 - accuracy: 0.7822 - val_loss: 0.6197 - val_accuracy: 0.7871\n",
      "Epoch 70/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6223 - accuracy: 0.7866 - val_loss: 0.6918 - val_accuracy: 0.7658\n",
      "Epoch 71/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6165 - accuracy: 0.7879 - val_loss: 0.5772 - val_accuracy: 0.8016\n",
      "Epoch 72/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6074 - accuracy: 0.7893 - val_loss: 0.5562 - val_accuracy: 0.8084\n",
      "Epoch 73/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6165 - accuracy: 0.7865 - val_loss: 0.5705 - val_accuracy: 0.8056\n",
      "Epoch 74/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6075 - accuracy: 0.7906 - val_loss: 0.5836 - val_accuracy: 0.7983\n",
      "Epoch 75/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6062 - accuracy: 0.7895 - val_loss: 0.5848 - val_accuracy: 0.7997\n",
      "Epoch 76/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.6035 - accuracy: 0.7902 - val_loss: 0.5836 - val_accuracy: 0.8036\n",
      "Epoch 77/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5982 - accuracy: 0.7933 - val_loss: 0.5969 - val_accuracy: 0.7966\n",
      "Epoch 78/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5991 - accuracy: 0.7932 - val_loss: 0.5627 - val_accuracy: 0.8071\n",
      "Epoch 79/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5932 - accuracy: 0.7952 - val_loss: 0.5776 - val_accuracy: 0.7980\n",
      "Epoch 80/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5840 - accuracy: 0.7977 - val_loss: 0.5849 - val_accuracy: 0.8000\n",
      "Epoch 81/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5865 - accuracy: 0.7979 - val_loss: 0.6011 - val_accuracy: 0.7952\n",
      "Epoch 82/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5785 - accuracy: 0.8007 - val_loss: 0.5536 - val_accuracy: 0.8100\n",
      "Epoch 83/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5776 - accuracy: 0.8018 - val_loss: 0.6086 - val_accuracy: 0.7931\n",
      "Epoch 84/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5725 - accuracy: 0.8029 - val_loss: 0.5407 - val_accuracy: 0.8173\n",
      "Epoch 85/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5746 - accuracy: 0.8021 - val_loss: 0.5555 - val_accuracy: 0.8114\n",
      "Epoch 86/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5717 - accuracy: 0.8035 - val_loss: 0.5443 - val_accuracy: 0.8153\n",
      "Epoch 87/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5712 - accuracy: 0.8030 - val_loss: 0.5227 - val_accuracy: 0.8215\n",
      "Epoch 88/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5663 - accuracy: 0.8045 - val_loss: 0.5383 - val_accuracy: 0.8189\n",
      "Epoch 89/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5594 - accuracy: 0.8064 - val_loss: 0.6261 - val_accuracy: 0.7911\n",
      "Epoch 90/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5634 - accuracy: 0.8045 - val_loss: 0.5588 - val_accuracy: 0.8120\n",
      "Epoch 91/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5537 - accuracy: 0.8081 - val_loss: 0.5335 - val_accuracy: 0.8187\n",
      "Epoch 92/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5558 - accuracy: 0.8065 - val_loss: 0.5174 - val_accuracy: 0.8230\n",
      "Epoch 93/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5498 - accuracy: 0.8103 - val_loss: 0.5725 - val_accuracy: 0.8056\n",
      "Epoch 94/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.5511 - accuracy: 0.8095 - val_loss: 0.5476 - val_accuracy: 0.8133\n",
      "Epoch 95/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5422 - accuracy: 0.8114 - val_loss: 0.6229 - val_accuracy: 0.7976\n",
      "Epoch 96/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5449 - accuracy: 0.8123 - val_loss: 0.5423 - val_accuracy: 0.8186\n",
      "Epoch 97/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5391 - accuracy: 0.8140 - val_loss: 0.5148 - val_accuracy: 0.8257\n",
      "Epoch 98/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5380 - accuracy: 0.8140 - val_loss: 0.4981 - val_accuracy: 0.8292\n",
      "Epoch 99/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5319 - accuracy: 0.8165 - val_loss: 0.5354 - val_accuracy: 0.8202\n",
      "Epoch 100/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5356 - accuracy: 0.8150 - val_loss: 0.5251 - val_accuracy: 0.8222\n",
      "Epoch 101/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5332 - accuracy: 0.8145 - val_loss: 0.5083 - val_accuracy: 0.8295\n",
      "Epoch 102/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5337 - accuracy: 0.8183 - val_loss: 0.5247 - val_accuracy: 0.8238\n",
      "Epoch 103/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5244 - accuracy: 0.8191 - val_loss: 0.5026 - val_accuracy: 0.8290\n",
      "Epoch 104/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5247 - accuracy: 0.8185 - val_loss: 0.5675 - val_accuracy: 0.8130\n",
      "Epoch 105/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5214 - accuracy: 0.8204 - val_loss: 0.4992 - val_accuracy: 0.8291\n",
      "Epoch 106/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5222 - accuracy: 0.8195 - val_loss: 0.4960 - val_accuracy: 0.8324\n",
      "Epoch 107/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5156 - accuracy: 0.8229 - val_loss: 0.5455 - val_accuracy: 0.8173\n",
      "Epoch 108/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5169 - accuracy: 0.8226 - val_loss: 0.4942 - val_accuracy: 0.8339\n",
      "Epoch 109/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5164 - accuracy: 0.8217 - val_loss: 0.4817 - val_accuracy: 0.8346\n",
      "Epoch 110/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5123 - accuracy: 0.8215 - val_loss: 0.5098 - val_accuracy: 0.8267\n",
      "Epoch 111/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5122 - accuracy: 0.8255 - val_loss: 0.4984 - val_accuracy: 0.8344\n",
      "Epoch 112/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5095 - accuracy: 0.8253 - val_loss: 0.4921 - val_accuracy: 0.8334\n",
      "Epoch 113/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5067 - accuracy: 0.8258 - val_loss: 0.4988 - val_accuracy: 0.8326\n",
      "Epoch 114/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5068 - accuracy: 0.8267 - val_loss: 0.5033 - val_accuracy: 0.8298\n",
      "Epoch 115/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5042 - accuracy: 0.8255 - val_loss: 0.4732 - val_accuracy: 0.8410\n",
      "Epoch 116/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4987 - accuracy: 0.8284 - val_loss: 0.5060 - val_accuracy: 0.8319\n",
      "Epoch 117/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4997 - accuracy: 0.8279 - val_loss: 0.5459 - val_accuracy: 0.8182\n",
      "Epoch 118/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4966 - accuracy: 0.8274 - val_loss: 0.5090 - val_accuracy: 0.8299\n",
      "Epoch 119/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5000 - accuracy: 0.8290 - val_loss: 0.4699 - val_accuracy: 0.8407\n",
      "Epoch 120/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4904 - accuracy: 0.8324 - val_loss: 0.5049 - val_accuracy: 0.8306\n",
      "Epoch 121/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4899 - accuracy: 0.8330 - val_loss: 0.4982 - val_accuracy: 0.8319\n",
      "Epoch 122/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4911 - accuracy: 0.8313 - val_loss: 0.5278 - val_accuracy: 0.8239\n",
      "Epoch 123/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4845 - accuracy: 0.8337 - val_loss: 0.5156 - val_accuracy: 0.8298\n",
      "Epoch 124/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4872 - accuracy: 0.8331 - val_loss: 0.5034 - val_accuracy: 0.8346\n",
      "Epoch 125/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4910 - accuracy: 0.8309 - val_loss: 0.4683 - val_accuracy: 0.8409\n",
      "Epoch 126/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4812 - accuracy: 0.8343 - val_loss: 0.4889 - val_accuracy: 0.8356\n",
      "Epoch 127/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4789 - accuracy: 0.8362 - val_loss: 0.5560 - val_accuracy: 0.8155\n",
      "Epoch 128/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4779 - accuracy: 0.8339 - val_loss: 0.4723 - val_accuracy: 0.8423\n",
      "Epoch 129/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4779 - accuracy: 0.8353 - val_loss: 0.4578 - val_accuracy: 0.8434\n",
      "Epoch 130/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4788 - accuracy: 0.8351 - val_loss: 0.4786 - val_accuracy: 0.8392\n",
      "Epoch 131/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4778 - accuracy: 0.8348 - val_loss: 0.4993 - val_accuracy: 0.8325\n",
      "Epoch 132/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4744 - accuracy: 0.8373 - val_loss: 0.4549 - val_accuracy: 0.8463\n",
      "Epoch 133/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4743 - accuracy: 0.8370 - val_loss: 0.4694 - val_accuracy: 0.8466\n",
      "Epoch 134/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4688 - accuracy: 0.8379 - val_loss: 0.5238 - val_accuracy: 0.8288\n",
      "Epoch 135/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4632 - accuracy: 0.8404 - val_loss: 0.5265 - val_accuracy: 0.8273\n",
      "Epoch 136/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4738 - accuracy: 0.8379 - val_loss: 0.4686 - val_accuracy: 0.8454\n",
      "Epoch 137/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4658 - accuracy: 0.8388 - val_loss: 0.4701 - val_accuracy: 0.8478\n",
      "Epoch 138/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4627 - accuracy: 0.8400 - val_loss: 0.4470 - val_accuracy: 0.8528\n",
      "Epoch 139/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4629 - accuracy: 0.8410 - val_loss: 0.4677 - val_accuracy: 0.8445\n",
      "Epoch 140/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4610 - accuracy: 0.8412 - val_loss: 0.4584 - val_accuracy: 0.8485\n",
      "Epoch 141/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4580 - accuracy: 0.8421 - val_loss: 0.4561 - val_accuracy: 0.8505\n",
      "Epoch 142/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4607 - accuracy: 0.8406 - val_loss: 0.4637 - val_accuracy: 0.8438\n",
      "Epoch 143/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4572 - accuracy: 0.8433 - val_loss: 0.4548 - val_accuracy: 0.8475\n",
      "Epoch 144/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4590 - accuracy: 0.8418 - val_loss: 0.4602 - val_accuracy: 0.8471\n",
      "Epoch 145/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4496 - accuracy: 0.8450 - val_loss: 0.4601 - val_accuracy: 0.8499\n",
      "Epoch 146/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4557 - accuracy: 0.8425 - val_loss: 0.5047 - val_accuracy: 0.8369\n",
      "Epoch 147/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4541 - accuracy: 0.8439 - val_loss: 0.4639 - val_accuracy: 0.8459\n",
      "Epoch 148/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4485 - accuracy: 0.8450 - val_loss: 0.4593 - val_accuracy: 0.8467\n",
      "Epoch 149/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4507 - accuracy: 0.8435 - val_loss: 0.4657 - val_accuracy: 0.8462\n",
      "Epoch 150/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4475 - accuracy: 0.8455 - val_loss: 0.4607 - val_accuracy: 0.8475\n",
      "Epoch 151/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4442 - accuracy: 0.8483 - val_loss: 0.4338 - val_accuracy: 0.8562\n",
      "Epoch 152/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4420 - accuracy: 0.8496 - val_loss: 0.4406 - val_accuracy: 0.8535\n",
      "Epoch 153/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4435 - accuracy: 0.8474 - val_loss: 0.5088 - val_accuracy: 0.8339\n",
      "Epoch 154/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.4435 - accuracy: 0.8473 - val_loss: 0.4362 - val_accuracy: 0.8538\n",
      "Epoch 155/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4374 - accuracy: 0.8504 - val_loss: 0.4711 - val_accuracy: 0.8456\n",
      "Epoch 156/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4351 - accuracy: 0.8500 - val_loss: 0.4460 - val_accuracy: 0.8525\n",
      "Epoch 157/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4396 - accuracy: 0.8477 - val_loss: 0.4635 - val_accuracy: 0.8450\n",
      "Epoch 158/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4356 - accuracy: 0.8506 - val_loss: 0.4380 - val_accuracy: 0.8572\n",
      "Epoch 159/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4322 - accuracy: 0.8510 - val_loss: 0.4363 - val_accuracy: 0.8581\n",
      "Epoch 160/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4362 - accuracy: 0.8508 - val_loss: 0.4570 - val_accuracy: 0.8485\n",
      "Epoch 161/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4330 - accuracy: 0.8499 - val_loss: 0.4539 - val_accuracy: 0.8513\n",
      "Epoch 162/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4367 - accuracy: 0.8512 - val_loss: 0.4370 - val_accuracy: 0.8557\n",
      "Epoch 163/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4312 - accuracy: 0.8512 - val_loss: 0.4360 - val_accuracy: 0.8567\n",
      "Epoch 164/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4262 - accuracy: 0.8539 - val_loss: 0.4572 - val_accuracy: 0.8517\n",
      "Epoch 165/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4270 - accuracy: 0.8531 - val_loss: 0.4463 - val_accuracy: 0.8523\n",
      "Epoch 166/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4226 - accuracy: 0.8550 - val_loss: 0.4361 - val_accuracy: 0.8549\n",
      "Epoch 167/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4302 - accuracy: 0.8514 - val_loss: 0.4314 - val_accuracy: 0.8565\n",
      "Epoch 168/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4249 - accuracy: 0.8536 - val_loss: 0.4454 - val_accuracy: 0.8545\n",
      "Epoch 169/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4227 - accuracy: 0.8559 - val_loss: 0.4329 - val_accuracy: 0.8540\n",
      "Epoch 170/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4228 - accuracy: 0.8529 - val_loss: 0.4840 - val_accuracy: 0.8425\n",
      "Epoch 171/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4172 - accuracy: 0.8562 - val_loss: 0.4438 - val_accuracy: 0.8551\n",
      "Epoch 172/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4227 - accuracy: 0.8543 - val_loss: 0.4278 - val_accuracy: 0.8591\n",
      "Epoch 173/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4179 - accuracy: 0.8562 - val_loss: 0.4385 - val_accuracy: 0.8563\n",
      "Epoch 174/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4143 - accuracy: 0.8567 - val_loss: 0.4233 - val_accuracy: 0.8592\n",
      "Epoch 175/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4129 - accuracy: 0.8575 - val_loss: 0.4362 - val_accuracy: 0.8583\n",
      "Epoch 176/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4176 - accuracy: 0.8563 - val_loss: 0.4441 - val_accuracy: 0.8543\n",
      "Epoch 177/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4170 - accuracy: 0.8564 - val_loss: 0.4488 - val_accuracy: 0.8563\n",
      "Epoch 178/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4101 - accuracy: 0.8584 - val_loss: 0.4505 - val_accuracy: 0.8544\n",
      "Epoch 179/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4141 - accuracy: 0.8567 - val_loss: 0.4258 - val_accuracy: 0.8612\n",
      "Epoch 180/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4122 - accuracy: 0.8571 - val_loss: 0.4270 - val_accuracy: 0.8579\n",
      "Epoch 181/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4114 - accuracy: 0.8587 - val_loss: 0.4343 - val_accuracy: 0.8584\n",
      "Epoch 182/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4057 - accuracy: 0.8599 - val_loss: 0.4312 - val_accuracy: 0.8571\n",
      "Epoch 183/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4134 - accuracy: 0.8587 - val_loss: 0.4315 - val_accuracy: 0.8600\n",
      "Epoch 184/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4045 - accuracy: 0.8602 - val_loss: 0.4586 - val_accuracy: 0.8510\n",
      "Epoch 185/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4042 - accuracy: 0.8606 - val_loss: 0.4179 - val_accuracy: 0.8634\n",
      "Epoch 186/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4015 - accuracy: 0.8613 - val_loss: 0.4446 - val_accuracy: 0.8556\n",
      "Epoch 187/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4064 - accuracy: 0.8598 - val_loss: 0.4464 - val_accuracy: 0.8519\n",
      "Epoch 188/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3999 - accuracy: 0.8608 - val_loss: 0.4118 - val_accuracy: 0.8638\n",
      "Epoch 189/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4000 - accuracy: 0.8637 - val_loss: 0.4130 - val_accuracy: 0.8652\n",
      "Epoch 190/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4009 - accuracy: 0.8615 - val_loss: 0.4187 - val_accuracy: 0.8637\n",
      "Epoch 191/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4029 - accuracy: 0.8610 - val_loss: 0.4119 - val_accuracy: 0.8640\n",
      "Epoch 192/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4006 - accuracy: 0.8624 - val_loss: 0.4295 - val_accuracy: 0.8609\n",
      "Epoch 193/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4005 - accuracy: 0.8631 - val_loss: 0.4229 - val_accuracy: 0.8639\n",
      "Epoch 194/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3958 - accuracy: 0.8641 - val_loss: 0.4125 - val_accuracy: 0.8675\n",
      "Epoch 195/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3980 - accuracy: 0.8618 - val_loss: 0.4315 - val_accuracy: 0.8619\n",
      "Epoch 196/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3942 - accuracy: 0.8648 - val_loss: 0.4328 - val_accuracy: 0.8607\n",
      "Epoch 197/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3975 - accuracy: 0.8632 - val_loss: 0.4239 - val_accuracy: 0.8588\n",
      "Epoch 198/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3944 - accuracy: 0.8642 - val_loss: 0.4123 - val_accuracy: 0.8668\n",
      "Epoch 199/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3898 - accuracy: 0.8649 - val_loss: 0.4331 - val_accuracy: 0.8576\n",
      "Epoch 200/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3873 - accuracy: 0.8666 - val_loss: 0.4129 - val_accuracy: 0.8645\n",
      "Epoch 201/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3934 - accuracy: 0.8646 - val_loss: 0.4265 - val_accuracy: 0.8618\n",
      "Epoch 202/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3837 - accuracy: 0.8689 - val_loss: 0.4003 - val_accuracy: 0.8664\n",
      "Epoch 203/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3893 - accuracy: 0.8667 - val_loss: 0.4147 - val_accuracy: 0.8650\n",
      "Epoch 204/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3887 - accuracy: 0.8656 - val_loss: 0.4759 - val_accuracy: 0.8482\n",
      "Epoch 205/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3886 - accuracy: 0.8648 - val_loss: 0.4409 - val_accuracy: 0.8566\n",
      "Epoch 206/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3866 - accuracy: 0.8675 - val_loss: 0.4340 - val_accuracy: 0.8606\n",
      "Epoch 207/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3849 - accuracy: 0.8691 - val_loss: 0.3989 - val_accuracy: 0.8679\n",
      "Epoch 208/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3847 - accuracy: 0.8686 - val_loss: 0.4334 - val_accuracy: 0.8597\n",
      "Epoch 209/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3808 - accuracy: 0.8692 - val_loss: 0.4248 - val_accuracy: 0.8611\n",
      "Epoch 210/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3833 - accuracy: 0.8675 - val_loss: 0.4281 - val_accuracy: 0.8623\n",
      "Epoch 211/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3832 - accuracy: 0.8686 - val_loss: 0.4098 - val_accuracy: 0.8690\n",
      "Epoch 212/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3856 - accuracy: 0.8676 - val_loss: 0.4500 - val_accuracy: 0.8559\n",
      "Epoch 213/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3777 - accuracy: 0.8684 - val_loss: 0.4151 - val_accuracy: 0.8638\n",
      "Epoch 214/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3827 - accuracy: 0.8680 - val_loss: 0.4424 - val_accuracy: 0.8602\n",
      "Epoch 215/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3800 - accuracy: 0.8680 - val_loss: 0.4138 - val_accuracy: 0.8653\n",
      "Epoch 216/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3793 - accuracy: 0.8696 - val_loss: 0.4243 - val_accuracy: 0.8624\n",
      "Epoch 217/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3787 - accuracy: 0.8689 - val_loss: 0.4109 - val_accuracy: 0.8660\n",
      "Epoch 218/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3758 - accuracy: 0.8703 - val_loss: 0.4142 - val_accuracy: 0.8669\n",
      "Epoch 219/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3772 - accuracy: 0.8708 - val_loss: 0.4225 - val_accuracy: 0.8609\n",
      "Epoch 220/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3769 - accuracy: 0.8708 - val_loss: 0.4382 - val_accuracy: 0.8609\n",
      "Epoch 221/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3753 - accuracy: 0.8710 - val_loss: 0.4007 - val_accuracy: 0.8683\n",
      "Epoch 222/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3684 - accuracy: 0.8725 - val_loss: 0.4167 - val_accuracy: 0.8617\n",
      "Epoch 223/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3705 - accuracy: 0.8732 - val_loss: 0.4173 - val_accuracy: 0.8665\n",
      "Epoch 224/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3706 - accuracy: 0.8726 - val_loss: 0.4113 - val_accuracy: 0.8676\n",
      "Epoch 225/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3695 - accuracy: 0.8730 - val_loss: 0.4065 - val_accuracy: 0.8666\n",
      "Epoch 226/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3697 - accuracy: 0.8713 - val_loss: 0.3965 - val_accuracy: 0.8715\n",
      "Epoch 227/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3663 - accuracy: 0.8744 - val_loss: 0.4076 - val_accuracy: 0.8696\n",
      "Epoch 228/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3705 - accuracy: 0.8722 - val_loss: 0.3958 - val_accuracy: 0.8702\n",
      "Epoch 229/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3705 - accuracy: 0.8729 - val_loss: 0.4106 - val_accuracy: 0.8649\n",
      "Epoch 230/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3652 - accuracy: 0.8734 - val_loss: 0.4097 - val_accuracy: 0.8696\n",
      "Epoch 231/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3638 - accuracy: 0.8744 - val_loss: 0.3936 - val_accuracy: 0.8688\n",
      "Epoch 232/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3668 - accuracy: 0.8736 - val_loss: 0.4001 - val_accuracy: 0.8710\n",
      "Epoch 233/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3615 - accuracy: 0.8750 - val_loss: 0.3966 - val_accuracy: 0.8725\n",
      "Epoch 234/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3625 - accuracy: 0.8749 - val_loss: 0.4190 - val_accuracy: 0.8672\n",
      "Epoch 235/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3680 - accuracy: 0.8740 - val_loss: 0.3997 - val_accuracy: 0.8713\n",
      "Epoch 236/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3668 - accuracy: 0.8737 - val_loss: 0.4051 - val_accuracy: 0.8698\n",
      "Epoch 237/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3631 - accuracy: 0.8761 - val_loss: 0.4373 - val_accuracy: 0.8628\n",
      "Epoch 238/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3563 - accuracy: 0.8773 - val_loss: 0.4243 - val_accuracy: 0.8652\n",
      "Epoch 239/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3600 - accuracy: 0.8760 - val_loss: 0.4214 - val_accuracy: 0.8680\n",
      "Epoch 240/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3563 - accuracy: 0.8775 - val_loss: 0.3951 - val_accuracy: 0.8736\n",
      "Epoch 241/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3603 - accuracy: 0.8756 - val_loss: 0.4252 - val_accuracy: 0.8642\n",
      "Epoch 242/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3585 - accuracy: 0.8756 - val_loss: 0.3889 - val_accuracy: 0.8714\n",
      "Epoch 243/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3582 - accuracy: 0.8763 - val_loss: 0.4112 - val_accuracy: 0.8669\n",
      "Epoch 244/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3551 - accuracy: 0.8786 - val_loss: 0.4014 - val_accuracy: 0.8711\n",
      "Epoch 245/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3556 - accuracy: 0.8772 - val_loss: 0.4070 - val_accuracy: 0.8692\n",
      "Epoch 246/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3602 - accuracy: 0.8759 - val_loss: 0.4125 - val_accuracy: 0.8662\n",
      "Epoch 247/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3537 - accuracy: 0.8767 - val_loss: 0.4222 - val_accuracy: 0.8650\n",
      "Epoch 248/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3555 - accuracy: 0.8762 - val_loss: 0.4218 - val_accuracy: 0.8658\n",
      "Epoch 249/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3528 - accuracy: 0.8775 - val_loss: 0.3969 - val_accuracy: 0.8717\n",
      "Epoch 250/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3534 - accuracy: 0.8776 - val_loss: 0.4367 - val_accuracy: 0.8644\n",
      "Epoch 251/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3484 - accuracy: 0.8791 - val_loss: 0.4182 - val_accuracy: 0.8670\n",
      "Epoch 252/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3531 - accuracy: 0.8781 - val_loss: 0.4226 - val_accuracy: 0.8684\n",
      "Epoch 253/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3571 - accuracy: 0.8795 - val_loss: 0.3930 - val_accuracy: 0.8738\n",
      "Epoch 254/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3512 - accuracy: 0.8786 - val_loss: 0.3964 - val_accuracy: 0.8707\n",
      "Epoch 255/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3479 - accuracy: 0.8802 - val_loss: 0.4071 - val_accuracy: 0.8703\n",
      "Epoch 256/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3464 - accuracy: 0.8808 - val_loss: 0.4059 - val_accuracy: 0.8712\n",
      "Epoch 257/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3470 - accuracy: 0.8795 - val_loss: 0.3966 - val_accuracy: 0.8717\n",
      "Epoch 258/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3456 - accuracy: 0.8803 - val_loss: 0.4009 - val_accuracy: 0.8737\n",
      "Epoch 259/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3490 - accuracy: 0.8793 - val_loss: 0.3944 - val_accuracy: 0.8754\n",
      "Epoch 260/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3458 - accuracy: 0.8817 - val_loss: 0.4478 - val_accuracy: 0.8619\n",
      "Epoch 261/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3448 - accuracy: 0.8809 - val_loss: 0.3959 - val_accuracy: 0.8740\n",
      "Epoch 262/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3456 - accuracy: 0.8807 - val_loss: 0.4274 - val_accuracy: 0.8640\n",
      "Epoch 263/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3469 - accuracy: 0.8802 - val_loss: 0.4041 - val_accuracy: 0.8710\n",
      "Epoch 264/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3461 - accuracy: 0.8795 - val_loss: 0.4049 - val_accuracy: 0.8721\n",
      "Epoch 265/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3397 - accuracy: 0.8829 - val_loss: 0.4058 - val_accuracy: 0.8678\n",
      "Epoch 266/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3453 - accuracy: 0.8816 - val_loss: 0.4054 - val_accuracy: 0.8723\n",
      "Epoch 267/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3362 - accuracy: 0.8848 - val_loss: 0.4196 - val_accuracy: 0.8673\n",
      "Epoch 268/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3396 - accuracy: 0.8837 - val_loss: 0.3934 - val_accuracy: 0.8745\n",
      "Epoch 269/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3409 - accuracy: 0.8810 - val_loss: 0.4091 - val_accuracy: 0.8720\n",
      "Epoch 270/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3415 - accuracy: 0.8832 - val_loss: 0.3944 - val_accuracy: 0.8764\n",
      "Epoch 271/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3382 - accuracy: 0.8828 - val_loss: 0.3893 - val_accuracy: 0.8743\n",
      "Epoch 272/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3388 - accuracy: 0.8836 - val_loss: 0.3821 - val_accuracy: 0.8787\n",
      "Epoch 273/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3406 - accuracy: 0.8841 - val_loss: 0.4145 - val_accuracy: 0.8681\n",
      "Epoch 274/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 0.4154 - val_accuracy: 0.8697\n",
      "Epoch 275/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3378 - accuracy: 0.8835 - val_loss: 0.3914 - val_accuracy: 0.8759\n",
      "Epoch 276/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3410 - accuracy: 0.8817 - val_loss: 0.3887 - val_accuracy: 0.8775\n",
      "Epoch 277/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3378 - accuracy: 0.8836 - val_loss: 0.3865 - val_accuracy: 0.8771\n",
      "Epoch 278/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3426 - accuracy: 0.8822 - val_loss: 0.4103 - val_accuracy: 0.8729\n",
      "Epoch 279/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3328 - accuracy: 0.8868 - val_loss: 0.4137 - val_accuracy: 0.8701\n",
      "Epoch 280/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3353 - accuracy: 0.8841 - val_loss: 0.3960 - val_accuracy: 0.8760\n",
      "Epoch 281/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3295 - accuracy: 0.8859 - val_loss: 0.3892 - val_accuracy: 0.8763\n",
      "Epoch 282/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3355 - accuracy: 0.8843 - val_loss: 0.4087 - val_accuracy: 0.8698\n",
      "Epoch 283/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3317 - accuracy: 0.8858 - val_loss: 0.3973 - val_accuracy: 0.8768\n",
      "Epoch 284/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3301 - accuracy: 0.8879 - val_loss: 0.3986 - val_accuracy: 0.8748\n",
      "Epoch 285/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3272 - accuracy: 0.8869 - val_loss: 0.3843 - val_accuracy: 0.8762\n",
      "Epoch 286/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3336 - accuracy: 0.8859 - val_loss: 0.3842 - val_accuracy: 0.8759\n",
      "Epoch 287/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3296 - accuracy: 0.8855 - val_loss: 0.3784 - val_accuracy: 0.8788\n",
      "Epoch 288/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3323 - accuracy: 0.8872 - val_loss: 0.4082 - val_accuracy: 0.8709\n",
      "Epoch 289/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3292 - accuracy: 0.8851 - val_loss: 0.3859 - val_accuracy: 0.8740\n",
      "Epoch 290/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3293 - accuracy: 0.8861 - val_loss: 0.4016 - val_accuracy: 0.8734\n",
      "Epoch 291/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3285 - accuracy: 0.8874 - val_loss: 0.3988 - val_accuracy: 0.8727\n",
      "Epoch 292/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3281 - accuracy: 0.8872 - val_loss: 0.4188 - val_accuracy: 0.8703\n",
      "Epoch 293/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3320 - accuracy: 0.8858 - val_loss: 0.3726 - val_accuracy: 0.8781\n",
      "Epoch 294/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3291 - accuracy: 0.8865 - val_loss: 0.3944 - val_accuracy: 0.8751\n",
      "Epoch 295/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3270 - accuracy: 0.8878 - val_loss: 0.4053 - val_accuracy: 0.8709\n",
      "Epoch 296/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3269 - accuracy: 0.8883 - val_loss: 0.3947 - val_accuracy: 0.8747\n",
      "Epoch 297/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3247 - accuracy: 0.8867 - val_loss: 0.4012 - val_accuracy: 0.8728\n",
      "Epoch 298/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3245 - accuracy: 0.8873 - val_loss: 0.3798 - val_accuracy: 0.8775\n",
      "Epoch 299/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3267 - accuracy: 0.8881 - val_loss: 0.3979 - val_accuracy: 0.8746\n",
      "Epoch 300/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3189 - accuracy: 0.8894 - val_loss: 0.3964 - val_accuracy: 0.8774\n",
      "Epoch 301/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3215 - accuracy: 0.8895 - val_loss: 0.3758 - val_accuracy: 0.8791\n",
      "Epoch 302/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3254 - accuracy: 0.8887 - val_loss: 0.3925 - val_accuracy: 0.8756\n",
      "Epoch 303/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3197 - accuracy: 0.8892 - val_loss: 0.4054 - val_accuracy: 0.8741\n",
      "Epoch 304/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3197 - accuracy: 0.8904 - val_loss: 0.4048 - val_accuracy: 0.8725\n",
      "Epoch 305/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3223 - accuracy: 0.8867 - val_loss: 0.3931 - val_accuracy: 0.8800\n",
      "Epoch 306/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3234 - accuracy: 0.8876 - val_loss: 0.4007 - val_accuracy: 0.8736\n",
      "Epoch 307/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3218 - accuracy: 0.8889 - val_loss: 0.3947 - val_accuracy: 0.8764\n",
      "Epoch 308/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3143 - accuracy: 0.8920 - val_loss: 0.4025 - val_accuracy: 0.8744\n",
      "Epoch 309/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3205 - accuracy: 0.8885 - val_loss: 0.3989 - val_accuracy: 0.8752\n",
      "Epoch 310/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3215 - accuracy: 0.8884 - val_loss: 0.3974 - val_accuracy: 0.8760\n",
      "Epoch 311/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3167 - accuracy: 0.8908 - val_loss: 0.3775 - val_accuracy: 0.8802\n",
      "Epoch 312/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3155 - accuracy: 0.8915 - val_loss: 0.3799 - val_accuracy: 0.8818\n",
      "Epoch 313/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3174 - accuracy: 0.8905 - val_loss: 0.3793 - val_accuracy: 0.8790\n",
      "Epoch 314/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3160 - accuracy: 0.8918 - val_loss: 0.4115 - val_accuracy: 0.8736\n",
      "Epoch 315/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3164 - accuracy: 0.8901 - val_loss: 0.4206 - val_accuracy: 0.8686\n",
      "Epoch 316/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3156 - accuracy: 0.8909 - val_loss: 0.3907 - val_accuracy: 0.8743\n",
      "Epoch 317/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3140 - accuracy: 0.8900 - val_loss: 0.3720 - val_accuracy: 0.8802\n",
      "Epoch 318/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3152 - accuracy: 0.8908 - val_loss: 0.3615 - val_accuracy: 0.8826\n",
      "Epoch 319/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3142 - accuracy: 0.8932 - val_loss: 0.3711 - val_accuracy: 0.8808\n",
      "Epoch 320/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3086 - accuracy: 0.8934 - val_loss: 0.3765 - val_accuracy: 0.8795\n",
      "Epoch 321/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3154 - accuracy: 0.8905 - val_loss: 0.3966 - val_accuracy: 0.8759\n",
      "Epoch 322/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3134 - accuracy: 0.8920 - val_loss: 0.3844 - val_accuracy: 0.8789\n",
      "Epoch 323/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3109 - accuracy: 0.8923 - val_loss: 0.3659 - val_accuracy: 0.8846\n",
      "Epoch 324/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3108 - accuracy: 0.8924 - val_loss: 0.3988 - val_accuracy: 0.8771\n",
      "Epoch 325/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3112 - accuracy: 0.8920 - val_loss: 0.3746 - val_accuracy: 0.8819\n",
      "Epoch 326/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3152 - accuracy: 0.8911 - val_loss: 0.3916 - val_accuracy: 0.8784\n",
      "Epoch 327/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3106 - accuracy: 0.8930 - val_loss: 0.3836 - val_accuracy: 0.8821\n",
      "Epoch 328/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3112 - accuracy: 0.8920 - val_loss: 0.4163 - val_accuracy: 0.8707\n",
      "Epoch 329/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3112 - accuracy: 0.8931 - val_loss: 0.3707 - val_accuracy: 0.8821\n",
      "Epoch 330/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3052 - accuracy: 0.8944 - val_loss: 0.3845 - val_accuracy: 0.8793\n",
      "Epoch 331/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3092 - accuracy: 0.8925 - val_loss: 0.3778 - val_accuracy: 0.8803\n",
      "Epoch 332/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3086 - accuracy: 0.8918 - val_loss: 0.3743 - val_accuracy: 0.8813\n",
      "Epoch 333/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3108 - accuracy: 0.8915 - val_loss: 0.4281 - val_accuracy: 0.8677\n",
      "Epoch 334/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3055 - accuracy: 0.8943 - val_loss: 0.3669 - val_accuracy: 0.8844\n",
      "Epoch 335/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3031 - accuracy: 0.8951 - val_loss: 0.3925 - val_accuracy: 0.8789\n",
      "Epoch 336/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3047 - accuracy: 0.8946 - val_loss: 0.3769 - val_accuracy: 0.8823\n",
      "Epoch 337/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3117 - accuracy: 0.8915 - val_loss: 0.3865 - val_accuracy: 0.8769\n",
      "Epoch 338/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3048 - accuracy: 0.8964 - val_loss: 0.3729 - val_accuracy: 0.8804\n",
      "Epoch 339/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3061 - accuracy: 0.8944 - val_loss: 0.3672 - val_accuracy: 0.8831\n",
      "Epoch 340/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3054 - accuracy: 0.8944 - val_loss: 0.3794 - val_accuracy: 0.8810\n",
      "Epoch 341/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3020 - accuracy: 0.8954 - val_loss: 0.3935 - val_accuracy: 0.8781\n",
      "Epoch 342/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3073 - accuracy: 0.8921 - val_loss: 0.3808 - val_accuracy: 0.8809\n",
      "Epoch 343/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3050 - accuracy: 0.8941 - val_loss: 0.3598 - val_accuracy: 0.8833\n",
      "Epoch 344/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3051 - accuracy: 0.8943 - val_loss: 0.3983 - val_accuracy: 0.8733\n",
      "Epoch 345/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2989 - accuracy: 0.8966 - val_loss: 0.3910 - val_accuracy: 0.8785\n",
      "Epoch 346/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3035 - accuracy: 0.8941 - val_loss: 0.3755 - val_accuracy: 0.8812\n",
      "Epoch 347/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3033 - accuracy: 0.8945 - val_loss: 0.3799 - val_accuracy: 0.8820\n",
      "Epoch 348/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3074 - accuracy: 0.8951 - val_loss: 0.4034 - val_accuracy: 0.8744\n",
      "Epoch 349/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3045 - accuracy: 0.8946 - val_loss: 0.3812 - val_accuracy: 0.8801\n",
      "Epoch 350/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3013 - accuracy: 0.8947 - val_loss: 0.3657 - val_accuracy: 0.8843\n",
      "Epoch 351/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3019 - accuracy: 0.8964 - val_loss: 0.3861 - val_accuracy: 0.8776\n",
      "Epoch 352/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3025 - accuracy: 0.8953 - val_loss: 0.3686 - val_accuracy: 0.8840\n",
      "Epoch 353/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.3012 - accuracy: 0.8970 - val_loss: 0.3847 - val_accuracy: 0.8801\n",
      "Epoch 354/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2969 - accuracy: 0.8979 - val_loss: 0.3795 - val_accuracy: 0.8817\n",
      "Epoch 355/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3023 - accuracy: 0.8962 - val_loss: 0.3846 - val_accuracy: 0.8775\n",
      "Epoch 356/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2994 - accuracy: 0.8960 - val_loss: 0.3911 - val_accuracy: 0.8756\n",
      "Epoch 357/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2981 - accuracy: 0.8966 - val_loss: 0.3761 - val_accuracy: 0.8833\n",
      "Epoch 358/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2973 - accuracy: 0.8968 - val_loss: 0.4039 - val_accuracy: 0.8719\n",
      "Epoch 359/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2985 - accuracy: 0.8956 - val_loss: 0.3693 - val_accuracy: 0.8841\n",
      "Epoch 360/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2963 - accuracy: 0.8969 - val_loss: 0.4252 - val_accuracy: 0.8703\n",
      "Epoch 361/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2969 - accuracy: 0.8980 - val_loss: 0.3725 - val_accuracy: 0.8838\n",
      "Epoch 362/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2955 - accuracy: 0.8969 - val_loss: 0.3768 - val_accuracy: 0.8819\n",
      "Epoch 363/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2925 - accuracy: 0.8988 - val_loss: 0.3975 - val_accuracy: 0.8755\n",
      "Epoch 364/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2977 - accuracy: 0.8980 - val_loss: 0.3709 - val_accuracy: 0.8839\n",
      "Epoch 365/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2986 - accuracy: 0.8956 - val_loss: 0.3655 - val_accuracy: 0.8852\n",
      "Epoch 366/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2952 - accuracy: 0.8971 - val_loss: 0.3564 - val_accuracy: 0.8896\n",
      "Epoch 367/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3003 - accuracy: 0.8960 - val_loss: 0.4063 - val_accuracy: 0.8746\n",
      "Epoch 368/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2953 - accuracy: 0.8980 - val_loss: 0.3652 - val_accuracy: 0.8836\n",
      "Epoch 369/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2897 - accuracy: 0.8987 - val_loss: 0.3660 - val_accuracy: 0.8830\n",
      "Epoch 370/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2903 - accuracy: 0.9006 - val_loss: 0.3985 - val_accuracy: 0.8733\n",
      "Epoch 371/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2931 - accuracy: 0.8985 - val_loss: 0.3873 - val_accuracy: 0.8766\n",
      "Epoch 372/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2929 - accuracy: 0.8982 - val_loss: 0.3786 - val_accuracy: 0.8836\n",
      "Epoch 373/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2928 - accuracy: 0.8998 - val_loss: 0.3753 - val_accuracy: 0.8843\n",
      "Epoch 374/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2902 - accuracy: 0.8998 - val_loss: 0.3987 - val_accuracy: 0.8742\n",
      "Epoch 375/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2905 - accuracy: 0.8998 - val_loss: 0.3787 - val_accuracy: 0.8804\n",
      "Epoch 376/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2890 - accuracy: 0.9008 - val_loss: 0.3852 - val_accuracy: 0.8786\n",
      "Epoch 377/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2876 - accuracy: 0.9014 - val_loss: 0.3670 - val_accuracy: 0.8836\n",
      "Epoch 378/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.2902 - accuracy: 0.8994 - val_loss: 0.3732 - val_accuracy: 0.8854\n",
      "Epoch 379/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2907 - accuracy: 0.8998 - val_loss: 0.3747 - val_accuracy: 0.8846\n",
      "Epoch 380/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2900 - accuracy: 0.8996 - val_loss: 0.3744 - val_accuracy: 0.8844\n",
      "Epoch 381/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2933 - accuracy: 0.8993 - val_loss: 0.4106 - val_accuracy: 0.8735\n",
      "Epoch 382/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2876 - accuracy: 0.9015 - val_loss: 0.3678 - val_accuracy: 0.8860\n",
      "Epoch 383/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2837 - accuracy: 0.9006 - val_loss: 0.3710 - val_accuracy: 0.8862\n",
      "Epoch 384/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2859 - accuracy: 0.9014 - val_loss: 0.3803 - val_accuracy: 0.8793\n",
      "Epoch 385/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2857 - accuracy: 0.9009 - val_loss: 0.3897 - val_accuracy: 0.8797\n",
      "Epoch 386/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2884 - accuracy: 0.9010 - val_loss: 0.3725 - val_accuracy: 0.8863\n",
      "Epoch 387/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2878 - accuracy: 0.9002 - val_loss: 0.3632 - val_accuracy: 0.8866\n",
      "Epoch 388/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2869 - accuracy: 0.9008 - val_loss: 0.3834 - val_accuracy: 0.8809\n",
      "Epoch 389/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2869 - accuracy: 0.9025 - val_loss: 0.3905 - val_accuracy: 0.8767\n",
      "Epoch 390/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2836 - accuracy: 0.9019 - val_loss: 0.3700 - val_accuracy: 0.8857\n",
      "Epoch 391/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2807 - accuracy: 0.9022 - val_loss: 0.3886 - val_accuracy: 0.8805\n",
      "Epoch 392/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2844 - accuracy: 0.9017 - val_loss: 0.3705 - val_accuracy: 0.8836\n",
      "Epoch 393/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2836 - accuracy: 0.9028 - val_loss: 0.3647 - val_accuracy: 0.8887\n",
      "Epoch 394/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2846 - accuracy: 0.9022 - val_loss: 0.3855 - val_accuracy: 0.8816\n",
      "Epoch 395/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2886 - accuracy: 0.8996 - val_loss: 0.3733 - val_accuracy: 0.8864\n",
      "Epoch 396/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2836 - accuracy: 0.9019 - val_loss: 0.3824 - val_accuracy: 0.8814\n",
      "Epoch 397/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2835 - accuracy: 0.9027 - val_loss: 0.3861 - val_accuracy: 0.8778\n",
      "Epoch 398/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2848 - accuracy: 0.9006 - val_loss: 0.3577 - val_accuracy: 0.8890\n",
      "Epoch 399/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2876 - accuracy: 0.9003 - val_loss: 0.3675 - val_accuracy: 0.8872\n",
      "Epoch 400/400\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.2800 - accuracy: 0.9029 - val_loss: 0.3871 - val_accuracy: 0.8788\n",
      "\n",
      "Forming the grid-search model #1 using: optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28fc29b1d0>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f28fc248a20>, epochs=400, batch_size=64\n",
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.8009 - accuracy: 0.3859 - val_loss: 1.3289 - val_accuracy: 0.5265\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.2571 - accuracy: 0.5498 - val_loss: 0.9907 - val_accuracy: 0.6523\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.0648 - accuracy: 0.6226 - val_loss: 1.0878 - val_accuracy: 0.6290\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.9510 - accuracy: 0.6652 - val_loss: 0.7803 - val_accuracy: 0.7283\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8774 - accuracy: 0.6951 - val_loss: 0.7837 - val_accuracy: 0.7231\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8252 - accuracy: 0.7136 - val_loss: 0.8125 - val_accuracy: 0.7156\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7800 - accuracy: 0.7326 - val_loss: 0.6716 - val_accuracy: 0.7683\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7392 - accuracy: 0.7450 - val_loss: 0.6390 - val_accuracy: 0.7791\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6951 - accuracy: 0.7619 - val_loss: 0.6644 - val_accuracy: 0.7726\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6715 - accuracy: 0.7710 - val_loss: 0.5878 - val_accuracy: 0.7996\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6493 - accuracy: 0.7778 - val_loss: 0.6832 - val_accuracy: 0.7702\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6236 - accuracy: 0.7885 - val_loss: 0.5873 - val_accuracy: 0.7972\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6063 - accuracy: 0.7931 - val_loss: 0.5879 - val_accuracy: 0.7980\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5908 - accuracy: 0.7981 - val_loss: 0.5299 - val_accuracy: 0.8207\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5753 - accuracy: 0.8052 - val_loss: 0.5166 - val_accuracy: 0.8238\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5586 - accuracy: 0.8097 - val_loss: 0.5281 - val_accuracy: 0.8237\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.5484 - accuracy: 0.8126 - val_loss: 0.5435 - val_accuracy: 0.8188\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.5368 - accuracy: 0.8166 - val_loss: 0.4974 - val_accuracy: 0.8333\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5291 - accuracy: 0.8191 - val_loss: 0.4726 - val_accuracy: 0.8420\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5163 - accuracy: 0.8247 - val_loss: 0.4937 - val_accuracy: 0.8351\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.5053 - accuracy: 0.8295 - val_loss: 0.5070 - val_accuracy: 0.8278\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4980 - accuracy: 0.8301 - val_loss: 0.4335 - val_accuracy: 0.8541\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4901 - accuracy: 0.8341 - val_loss: 0.4962 - val_accuracy: 0.8344\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4800 - accuracy: 0.8370 - val_loss: 0.5042 - val_accuracy: 0.8305\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.4751 - accuracy: 0.8370 - val_loss: 0.4439 - val_accuracy: 0.8485\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4708 - accuracy: 0.8406 - val_loss: 0.4872 - val_accuracy: 0.8408\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4627 - accuracy: 0.8433 - val_loss: 0.4210 - val_accuracy: 0.8577\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4561 - accuracy: 0.8430 - val_loss: 0.4602 - val_accuracy: 0.8483\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4457 - accuracy: 0.8483 - val_loss: 0.4541 - val_accuracy: 0.8512\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4468 - accuracy: 0.8497 - val_loss: 0.4592 - val_accuracy: 0.8506\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4388 - accuracy: 0.8511 - val_loss: 0.5220 - val_accuracy: 0.8308\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4330 - accuracy: 0.8526 - val_loss: 0.5618 - val_accuracy: 0.8179\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4353 - accuracy: 0.8528 - val_loss: 0.4050 - val_accuracy: 0.8658\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4277 - accuracy: 0.8552 - val_loss: 0.4689 - val_accuracy: 0.8485\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.4218 - accuracy: 0.8570 - val_loss: 0.4662 - val_accuracy: 0.8473\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4134 - accuracy: 0.8580 - val_loss: 0.4309 - val_accuracy: 0.8545\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4136 - accuracy: 0.8589 - val_loss: 0.4650 - val_accuracy: 0.8499\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4094 - accuracy: 0.8613 - val_loss: 0.3933 - val_accuracy: 0.8663\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.4064 - accuracy: 0.8606 - val_loss: 0.4799 - val_accuracy: 0.8437\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3997 - accuracy: 0.8636 - val_loss: 0.4210 - val_accuracy: 0.8620\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3916 - accuracy: 0.8649 - val_loss: 0.4362 - val_accuracy: 0.8556\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3934 - accuracy: 0.8656 - val_loss: 0.4037 - val_accuracy: 0.8645\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3905 - accuracy: 0.8659 - val_loss: 0.4028 - val_accuracy: 0.8675\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3920 - accuracy: 0.8661 - val_loss: 0.3744 - val_accuracy: 0.8776\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3840 - accuracy: 0.8705 - val_loss: 0.3872 - val_accuracy: 0.8715\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3833 - accuracy: 0.8694 - val_loss: 0.3771 - val_accuracy: 0.8754\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3821 - accuracy: 0.8705 - val_loss: 0.4554 - val_accuracy: 0.8521\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3740 - accuracy: 0.8716 - val_loss: 0.3996 - val_accuracy: 0.8698\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3711 - accuracy: 0.8746 - val_loss: 0.4717 - val_accuracy: 0.8514\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3717 - accuracy: 0.8717 - val_loss: 0.4108 - val_accuracy: 0.8637\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3668 - accuracy: 0.8741 - val_loss: 0.4194 - val_accuracy: 0.8625\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3707 - accuracy: 0.8741 - val_loss: 0.3784 - val_accuracy: 0.8761\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3665 - accuracy: 0.8746 - val_loss: 0.3894 - val_accuracy: 0.8718\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3658 - accuracy: 0.8763 - val_loss: 0.4180 - val_accuracy: 0.8652\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3611 - accuracy: 0.8761 - val_loss: 0.3756 - val_accuracy: 0.8775\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3585 - accuracy: 0.8763 - val_loss: 0.3883 - val_accuracy: 0.8718\n",
      "Epoch 57/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3544 - accuracy: 0.8806 - val_loss: 0.3924 - val_accuracy: 0.8690\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3534 - accuracy: 0.8792 - val_loss: 0.4002 - val_accuracy: 0.8670\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3490 - accuracy: 0.8797 - val_loss: 0.4252 - val_accuracy: 0.8676\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3552 - accuracy: 0.8781 - val_loss: 0.3764 - val_accuracy: 0.8778\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3504 - accuracy: 0.8800 - val_loss: 0.3824 - val_accuracy: 0.8743\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3436 - accuracy: 0.8833 - val_loss: 0.4441 - val_accuracy: 0.8600\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3373 - accuracy: 0.8833 - val_loss: 0.4101 - val_accuracy: 0.8663\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3414 - accuracy: 0.8830 - val_loss: 0.3673 - val_accuracy: 0.8806\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3453 - accuracy: 0.8825 - val_loss: 0.3750 - val_accuracy: 0.8809\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3393 - accuracy: 0.8829 - val_loss: 0.3638 - val_accuracy: 0.8816\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3354 - accuracy: 0.8839 - val_loss: 0.4034 - val_accuracy: 0.8717\n",
      "Epoch 68/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3348 - accuracy: 0.8838 - val_loss: 0.4374 - val_accuracy: 0.8617\n",
      "Epoch 69/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3265 - accuracy: 0.8898 - val_loss: 0.3933 - val_accuracy: 0.8769\n",
      "Epoch 70/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3364 - accuracy: 0.8846 - val_loss: 0.4220 - val_accuracy: 0.8669\n",
      "Epoch 71/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3287 - accuracy: 0.8867 - val_loss: 0.3566 - val_accuracy: 0.8854\n",
      "Epoch 72/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3272 - accuracy: 0.8863 - val_loss: 0.3842 - val_accuracy: 0.8745\n",
      "Epoch 73/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3251 - accuracy: 0.8882 - val_loss: 0.3755 - val_accuracy: 0.8803\n",
      "Epoch 74/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3221 - accuracy: 0.8902 - val_loss: 0.4376 - val_accuracy: 0.8636\n",
      "Epoch 75/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3281 - accuracy: 0.8870 - val_loss: 0.3893 - val_accuracy: 0.8756\n",
      "Epoch 76/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3212 - accuracy: 0.8892 - val_loss: 0.3978 - val_accuracy: 0.8720\n",
      "Epoch 77/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3172 - accuracy: 0.8914 - val_loss: 0.3707 - val_accuracy: 0.8829\n",
      "Epoch 78/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3230 - accuracy: 0.8876 - val_loss: 0.3617 - val_accuracy: 0.8808\n",
      "Epoch 79/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3213 - accuracy: 0.8899 - val_loss: 0.3745 - val_accuracy: 0.8770\n",
      "Epoch 80/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3141 - accuracy: 0.8926 - val_loss: 0.4109 - val_accuracy: 0.8666\n",
      "Epoch 81/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3150 - accuracy: 0.8925 - val_loss: 0.3521 - val_accuracy: 0.8857\n",
      "Epoch 82/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3169 - accuracy: 0.8913 - val_loss: 0.3961 - val_accuracy: 0.8754\n",
      "Epoch 83/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3093 - accuracy: 0.8946 - val_loss: 0.4686 - val_accuracy: 0.8564\n",
      "Epoch 84/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3120 - accuracy: 0.8927 - val_loss: 0.3953 - val_accuracy: 0.8727\n",
      "Epoch 85/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3130 - accuracy: 0.8927 - val_loss: 0.3880 - val_accuracy: 0.8770\n",
      "Epoch 86/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3122 - accuracy: 0.8930 - val_loss: 0.3689 - val_accuracy: 0.8825\n",
      "Epoch 87/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3095 - accuracy: 0.8924 - val_loss: 0.3473 - val_accuracy: 0.8883\n",
      "Epoch 88/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3118 - accuracy: 0.8935 - val_loss: 0.3653 - val_accuracy: 0.8809\n",
      "Epoch 89/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3067 - accuracy: 0.8940 - val_loss: 0.3594 - val_accuracy: 0.8836\n",
      "Epoch 90/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3061 - accuracy: 0.8934 - val_loss: 0.3815 - val_accuracy: 0.8785\n",
      "Epoch 91/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3010 - accuracy: 0.8967 - val_loss: 0.3606 - val_accuracy: 0.8848\n",
      "Epoch 92/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3076 - accuracy: 0.8943 - val_loss: 0.4049 - val_accuracy: 0.8725\n",
      "Epoch 93/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2995 - accuracy: 0.8978 - val_loss: 0.3499 - val_accuracy: 0.8875\n",
      "Epoch 94/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2988 - accuracy: 0.8975 - val_loss: 0.3806 - val_accuracy: 0.8784\n",
      "Epoch 95/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3013 - accuracy: 0.8969 - val_loss: 0.3481 - val_accuracy: 0.8868\n",
      "Epoch 96/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2979 - accuracy: 0.8980 - val_loss: 0.3665 - val_accuracy: 0.8814\n",
      "Epoch 97/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2977 - accuracy: 0.8987 - val_loss: 0.3668 - val_accuracy: 0.8797\n",
      "Epoch 98/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2952 - accuracy: 0.8969 - val_loss: 0.3580 - val_accuracy: 0.8830\n",
      "Epoch 99/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2921 - accuracy: 0.8997 - val_loss: 0.3556 - val_accuracy: 0.8879\n",
      "Epoch 100/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2941 - accuracy: 0.8990 - val_loss: 0.3367 - val_accuracy: 0.8917\n",
      "Epoch 101/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2912 - accuracy: 0.9006 - val_loss: 0.3461 - val_accuracy: 0.8881\n",
      "Epoch 102/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2935 - accuracy: 0.8995 - val_loss: 0.3582 - val_accuracy: 0.8873\n",
      "Epoch 103/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2925 - accuracy: 0.9003 - val_loss: 0.3578 - val_accuracy: 0.8847\n",
      "Epoch 104/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2925 - accuracy: 0.8995 - val_loss: 0.3486 - val_accuracy: 0.8881\n",
      "Epoch 105/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2895 - accuracy: 0.8998 - val_loss: 0.3717 - val_accuracy: 0.8817\n",
      "Epoch 106/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2886 - accuracy: 0.9012 - val_loss: 0.3662 - val_accuracy: 0.8826\n",
      "Epoch 107/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2892 - accuracy: 0.9003 - val_loss: 0.3404 - val_accuracy: 0.8907\n",
      "Epoch 108/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2898 - accuracy: 0.8996 - val_loss: 0.3847 - val_accuracy: 0.8783\n",
      "Epoch 109/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2864 - accuracy: 0.9024 - val_loss: 0.3602 - val_accuracy: 0.8870\n",
      "Epoch 110/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2843 - accuracy: 0.9017 - val_loss: 0.3570 - val_accuracy: 0.8870\n",
      "Epoch 111/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2855 - accuracy: 0.8994 - val_loss: 0.3665 - val_accuracy: 0.8821\n",
      "Epoch 112/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2800 - accuracy: 0.9026 - val_loss: 0.3488 - val_accuracy: 0.8862\n",
      "Epoch 113/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2811 - accuracy: 0.9024 - val_loss: 0.3808 - val_accuracy: 0.8822\n",
      "Epoch 114/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2839 - accuracy: 0.9027 - val_loss: 0.4120 - val_accuracy: 0.8748\n",
      "Epoch 115/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2834 - accuracy: 0.9016 - val_loss: 0.3388 - val_accuracy: 0.8888\n",
      "Epoch 116/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2794 - accuracy: 0.9038 - val_loss: 0.3765 - val_accuracy: 0.8801\n",
      "Epoch 117/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2810 - accuracy: 0.9034 - val_loss: 0.3760 - val_accuracy: 0.8806\n",
      "Epoch 118/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2756 - accuracy: 0.9045 - val_loss: 0.3598 - val_accuracy: 0.8874\n",
      "Epoch 119/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2761 - accuracy: 0.9054 - val_loss: 0.3444 - val_accuracy: 0.8906\n",
      "Epoch 120/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2794 - accuracy: 0.9035 - val_loss: 0.3374 - val_accuracy: 0.8916\n",
      "Epoch 121/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2775 - accuracy: 0.9041 - val_loss: 0.3325 - val_accuracy: 0.8929\n",
      "Epoch 122/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2733 - accuracy: 0.9062 - val_loss: 0.3542 - val_accuracy: 0.8867\n",
      "Epoch 123/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2751 - accuracy: 0.9044 - val_loss: 0.3525 - val_accuracy: 0.8896\n",
      "Epoch 124/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2718 - accuracy: 0.9060 - val_loss: 0.3469 - val_accuracy: 0.8877\n",
      "Epoch 125/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2724 - accuracy: 0.9078 - val_loss: 0.3769 - val_accuracy: 0.8793\n",
      "Epoch 126/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2757 - accuracy: 0.9052 - val_loss: 0.3451 - val_accuracy: 0.8919\n",
      "Epoch 127/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2748 - accuracy: 0.9046 - val_loss: 0.3359 - val_accuracy: 0.8954\n",
      "Epoch 128/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2725 - accuracy: 0.9059 - val_loss: 0.3353 - val_accuracy: 0.8946\n",
      "Epoch 129/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2694 - accuracy: 0.9061 - val_loss: 0.3341 - val_accuracy: 0.8938\n",
      "Epoch 130/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2707 - accuracy: 0.9066 - val_loss: 0.3523 - val_accuracy: 0.8901\n",
      "Epoch 131/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2648 - accuracy: 0.9088 - val_loss: 0.3789 - val_accuracy: 0.8825\n",
      "Epoch 132/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2696 - accuracy: 0.9080 - val_loss: 0.3860 - val_accuracy: 0.8806\n",
      "Epoch 133/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2657 - accuracy: 0.9087 - val_loss: 0.3646 - val_accuracy: 0.8864\n",
      "Epoch 134/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2671 - accuracy: 0.9073 - val_loss: 0.3595 - val_accuracy: 0.8896\n",
      "Epoch 135/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2649 - accuracy: 0.9085 - val_loss: 0.3507 - val_accuracy: 0.8896\n",
      "Epoch 136/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2629 - accuracy: 0.9086 - val_loss: 0.3608 - val_accuracy: 0.8881\n",
      "Epoch 137/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2648 - accuracy: 0.9082 - val_loss: 0.3560 - val_accuracy: 0.8870\n",
      "Epoch 138/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2618 - accuracy: 0.9092 - val_loss: 0.3405 - val_accuracy: 0.8922\n",
      "Epoch 139/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2618 - accuracy: 0.9093 - val_loss: 0.3864 - val_accuracy: 0.8802\n",
      "Epoch 140/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2648 - accuracy: 0.9079 - val_loss: 0.3523 - val_accuracy: 0.8907\n",
      "Epoch 141/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2630 - accuracy: 0.9096 - val_loss: 0.3643 - val_accuracy: 0.8878\n",
      "Epoch 142/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2636 - accuracy: 0.9098 - val_loss: 0.3330 - val_accuracy: 0.8923\n",
      "Epoch 143/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2609 - accuracy: 0.9092 - val_loss: 0.3464 - val_accuracy: 0.8915\n",
      "Epoch 144/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2576 - accuracy: 0.9112 - val_loss: 0.3741 - val_accuracy: 0.8851\n",
      "Epoch 145/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2628 - accuracy: 0.9093 - val_loss: 0.3758 - val_accuracy: 0.8851\n",
      "Epoch 146/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2569 - accuracy: 0.9113 - val_loss: 0.3805 - val_accuracy: 0.8821\n",
      "Epoch 147/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2633 - accuracy: 0.9100 - val_loss: 0.3419 - val_accuracy: 0.8932\n",
      "Epoch 148/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2581 - accuracy: 0.9115 - val_loss: 0.3333 - val_accuracy: 0.8945\n",
      "Epoch 149/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2584 - accuracy: 0.9111 - val_loss: 0.3344 - val_accuracy: 0.8948\n",
      "Epoch 150/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2573 - accuracy: 0.9130 - val_loss: 0.3344 - val_accuracy: 0.8958\n",
      "Epoch 151/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2605 - accuracy: 0.9095 - val_loss: 0.3314 - val_accuracy: 0.8955\n",
      "Epoch 152/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2552 - accuracy: 0.9124 - val_loss: 0.3409 - val_accuracy: 0.8900\n",
      "Epoch 153/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2586 - accuracy: 0.9111 - val_loss: 0.3802 - val_accuracy: 0.8818\n",
      "Epoch 154/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2571 - accuracy: 0.9103 - val_loss: 0.3715 - val_accuracy: 0.8859\n",
      "Epoch 155/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2545 - accuracy: 0.9134 - val_loss: 0.3841 - val_accuracy: 0.8840\n",
      "Epoch 156/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2543 - accuracy: 0.9118 - val_loss: 0.3761 - val_accuracy: 0.8823\n",
      "Epoch 157/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2536 - accuracy: 0.9122 - val_loss: 0.3738 - val_accuracy: 0.8845\n",
      "Epoch 158/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2504 - accuracy: 0.9121 - val_loss: 0.3487 - val_accuracy: 0.8911\n",
      "Epoch 159/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2547 - accuracy: 0.9119 - val_loss: 0.3513 - val_accuracy: 0.8889\n",
      "Epoch 160/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2472 - accuracy: 0.9152 - val_loss: 0.3568 - val_accuracy: 0.8896\n",
      "Epoch 161/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2499 - accuracy: 0.9136 - val_loss: 0.3479 - val_accuracy: 0.8915\n",
      "Epoch 162/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2469 - accuracy: 0.9140 - val_loss: 0.3453 - val_accuracy: 0.8904\n",
      "Epoch 163/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2492 - accuracy: 0.9134 - val_loss: 0.3535 - val_accuracy: 0.8871\n",
      "Epoch 164/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2507 - accuracy: 0.9125 - val_loss: 0.3528 - val_accuracy: 0.8890\n",
      "Epoch 165/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2487 - accuracy: 0.9130 - val_loss: 0.3541 - val_accuracy: 0.8889\n",
      "Epoch 166/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2454 - accuracy: 0.9153 - val_loss: 0.3748 - val_accuracy: 0.8856\n",
      "Epoch 167/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2490 - accuracy: 0.9140 - val_loss: 0.3617 - val_accuracy: 0.8888\n",
      "Epoch 168/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2482 - accuracy: 0.9145 - val_loss: 0.3403 - val_accuracy: 0.8950\n",
      "Epoch 169/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2464 - accuracy: 0.9143 - val_loss: 0.3390 - val_accuracy: 0.8912\n",
      "Epoch 170/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2443 - accuracy: 0.9147 - val_loss: 0.3506 - val_accuracy: 0.8925\n",
      "Epoch 171/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2509 - accuracy: 0.9140 - val_loss: 0.3574 - val_accuracy: 0.8890\n",
      "Epoch 172/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2496 - accuracy: 0.9140 - val_loss: 0.3471 - val_accuracy: 0.8921\n",
      "Epoch 173/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2461 - accuracy: 0.9160 - val_loss: 0.3472 - val_accuracy: 0.8905\n",
      "Epoch 174/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2449 - accuracy: 0.9159 - val_loss: 0.3364 - val_accuracy: 0.8937\n",
      "Epoch 175/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2457 - accuracy: 0.9149 - val_loss: 0.3560 - val_accuracy: 0.8898\n",
      "Epoch 176/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2478 - accuracy: 0.9142 - val_loss: 0.3484 - val_accuracy: 0.8930\n",
      "Epoch 177/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2398 - accuracy: 0.9171 - val_loss: 0.3463 - val_accuracy: 0.8944\n",
      "Epoch 178/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2422 - accuracy: 0.9152 - val_loss: 0.3608 - val_accuracy: 0.8909\n",
      "Epoch 179/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2431 - accuracy: 0.9148 - val_loss: 0.3543 - val_accuracy: 0.8919\n",
      "Epoch 180/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2452 - accuracy: 0.9155 - val_loss: 0.3671 - val_accuracy: 0.8866\n",
      "Epoch 181/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2366 - accuracy: 0.9194 - val_loss: 0.3342 - val_accuracy: 0.8923\n",
      "Epoch 182/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2414 - accuracy: 0.9156 - val_loss: 0.3543 - val_accuracy: 0.8880\n",
      "Epoch 183/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2427 - accuracy: 0.9160 - val_loss: 0.3481 - val_accuracy: 0.8910\n",
      "Epoch 184/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2420 - accuracy: 0.9153 - val_loss: 0.3516 - val_accuracy: 0.8915\n",
      "Epoch 185/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2457 - accuracy: 0.9136 - val_loss: 0.3626 - val_accuracy: 0.8864\n",
      "Epoch 186/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2391 - accuracy: 0.9162 - val_loss: 0.4320 - val_accuracy: 0.8783\n",
      "Epoch 187/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2429 - accuracy: 0.9160 - val_loss: 0.3528 - val_accuracy: 0.8906\n",
      "Epoch 188/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2331 - accuracy: 0.9200 - val_loss: 0.3386 - val_accuracy: 0.8962\n",
      "Epoch 189/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2381 - accuracy: 0.9173 - val_loss: 0.3766 - val_accuracy: 0.8878\n",
      "Epoch 190/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2416 - accuracy: 0.9151 - val_loss: 0.3411 - val_accuracy: 0.8952\n",
      "Epoch 191/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2381 - accuracy: 0.9153 - val_loss: 0.3972 - val_accuracy: 0.8821\n",
      "Epoch 192/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2333 - accuracy: 0.9179 - val_loss: 0.3507 - val_accuracy: 0.8952\n",
      "Epoch 193/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2343 - accuracy: 0.9171 - val_loss: 0.3388 - val_accuracy: 0.8957\n",
      "Epoch 194/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2406 - accuracy: 0.9151 - val_loss: 0.3581 - val_accuracy: 0.8918\n",
      "Epoch 195/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2366 - accuracy: 0.9185 - val_loss: 0.3249 - val_accuracy: 0.8985\n",
      "Epoch 196/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2362 - accuracy: 0.9173 - val_loss: 0.3691 - val_accuracy: 0.8881\n",
      "Epoch 197/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2402 - accuracy: 0.9166 - val_loss: 0.3406 - val_accuracy: 0.8956\n",
      "Epoch 198/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2362 - accuracy: 0.9182 - val_loss: 0.3327 - val_accuracy: 0.8965\n",
      "Epoch 199/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2337 - accuracy: 0.9183 - val_loss: 0.3747 - val_accuracy: 0.8868\n",
      "Epoch 200/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2373 - accuracy: 0.9184 - val_loss: 0.3644 - val_accuracy: 0.8904\n",
      "Epoch 201/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2363 - accuracy: 0.9171 - val_loss: 0.3723 - val_accuracy: 0.8880\n",
      "Epoch 202/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2294 - accuracy: 0.9211 - val_loss: 0.3353 - val_accuracy: 0.8967\n",
      "Epoch 203/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2319 - accuracy: 0.9201 - val_loss: 0.3387 - val_accuracy: 0.8970\n",
      "Epoch 204/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2327 - accuracy: 0.9191 - val_loss: 0.3531 - val_accuracy: 0.8921\n",
      "Epoch 205/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2347 - accuracy: 0.9178 - val_loss: 0.3442 - val_accuracy: 0.8938\n",
      "Epoch 206/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2298 - accuracy: 0.9211 - val_loss: 0.3474 - val_accuracy: 0.8944\n",
      "Epoch 207/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2261 - accuracy: 0.9221 - val_loss: 0.3235 - val_accuracy: 0.9012\n",
      "Epoch 208/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2310 - accuracy: 0.9202 - val_loss: 0.3372 - val_accuracy: 0.8939\n",
      "Epoch 209/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2318 - accuracy: 0.9195 - val_loss: 0.3307 - val_accuracy: 0.8962\n",
      "Epoch 210/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2286 - accuracy: 0.9210 - val_loss: 0.3532 - val_accuracy: 0.8902\n",
      "Epoch 211/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2305 - accuracy: 0.9201 - val_loss: 0.3783 - val_accuracy: 0.8888\n",
      "Epoch 212/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2318 - accuracy: 0.9190 - val_loss: 0.3602 - val_accuracy: 0.8907\n",
      "Epoch 213/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2304 - accuracy: 0.9210 - val_loss: 0.3495 - val_accuracy: 0.8927\n",
      "Epoch 214/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2295 - accuracy: 0.9197 - val_loss: 0.3592 - val_accuracy: 0.8918\n",
      "Epoch 215/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2263 - accuracy: 0.9211 - val_loss: 0.3600 - val_accuracy: 0.8945\n",
      "Epoch 216/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2297 - accuracy: 0.9191 - val_loss: 0.3455 - val_accuracy: 0.8950\n",
      "Epoch 217/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2287 - accuracy: 0.9209 - val_loss: 0.3422 - val_accuracy: 0.8955\n",
      "Epoch 218/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2266 - accuracy: 0.9209 - val_loss: 0.4219 - val_accuracy: 0.8801\n",
      "Epoch 219/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2296 - accuracy: 0.9208 - val_loss: 0.3456 - val_accuracy: 0.8941\n",
      "Epoch 220/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2292 - accuracy: 0.9217 - val_loss: 0.3549 - val_accuracy: 0.8930\n",
      "Epoch 221/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2262 - accuracy: 0.9229 - val_loss: 0.3222 - val_accuracy: 0.8983\n",
      "Epoch 222/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2293 - accuracy: 0.9203 - val_loss: 0.3149 - val_accuracy: 0.9015\n",
      "Epoch 223/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2310 - accuracy: 0.9186 - val_loss: 0.3397 - val_accuracy: 0.8956\n",
      "Epoch 224/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2279 - accuracy: 0.9214 - val_loss: 0.3639 - val_accuracy: 0.8954\n",
      "Epoch 225/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2263 - accuracy: 0.9214 - val_loss: 0.3407 - val_accuracy: 0.8969\n",
      "Epoch 226/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2261 - accuracy: 0.9209 - val_loss: 0.3412 - val_accuracy: 0.9005\n",
      "Epoch 227/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2232 - accuracy: 0.9223 - val_loss: 0.3946 - val_accuracy: 0.8827\n",
      "Epoch 228/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2243 - accuracy: 0.9220 - val_loss: 0.3475 - val_accuracy: 0.8948\n",
      "Epoch 229/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2278 - accuracy: 0.9200 - val_loss: 0.3332 - val_accuracy: 0.8984\n",
      "Epoch 230/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2250 - accuracy: 0.9212 - val_loss: 0.3286 - val_accuracy: 0.8979\n",
      "Epoch 231/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2190 - accuracy: 0.9231 - val_loss: 0.3549 - val_accuracy: 0.8918\n",
      "Epoch 232/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2214 - accuracy: 0.9239 - val_loss: 0.3244 - val_accuracy: 0.8998\n",
      "Epoch 233/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2216 - accuracy: 0.9230 - val_loss: 0.3290 - val_accuracy: 0.9022\n",
      "Epoch 234/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2247 - accuracy: 0.9224 - val_loss: 0.3390 - val_accuracy: 0.8998\n",
      "Epoch 235/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2251 - accuracy: 0.9223 - val_loss: 0.3803 - val_accuracy: 0.8881\n",
      "Epoch 236/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2234 - accuracy: 0.9221 - val_loss: 0.3305 - val_accuracy: 0.9002\n",
      "Epoch 237/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2176 - accuracy: 0.9245 - val_loss: 0.3532 - val_accuracy: 0.8954\n",
      "Epoch 238/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2163 - accuracy: 0.9252 - val_loss: 0.3511 - val_accuracy: 0.8958\n",
      "Epoch 239/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2200 - accuracy: 0.9239 - val_loss: 0.3623 - val_accuracy: 0.8908\n",
      "Epoch 240/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2201 - accuracy: 0.9225 - val_loss: 0.3357 - val_accuracy: 0.8999\n",
      "Epoch 241/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2204 - accuracy: 0.9242 - val_loss: 0.3952 - val_accuracy: 0.8883\n",
      "Epoch 242/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.2253 - accuracy: 0.9213 - val_loss: 0.3219 - val_accuracy: 0.9020\n",
      "Epoch 243/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2194 - accuracy: 0.9242 - val_loss: 0.3372 - val_accuracy: 0.8975\n",
      "Epoch 244/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2173 - accuracy: 0.9247 - val_loss: 0.3296 - val_accuracy: 0.9021\n",
      "Epoch 245/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2217 - accuracy: 0.9229 - val_loss: 0.3704 - val_accuracy: 0.8905\n",
      "Epoch 246/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2195 - accuracy: 0.9246 - val_loss: 0.3730 - val_accuracy: 0.8896\n",
      "Epoch 247/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2236 - accuracy: 0.9221 - val_loss: 0.3367 - val_accuracy: 0.8970\n",
      "Epoch 248/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2204 - accuracy: 0.9236 - val_loss: 0.3384 - val_accuracy: 0.8974\n",
      "Epoch 249/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2182 - accuracy: 0.9242 - val_loss: 0.3481 - val_accuracy: 0.8937\n",
      "Epoch 250/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2199 - accuracy: 0.9240 - val_loss: 0.3472 - val_accuracy: 0.8951\n",
      "Epoch 251/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2243 - accuracy: 0.9226 - val_loss: 0.3402 - val_accuracy: 0.8959\n",
      "Epoch 252/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2163 - accuracy: 0.9236 - val_loss: 0.3329 - val_accuracy: 0.8975\n",
      "Epoch 253/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2194 - accuracy: 0.9230 - val_loss: 0.3503 - val_accuracy: 0.8967\n",
      "Epoch 254/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2166 - accuracy: 0.9246 - val_loss: 0.3549 - val_accuracy: 0.8959\n",
      "Epoch 255/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2202 - accuracy: 0.9236 - val_loss: 0.3357 - val_accuracy: 0.8968\n",
      "Epoch 256/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2159 - accuracy: 0.9242 - val_loss: 0.3418 - val_accuracy: 0.8982\n",
      "Epoch 257/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2158 - accuracy: 0.9258 - val_loss: 0.3528 - val_accuracy: 0.8952\n",
      "Epoch 258/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2179 - accuracy: 0.9242 - val_loss: 0.3263 - val_accuracy: 0.9001\n",
      "Epoch 259/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2194 - accuracy: 0.9234 - val_loss: 0.3346 - val_accuracy: 0.8980\n",
      "Epoch 260/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2190 - accuracy: 0.9243 - val_loss: 0.3435 - val_accuracy: 0.8972\n",
      "Epoch 261/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2159 - accuracy: 0.9244 - val_loss: 0.3274 - val_accuracy: 0.8993\n",
      "Epoch 262/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2155 - accuracy: 0.9235 - val_loss: 0.3451 - val_accuracy: 0.8974\n",
      "Epoch 263/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2147 - accuracy: 0.9253 - val_loss: 0.3276 - val_accuracy: 0.8977\n",
      "Epoch 264/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2166 - accuracy: 0.9248 - val_loss: 0.3464 - val_accuracy: 0.8965\n",
      "Epoch 265/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2161 - accuracy: 0.9251 - val_loss: 0.3619 - val_accuracy: 0.8923\n",
      "Epoch 266/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2105 - accuracy: 0.9265 - val_loss: 0.3647 - val_accuracy: 0.8937\n",
      "Epoch 267/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2098 - accuracy: 0.9263 - val_loss: 0.3344 - val_accuracy: 0.9010\n",
      "Epoch 268/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2136 - accuracy: 0.9242 - val_loss: 0.3308 - val_accuracy: 0.9001\n",
      "Epoch 269/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2146 - accuracy: 0.9268 - val_loss: 0.3459 - val_accuracy: 0.8950\n",
      "Epoch 270/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2176 - accuracy: 0.9229 - val_loss: 0.3255 - val_accuracy: 0.8984\n",
      "Epoch 271/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2166 - accuracy: 0.9258 - val_loss: 0.3435 - val_accuracy: 0.8961\n",
      "Epoch 272/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2127 - accuracy: 0.9267 - val_loss: 0.3374 - val_accuracy: 0.8987\n",
      "Epoch 273/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2168 - accuracy: 0.9250 - val_loss: 0.3413 - val_accuracy: 0.8976\n",
      "Epoch 274/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2075 - accuracy: 0.9265 - val_loss: 0.3305 - val_accuracy: 0.8995\n",
      "Epoch 275/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2077 - accuracy: 0.9278 - val_loss: 0.3479 - val_accuracy: 0.8962\n",
      "Epoch 276/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2124 - accuracy: 0.9268 - val_loss: 0.3391 - val_accuracy: 0.8986\n",
      "Epoch 277/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2102 - accuracy: 0.9268 - val_loss: 0.3222 - val_accuracy: 0.9009\n",
      "Epoch 278/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2111 - accuracy: 0.9251 - val_loss: 0.3668 - val_accuracy: 0.8921\n",
      "Epoch 279/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2138 - accuracy: 0.9253 - val_loss: 0.3401 - val_accuracy: 0.8974\n",
      "Epoch 280/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2091 - accuracy: 0.9276 - val_loss: 0.3296 - val_accuracy: 0.9015\n",
      "Epoch 281/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2109 - accuracy: 0.9268 - val_loss: 0.3519 - val_accuracy: 0.8944\n",
      "Epoch 282/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2100 - accuracy: 0.9259 - val_loss: 0.3787 - val_accuracy: 0.8897\n",
      "Epoch 283/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2076 - accuracy: 0.9282 - val_loss: 0.3379 - val_accuracy: 0.8977\n",
      "Epoch 284/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2087 - accuracy: 0.9265 - val_loss: 0.3481 - val_accuracy: 0.8959\n",
      "Epoch 285/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2085 - accuracy: 0.9280 - val_loss: 0.3535 - val_accuracy: 0.8948\n",
      "Epoch 286/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2081 - accuracy: 0.9280 - val_loss: 0.3691 - val_accuracy: 0.8911\n",
      "Epoch 287/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2043 - accuracy: 0.9285 - val_loss: 0.3602 - val_accuracy: 0.8961\n",
      "Epoch 288/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2112 - accuracy: 0.9261 - val_loss: 0.3465 - val_accuracy: 0.8966\n",
      "Epoch 289/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2093 - accuracy: 0.9271 - val_loss: 0.3145 - val_accuracy: 0.9033\n",
      "Epoch 290/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2110 - accuracy: 0.9261 - val_loss: 0.3375 - val_accuracy: 0.8965\n",
      "Epoch 291/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2064 - accuracy: 0.9287 - val_loss: 0.3211 - val_accuracy: 0.9023\n",
      "Epoch 292/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2046 - accuracy: 0.9284 - val_loss: 0.3179 - val_accuracy: 0.9025\n",
      "Epoch 293/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2106 - accuracy: 0.9265 - val_loss: 0.3207 - val_accuracy: 0.9026\n",
      "Epoch 294/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2114 - accuracy: 0.9260 - val_loss: 0.3330 - val_accuracy: 0.8998\n",
      "Epoch 295/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2106 - accuracy: 0.9261 - val_loss: 0.3517 - val_accuracy: 0.8987\n",
      "Epoch 296/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2041 - accuracy: 0.9290 - val_loss: 0.3388 - val_accuracy: 0.8977\n",
      "Epoch 297/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2115 - accuracy: 0.9256 - val_loss: 0.3283 - val_accuracy: 0.8996\n",
      "Epoch 298/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2035 - accuracy: 0.9297 - val_loss: 0.3360 - val_accuracy: 0.9008\n",
      "Epoch 299/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2076 - accuracy: 0.9271 - val_loss: 0.4107 - val_accuracy: 0.8820\n",
      "Epoch 300/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2054 - accuracy: 0.9280 - val_loss: 0.3711 - val_accuracy: 0.8902\n",
      "Epoch 301/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2071 - accuracy: 0.9284 - val_loss: 0.3240 - val_accuracy: 0.9014\n",
      "Epoch 302/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2039 - accuracy: 0.9292 - val_loss: 0.3751 - val_accuracy: 0.8869\n",
      "Epoch 303/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1996 - accuracy: 0.9310 - val_loss: 0.3270 - val_accuracy: 0.8990\n",
      "Epoch 304/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2099 - accuracy: 0.9269 - val_loss: 0.3418 - val_accuracy: 0.8962\n",
      "Epoch 305/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2092 - accuracy: 0.9268 - val_loss: 0.3768 - val_accuracy: 0.8881\n",
      "Epoch 306/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2029 - accuracy: 0.9291 - val_loss: 0.3865 - val_accuracy: 0.8858\n",
      "Epoch 307/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2062 - accuracy: 0.9281 - val_loss: 0.3652 - val_accuracy: 0.8936\n",
      "Epoch 308/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2051 - accuracy: 0.9283 - val_loss: 0.3404 - val_accuracy: 0.8986\n",
      "Epoch 309/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2082 - accuracy: 0.9274 - val_loss: 0.3992 - val_accuracy: 0.8842\n",
      "Epoch 310/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2010 - accuracy: 0.9299 - val_loss: 0.3415 - val_accuracy: 0.8961\n",
      "Epoch 311/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2009 - accuracy: 0.9302 - val_loss: 0.3463 - val_accuracy: 0.8980\n",
      "Epoch 312/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2020 - accuracy: 0.9299 - val_loss: 0.3608 - val_accuracy: 0.8941\n",
      "Epoch 313/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2064 - accuracy: 0.9287 - val_loss: 0.3489 - val_accuracy: 0.8951\n",
      "Epoch 314/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2012 - accuracy: 0.9290 - val_loss: 0.3439 - val_accuracy: 0.8964\n",
      "Epoch 315/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2020 - accuracy: 0.9303 - val_loss: 0.3875 - val_accuracy: 0.8887\n",
      "Epoch 316/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2050 - accuracy: 0.9293 - val_loss: 0.3526 - val_accuracy: 0.8943\n",
      "Epoch 317/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2010 - accuracy: 0.9302 - val_loss: 0.3488 - val_accuracy: 0.8985\n",
      "Epoch 318/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2016 - accuracy: 0.9297 - val_loss: 0.3377 - val_accuracy: 0.8992\n",
      "Epoch 319/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2062 - accuracy: 0.9280 - val_loss: 0.4035 - val_accuracy: 0.8842\n",
      "Epoch 320/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2001 - accuracy: 0.9302 - val_loss: 0.3342 - val_accuracy: 0.8988\n",
      "Epoch 321/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1994 - accuracy: 0.9315 - val_loss: 0.3606 - val_accuracy: 0.8922\n",
      "Epoch 322/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2040 - accuracy: 0.9289 - val_loss: 0.3335 - val_accuracy: 0.9007\n",
      "Epoch 323/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2011 - accuracy: 0.9295 - val_loss: 0.3274 - val_accuracy: 0.9024\n",
      "Epoch 324/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2031 - accuracy: 0.9280 - val_loss: 0.3672 - val_accuracy: 0.8919\n",
      "Epoch 325/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1995 - accuracy: 0.9301 - val_loss: 0.3682 - val_accuracy: 0.8947\n",
      "Epoch 326/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1998 - accuracy: 0.9295 - val_loss: 0.3438 - val_accuracy: 0.8988\n",
      "Epoch 327/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1991 - accuracy: 0.9302 - val_loss: 0.3558 - val_accuracy: 0.8954\n",
      "Epoch 328/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2044 - accuracy: 0.9294 - val_loss: 0.3480 - val_accuracy: 0.8988\n",
      "Epoch 329/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2034 - accuracy: 0.9284 - val_loss: 0.3373 - val_accuracy: 0.9010\n",
      "Epoch 330/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2001 - accuracy: 0.9302 - val_loss: 0.3291 - val_accuracy: 0.9013\n",
      "Epoch 331/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2006 - accuracy: 0.9306 - val_loss: 0.3333 - val_accuracy: 0.8989\n",
      "Epoch 332/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1983 - accuracy: 0.9315 - val_loss: 0.3494 - val_accuracy: 0.8978\n",
      "Epoch 333/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2011 - accuracy: 0.9298 - val_loss: 0.3470 - val_accuracy: 0.8969\n",
      "Epoch 334/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1988 - accuracy: 0.9300 - val_loss: 0.3463 - val_accuracy: 0.8981\n",
      "Epoch 335/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1987 - accuracy: 0.9321 - val_loss: 0.3319 - val_accuracy: 0.9018\n",
      "Epoch 336/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1996 - accuracy: 0.9300 - val_loss: 0.3352 - val_accuracy: 0.9007\n",
      "Epoch 337/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1989 - accuracy: 0.9304 - val_loss: 0.3460 - val_accuracy: 0.8977\n",
      "Epoch 338/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1970 - accuracy: 0.9321 - val_loss: 0.3646 - val_accuracy: 0.8965\n",
      "Epoch 339/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1998 - accuracy: 0.9309 - val_loss: 0.3655 - val_accuracy: 0.8943\n",
      "Epoch 340/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1971 - accuracy: 0.9311 - val_loss: 0.3363 - val_accuracy: 0.8994\n",
      "Epoch 341/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1958 - accuracy: 0.9330 - val_loss: 0.3385 - val_accuracy: 0.8982\n",
      "Epoch 342/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1977 - accuracy: 0.9324 - val_loss: 0.3454 - val_accuracy: 0.8974\n",
      "Epoch 343/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1983 - accuracy: 0.9308 - val_loss: 0.3348 - val_accuracy: 0.9007\n",
      "Epoch 344/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1984 - accuracy: 0.9303 - val_loss: 0.3407 - val_accuracy: 0.9010\n",
      "Epoch 345/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1978 - accuracy: 0.9306 - val_loss: 0.3371 - val_accuracy: 0.8989\n",
      "Epoch 346/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2033 - accuracy: 0.9298 - val_loss: 0.3483 - val_accuracy: 0.8964\n",
      "Epoch 347/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1966 - accuracy: 0.9318 - val_loss: 0.3437 - val_accuracy: 0.8984\n",
      "Epoch 348/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1974 - accuracy: 0.9315 - val_loss: 0.3859 - val_accuracy: 0.8917\n",
      "Epoch 349/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1955 - accuracy: 0.9333 - val_loss: 0.3666 - val_accuracy: 0.8926\n",
      "Epoch 350/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1951 - accuracy: 0.9311 - val_loss: 0.3210 - val_accuracy: 0.9037\n",
      "Epoch 351/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1963 - accuracy: 0.9326 - val_loss: 0.3591 - val_accuracy: 0.8963\n",
      "Epoch 352/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1994 - accuracy: 0.9303 - val_loss: 0.3255 - val_accuracy: 0.9036\n",
      "Epoch 353/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1937 - accuracy: 0.9322 - val_loss: 0.3745 - val_accuracy: 0.8940\n",
      "Epoch 354/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1952 - accuracy: 0.9320 - val_loss: 0.3787 - val_accuracy: 0.8931\n",
      "Epoch 355/400\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.1971 - accuracy: 0.9317 - val_loss: 0.3461 - val_accuracy: 0.8997\n",
      "Epoch 356/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1916 - accuracy: 0.9329 - val_loss: 0.3599 - val_accuracy: 0.8981\n",
      "Epoch 357/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1957 - accuracy: 0.9313 - val_loss: 0.3547 - val_accuracy: 0.8979\n",
      "Epoch 358/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1925 - accuracy: 0.9324 - val_loss: 0.3288 - val_accuracy: 0.9020\n",
      "Epoch 359/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1943 - accuracy: 0.9321 - val_loss: 0.3407 - val_accuracy: 0.8982\n",
      "Epoch 360/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1909 - accuracy: 0.9329 - val_loss: 0.3649 - val_accuracy: 0.8939\n",
      "Epoch 361/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1959 - accuracy: 0.9320 - val_loss: 0.3383 - val_accuracy: 0.8999\n",
      "Epoch 362/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1987 - accuracy: 0.9308 - val_loss: 0.3279 - val_accuracy: 0.9004\n",
      "Epoch 363/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1947 - accuracy: 0.9332 - val_loss: 0.3358 - val_accuracy: 0.9019\n",
      "Epoch 364/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1924 - accuracy: 0.9333 - val_loss: 0.3228 - val_accuracy: 0.9025\n",
      "Epoch 365/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1949 - accuracy: 0.9328 - val_loss: 0.3408 - val_accuracy: 0.9012\n",
      "Epoch 366/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1933 - accuracy: 0.9320 - val_loss: 0.3304 - val_accuracy: 0.9011\n",
      "Epoch 367/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1924 - accuracy: 0.9312 - val_loss: 0.3687 - val_accuracy: 0.8941\n",
      "Epoch 368/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1927 - accuracy: 0.9329 - val_loss: 0.3784 - val_accuracy: 0.8939\n",
      "Epoch 369/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1945 - accuracy: 0.9329 - val_loss: 0.3788 - val_accuracy: 0.8889\n",
      "Epoch 370/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.1890 - accuracy: 0.9344 - val_loss: 0.3607 - val_accuracy: 0.8977\n",
      "Epoch 371/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1976 - accuracy: 0.9314 - val_loss: 0.3404 - val_accuracy: 0.8996\n",
      "Epoch 372/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1900 - accuracy: 0.9344 - val_loss: 0.3577 - val_accuracy: 0.8949\n",
      "Epoch 373/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1930 - accuracy: 0.9322 - val_loss: 0.3701 - val_accuracy: 0.8931\n",
      "Epoch 374/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1895 - accuracy: 0.9332 - val_loss: 0.3937 - val_accuracy: 0.8891\n",
      "Epoch 375/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1934 - accuracy: 0.9335 - val_loss: 0.3405 - val_accuracy: 0.9002\n",
      "Epoch 376/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1923 - accuracy: 0.9326 - val_loss: 0.3495 - val_accuracy: 0.8970\n",
      "Epoch 377/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1943 - accuracy: 0.9326 - val_loss: 0.3107 - val_accuracy: 0.9063\n",
      "Epoch 378/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.1956 - accuracy: 0.9323 - val_loss: 0.3286 - val_accuracy: 0.9000\n",
      "Epoch 379/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1934 - accuracy: 0.9330 - val_loss: 0.3352 - val_accuracy: 0.9025\n",
      "Epoch 380/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.1900 - accuracy: 0.9339 - val_loss: 0.3199 - val_accuracy: 0.9050\n",
      "Epoch 381/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1936 - accuracy: 0.9324 - val_loss: 0.3167 - val_accuracy: 0.9049\n",
      "Epoch 382/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1925 - accuracy: 0.9331 - val_loss: 0.3425 - val_accuracy: 0.8983\n",
      "Epoch 383/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1887 - accuracy: 0.9340 - val_loss: 0.3377 - val_accuracy: 0.9000\n",
      "Epoch 384/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1892 - accuracy: 0.9337 - val_loss: 0.3655 - val_accuracy: 0.8921\n",
      "Epoch 385/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1888 - accuracy: 0.9352 - val_loss: 0.3311 - val_accuracy: 0.9026\n",
      "Epoch 386/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1867 - accuracy: 0.9347 - val_loss: 0.3317 - val_accuracy: 0.9016\n",
      "Epoch 387/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1881 - accuracy: 0.9332 - val_loss: 0.3455 - val_accuracy: 0.8978\n",
      "Epoch 388/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1933 - accuracy: 0.9322 - val_loss: 0.3474 - val_accuracy: 0.8977\n",
      "Epoch 389/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1890 - accuracy: 0.9328 - val_loss: 0.3413 - val_accuracy: 0.9008\n",
      "Epoch 390/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1893 - accuracy: 0.9325 - val_loss: 0.3318 - val_accuracy: 0.9022\n",
      "Epoch 391/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1921 - accuracy: 0.9339 - val_loss: 0.3555 - val_accuracy: 0.8972\n",
      "Epoch 392/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1899 - accuracy: 0.9336 - val_loss: 0.3588 - val_accuracy: 0.8957\n",
      "Epoch 393/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1909 - accuracy: 0.9331 - val_loss: 0.3443 - val_accuracy: 0.8965\n",
      "Epoch 394/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1877 - accuracy: 0.9349 - val_loss: 0.3314 - val_accuracy: 0.9023\n",
      "Epoch 395/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1907 - accuracy: 0.9337 - val_loss: 0.3334 - val_accuracy: 0.9023\n",
      "Epoch 396/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1923 - accuracy: 0.9325 - val_loss: 0.3340 - val_accuracy: 0.9010\n",
      "Epoch 397/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1896 - accuracy: 0.9339 - val_loss: 0.3286 - val_accuracy: 0.9013\n",
      "Epoch 398/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1873 - accuracy: 0.9351 - val_loss: 0.3277 - val_accuracy: 0.9029\n",
      "Epoch 399/400\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1904 - accuracy: 0.9343 - val_loss: 0.3592 - val_accuracy: 0.8961\n",
      "Epoch 400/400\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.1862 - accuracy: 0.9356 - val_loss: 0.3507 - val_accuracy: 0.8980\n",
      "\n",
      "Forming the grid-search model #2 using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f28fc29bc50>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f28fc248a20>, epochs=400, batch_size=64\n",
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 1.7009 - accuracy: 0.4187 - val_loss: 1.3211 - val_accuracy: 0.5498\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 1.1248 - accuracy: 0.6015 - val_loss: 0.9770 - val_accuracy: 0.6610\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.9488 - accuracy: 0.6656 - val_loss: 0.7957 - val_accuracy: 0.7269\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.8588 - accuracy: 0.7001 - val_loss: 0.7288 - val_accuracy: 0.7479\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.7930 - accuracy: 0.7265 - val_loss: 0.6866 - val_accuracy: 0.7622\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.7483 - accuracy: 0.7416 - val_loss: 0.6844 - val_accuracy: 0.7623\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.7158 - accuracy: 0.7545 - val_loss: 0.7550 - val_accuracy: 0.7447\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6810 - accuracy: 0.7674 - val_loss: 0.5819 - val_accuracy: 0.8046\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6469 - accuracy: 0.7789 - val_loss: 0.6313 - val_accuracy: 0.7868\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.6318 - accuracy: 0.7839 - val_loss: 0.6184 - val_accuracy: 0.7915\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6130 - accuracy: 0.7920 - val_loss: 0.5305 - val_accuracy: 0.8249\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5875 - accuracy: 0.7998 - val_loss: 0.5202 - val_accuracy: 0.8260\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5806 - accuracy: 0.8022 - val_loss: 0.6013 - val_accuracy: 0.8022\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5639 - accuracy: 0.8078 - val_loss: 0.5124 - val_accuracy: 0.8310\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.5508 - accuracy: 0.8129 - val_loss: 0.5278 - val_accuracy: 0.8234\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5433 - accuracy: 0.8168 - val_loss: 0.5233 - val_accuracy: 0.8278\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5309 - accuracy: 0.8212 - val_loss: 0.5414 - val_accuracy: 0.8182\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5211 - accuracy: 0.8212 - val_loss: 0.4731 - val_accuracy: 0.8388\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5094 - accuracy: 0.8281 - val_loss: 0.4961 - val_accuracy: 0.8316\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5035 - accuracy: 0.8294 - val_loss: 0.4769 - val_accuracy: 0.8418\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4919 - accuracy: 0.8341 - val_loss: 0.4896 - val_accuracy: 0.8377\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4878 - accuracy: 0.8356 - val_loss: 0.4742 - val_accuracy: 0.8422\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4809 - accuracy: 0.8387 - val_loss: 0.5250 - val_accuracy: 0.8303\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4732 - accuracy: 0.8425 - val_loss: 0.4847 - val_accuracy: 0.8406\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4700 - accuracy: 0.8425 - val_loss: 0.4334 - val_accuracy: 0.8524\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4600 - accuracy: 0.8421 - val_loss: 0.4497 - val_accuracy: 0.8508\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4584 - accuracy: 0.8437 - val_loss: 0.4310 - val_accuracy: 0.8527\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4476 - accuracy: 0.8483 - val_loss: 0.4926 - val_accuracy: 0.8386\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4484 - accuracy: 0.8488 - val_loss: 0.4249 - val_accuracy: 0.8622\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4367 - accuracy: 0.8533 - val_loss: 0.4375 - val_accuracy: 0.8585\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4344 - accuracy: 0.8533 - val_loss: 0.4880 - val_accuracy: 0.8455\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4361 - accuracy: 0.8531 - val_loss: 0.4355 - val_accuracy: 0.8616\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4305 - accuracy: 0.8548 - val_loss: 0.4301 - val_accuracy: 0.8600\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4228 - accuracy: 0.8578 - val_loss: 0.4402 - val_accuracy: 0.8598\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4201 - accuracy: 0.8592 - val_loss: 0.4002 - val_accuracy: 0.8666\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4165 - accuracy: 0.8583 - val_loss: 0.4510 - val_accuracy: 0.8529\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4131 - accuracy: 0.8609 - val_loss: 0.4516 - val_accuracy: 0.8538\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4091 - accuracy: 0.8622 - val_loss: 0.4072 - val_accuracy: 0.8681\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4070 - accuracy: 0.8622 - val_loss: 0.4160 - val_accuracy: 0.8634\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3997 - accuracy: 0.8642 - val_loss: 0.3924 - val_accuracy: 0.8694\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3971 - accuracy: 0.8648 - val_loss: 0.4084 - val_accuracy: 0.8668\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3981 - accuracy: 0.8656 - val_loss: 0.4288 - val_accuracy: 0.8612\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3958 - accuracy: 0.8666 - val_loss: 0.4320 - val_accuracy: 0.8578\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3920 - accuracy: 0.8676 - val_loss: 0.3870 - val_accuracy: 0.8731\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3891 - accuracy: 0.8671 - val_loss: 0.3800 - val_accuracy: 0.8749\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3845 - accuracy: 0.8692 - val_loss: 0.4030 - val_accuracy: 0.8715\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3825 - accuracy: 0.8711 - val_loss: 0.4035 - val_accuracy: 0.8725\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3792 - accuracy: 0.8717 - val_loss: 0.4106 - val_accuracy: 0.8652\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3776 - accuracy: 0.8719 - val_loss: 0.4413 - val_accuracy: 0.8604\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3772 - accuracy: 0.8700 - val_loss: 0.3998 - val_accuracy: 0.8705\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3734 - accuracy: 0.8724 - val_loss: 0.3884 - val_accuracy: 0.8783\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3768 - accuracy: 0.8741 - val_loss: 0.3774 - val_accuracy: 0.8770\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3676 - accuracy: 0.8762 - val_loss: 0.3961 - val_accuracy: 0.8715\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3640 - accuracy: 0.8786 - val_loss: 0.4100 - val_accuracy: 0.8722\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3711 - accuracy: 0.8741 - val_loss: 0.3580 - val_accuracy: 0.8813\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3654 - accuracy: 0.8755 - val_loss: 0.3667 - val_accuracy: 0.8787\n",
      "Epoch 57/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3584 - accuracy: 0.8801 - val_loss: 0.4084 - val_accuracy: 0.8694\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3575 - accuracy: 0.8780 - val_loss: 0.3713 - val_accuracy: 0.8795\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3586 - accuracy: 0.8785 - val_loss: 0.4693 - val_accuracy: 0.8539\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3574 - accuracy: 0.8799 - val_loss: 0.3804 - val_accuracy: 0.8783\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3514 - accuracy: 0.8804 - val_loss: 0.3653 - val_accuracy: 0.8819\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3524 - accuracy: 0.8802 - val_loss: 0.3667 - val_accuracy: 0.8826\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3450 - accuracy: 0.8831 - val_loss: 0.4038 - val_accuracy: 0.8704\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3453 - accuracy: 0.8829 - val_loss: 0.3612 - val_accuracy: 0.8843\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3458 - accuracy: 0.8832 - val_loss: 0.4099 - val_accuracy: 0.8703\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3420 - accuracy: 0.8832 - val_loss: 0.4054 - val_accuracy: 0.8718\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3444 - accuracy: 0.8832 - val_loss: 0.3963 - val_accuracy: 0.8765\n",
      "Epoch 68/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3393 - accuracy: 0.8844 - val_loss: 0.3708 - val_accuracy: 0.8826\n",
      "Epoch 69/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3421 - accuracy: 0.8838 - val_loss: 0.4276 - val_accuracy: 0.8678\n",
      "Epoch 70/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3381 - accuracy: 0.8843 - val_loss: 0.3774 - val_accuracy: 0.8808\n",
      "Epoch 71/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3372 - accuracy: 0.8849 - val_loss: 0.3412 - val_accuracy: 0.8911\n",
      "Epoch 72/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3302 - accuracy: 0.8873 - val_loss: 0.3400 - val_accuracy: 0.8943\n",
      "Epoch 73/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3354 - accuracy: 0.8860 - val_loss: 0.3377 - val_accuracy: 0.8917\n",
      "Epoch 74/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3308 - accuracy: 0.8878 - val_loss: 0.3819 - val_accuracy: 0.8778\n",
      "Epoch 75/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3295 - accuracy: 0.8882 - val_loss: 0.3510 - val_accuracy: 0.8885\n",
      "Epoch 76/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3323 - accuracy: 0.8877 - val_loss: 0.3706 - val_accuracy: 0.8814\n",
      "Epoch 77/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3329 - accuracy: 0.8870 - val_loss: 0.3711 - val_accuracy: 0.8832\n",
      "Epoch 78/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3277 - accuracy: 0.8884 - val_loss: 0.3476 - val_accuracy: 0.8911\n",
      "Epoch 79/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3276 - accuracy: 0.8885 - val_loss: 0.3751 - val_accuracy: 0.8800\n",
      "Epoch 80/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3278 - accuracy: 0.8890 - val_loss: 0.3398 - val_accuracy: 0.8906\n",
      "Epoch 81/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3217 - accuracy: 0.8907 - val_loss: 0.3663 - val_accuracy: 0.8824\n",
      "Epoch 82/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3249 - accuracy: 0.8901 - val_loss: 0.3967 - val_accuracy: 0.8744\n",
      "Epoch 83/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3217 - accuracy: 0.8905 - val_loss: 0.3770 - val_accuracy: 0.8793\n",
      "Epoch 84/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3170 - accuracy: 0.8915 - val_loss: 0.3756 - val_accuracy: 0.8811\n",
      "Epoch 85/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3194 - accuracy: 0.8928 - val_loss: 0.3864 - val_accuracy: 0.8776\n",
      "Epoch 86/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3183 - accuracy: 0.8924 - val_loss: 0.3565 - val_accuracy: 0.8872\n",
      "Epoch 87/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3144 - accuracy: 0.8938 - val_loss: 0.3497 - val_accuracy: 0.8878\n",
      "Epoch 88/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3180 - accuracy: 0.8911 - val_loss: 0.3680 - val_accuracy: 0.8839\n",
      "Epoch 89/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3144 - accuracy: 0.8924 - val_loss: 0.4017 - val_accuracy: 0.8733\n",
      "Epoch 90/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3147 - accuracy: 0.8941 - val_loss: 0.3747 - val_accuracy: 0.8839\n",
      "Epoch 91/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3116 - accuracy: 0.8942 - val_loss: 0.3454 - val_accuracy: 0.8916\n",
      "Epoch 92/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3096 - accuracy: 0.8937 - val_loss: 0.3543 - val_accuracy: 0.8891\n",
      "Epoch 93/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3101 - accuracy: 0.8942 - val_loss: 0.3870 - val_accuracy: 0.8795\n",
      "Epoch 94/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3110 - accuracy: 0.8946 - val_loss: 0.3868 - val_accuracy: 0.8821\n",
      "Epoch 95/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3136 - accuracy: 0.8945 - val_loss: 0.3316 - val_accuracy: 0.8946\n",
      "Epoch 96/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3087 - accuracy: 0.8956 - val_loss: 0.3705 - val_accuracy: 0.8845\n",
      "Epoch 97/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3054 - accuracy: 0.8960 - val_loss: 0.3364 - val_accuracy: 0.8915\n",
      "Epoch 98/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3049 - accuracy: 0.8969 - val_loss: 0.3780 - val_accuracy: 0.8805\n",
      "Epoch 99/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3030 - accuracy: 0.8974 - val_loss: 0.3744 - val_accuracy: 0.8814\n",
      "Epoch 100/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3011 - accuracy: 0.8989 - val_loss: 0.4052 - val_accuracy: 0.8794\n",
      "Epoch 101/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3012 - accuracy: 0.8983 - val_loss: 0.3505 - val_accuracy: 0.8886\n",
      "Epoch 102/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3067 - accuracy: 0.8961 - val_loss: 0.3408 - val_accuracy: 0.8929\n",
      "Epoch 103/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3024 - accuracy: 0.8972 - val_loss: 0.3316 - val_accuracy: 0.8934\n",
      "Epoch 104/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2961 - accuracy: 0.8995 - val_loss: 0.3432 - val_accuracy: 0.8918\n",
      "Epoch 105/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3024 - accuracy: 0.8961 - val_loss: 0.3396 - val_accuracy: 0.8910\n",
      "Epoch 106/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2964 - accuracy: 0.8989 - val_loss: 0.3661 - val_accuracy: 0.8863\n",
      "Epoch 107/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2934 - accuracy: 0.9007 - val_loss: 0.3643 - val_accuracy: 0.8866\n",
      "Epoch 108/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3039 - accuracy: 0.8968 - val_loss: 0.3395 - val_accuracy: 0.8913\n",
      "Epoch 109/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2954 - accuracy: 0.8978 - val_loss: 0.3981 - val_accuracy: 0.8784\n",
      "Epoch 110/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2948 - accuracy: 0.9005 - val_loss: 0.3576 - val_accuracy: 0.8890\n",
      "Epoch 111/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2932 - accuracy: 0.9007 - val_loss: 0.3562 - val_accuracy: 0.8885\n",
      "Epoch 112/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2968 - accuracy: 0.9015 - val_loss: 0.3486 - val_accuracy: 0.8882\n",
      "Epoch 113/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2968 - accuracy: 0.8985 - val_loss: 0.3706 - val_accuracy: 0.8823\n",
      "Epoch 114/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2906 - accuracy: 0.8991 - val_loss: 0.3642 - val_accuracy: 0.8841\n",
      "Epoch 115/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2900 - accuracy: 0.9014 - val_loss: 0.3746 - val_accuracy: 0.8808\n",
      "Epoch 116/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2952 - accuracy: 0.9002 - val_loss: 0.3594 - val_accuracy: 0.8855\n",
      "Epoch 117/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2882 - accuracy: 0.9015 - val_loss: 0.3754 - val_accuracy: 0.8861\n",
      "Epoch 118/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2907 - accuracy: 0.9007 - val_loss: 0.3494 - val_accuracy: 0.8899\n",
      "Epoch 119/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2845 - accuracy: 0.9030 - val_loss: 0.4007 - val_accuracy: 0.8763\n",
      "Epoch 120/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2891 - accuracy: 0.9009 - val_loss: 0.3344 - val_accuracy: 0.8975\n",
      "Epoch 121/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2867 - accuracy: 0.9035 - val_loss: 0.4069 - val_accuracy: 0.8712\n",
      "Epoch 122/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2898 - accuracy: 0.9017 - val_loss: 0.3796 - val_accuracy: 0.8830\n",
      "Epoch 123/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2853 - accuracy: 0.9029 - val_loss: 0.3283 - val_accuracy: 0.8920\n",
      "Epoch 124/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2869 - accuracy: 0.9019 - val_loss: 0.3737 - val_accuracy: 0.8863\n",
      "Epoch 125/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2841 - accuracy: 0.9031 - val_loss: 0.3376 - val_accuracy: 0.8940\n",
      "Epoch 126/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2828 - accuracy: 0.9026 - val_loss: 0.3839 - val_accuracy: 0.8807\n",
      "Epoch 127/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2826 - accuracy: 0.9041 - val_loss: 0.3273 - val_accuracy: 0.8931\n",
      "Epoch 128/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2828 - accuracy: 0.9045 - val_loss: 0.3481 - val_accuracy: 0.8922\n",
      "Epoch 129/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2833 - accuracy: 0.9035 - val_loss: 0.3717 - val_accuracy: 0.8836\n",
      "Epoch 130/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2813 - accuracy: 0.9037 - val_loss: 0.3590 - val_accuracy: 0.8860\n",
      "Epoch 131/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2826 - accuracy: 0.9044 - val_loss: 0.3527 - val_accuracy: 0.8914\n",
      "Epoch 132/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2804 - accuracy: 0.9038 - val_loss: 0.3248 - val_accuracy: 0.8973\n",
      "Epoch 133/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2788 - accuracy: 0.9060 - val_loss: 0.3311 - val_accuracy: 0.8953\n",
      "Epoch 134/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2756 - accuracy: 0.9064 - val_loss: 0.3575 - val_accuracy: 0.8861\n",
      "Epoch 135/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2819 - accuracy: 0.9042 - val_loss: 0.3763 - val_accuracy: 0.8844\n",
      "Epoch 136/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2784 - accuracy: 0.9050 - val_loss: 0.3367 - val_accuracy: 0.8930\n",
      "Epoch 137/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2800 - accuracy: 0.9055 - val_loss: 0.3251 - val_accuracy: 0.8982\n",
      "Epoch 138/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2761 - accuracy: 0.9046 - val_loss: 0.3363 - val_accuracy: 0.8944\n",
      "Epoch 139/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2758 - accuracy: 0.9067 - val_loss: 0.3467 - val_accuracy: 0.8907\n",
      "Epoch 140/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2748 - accuracy: 0.9057 - val_loss: 0.3967 - val_accuracy: 0.8792\n",
      "Epoch 141/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2761 - accuracy: 0.9042 - val_loss: 0.3282 - val_accuracy: 0.8972\n",
      "Epoch 142/400\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.2745 - accuracy: 0.9064 - val_loss: 0.3465 - val_accuracy: 0.8915\n",
      "Epoch 143/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2725 - accuracy: 0.9071 - val_loss: 0.3840 - val_accuracy: 0.8860\n",
      "Epoch 144/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2735 - accuracy: 0.9056 - val_loss: 0.3245 - val_accuracy: 0.8988\n",
      "Epoch 145/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2755 - accuracy: 0.9056 - val_loss: 0.3462 - val_accuracy: 0.8918\n",
      "Epoch 146/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2681 - accuracy: 0.9078 - val_loss: 0.3621 - val_accuracy: 0.8908\n",
      "Epoch 147/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2722 - accuracy: 0.9071 - val_loss: 0.3561 - val_accuracy: 0.8894\n",
      "Epoch 148/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2726 - accuracy: 0.9073 - val_loss: 0.3402 - val_accuracy: 0.8952\n",
      "Epoch 149/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2718 - accuracy: 0.9066 - val_loss: 0.3583 - val_accuracy: 0.8906\n",
      "Epoch 150/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2736 - accuracy: 0.9072 - val_loss: 0.3313 - val_accuracy: 0.8951\n",
      "Epoch 151/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2740 - accuracy: 0.9063 - val_loss: 0.3465 - val_accuracy: 0.8937\n",
      "Epoch 152/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2679 - accuracy: 0.9089 - val_loss: 0.3877 - val_accuracy: 0.8843\n",
      "Epoch 153/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2657 - accuracy: 0.9087 - val_loss: 0.3906 - val_accuracy: 0.8868\n",
      "Epoch 154/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2666 - accuracy: 0.9099 - val_loss: 0.3623 - val_accuracy: 0.8923\n",
      "Epoch 155/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2693 - accuracy: 0.9085 - val_loss: 0.3555 - val_accuracy: 0.8895\n",
      "Epoch 156/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2654 - accuracy: 0.9090 - val_loss: 0.3391 - val_accuracy: 0.8947\n",
      "Epoch 157/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2641 - accuracy: 0.9094 - val_loss: 0.3240 - val_accuracy: 0.8964\n",
      "Epoch 158/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2649 - accuracy: 0.9095 - val_loss: 0.3414 - val_accuracy: 0.8948\n",
      "Epoch 159/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2603 - accuracy: 0.9098 - val_loss: 0.3365 - val_accuracy: 0.8971\n",
      "Epoch 160/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2662 - accuracy: 0.9088 - val_loss: 0.3559 - val_accuracy: 0.8913\n",
      "Epoch 161/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2626 - accuracy: 0.9109 - val_loss: 0.3884 - val_accuracy: 0.8828\n",
      "Epoch 162/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2598 - accuracy: 0.9111 - val_loss: 0.3697 - val_accuracy: 0.8861\n",
      "Epoch 163/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2630 - accuracy: 0.9099 - val_loss: 0.3491 - val_accuracy: 0.8907\n",
      "Epoch 164/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2645 - accuracy: 0.9100 - val_loss: 0.3471 - val_accuracy: 0.8923\n",
      "Epoch 165/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2652 - accuracy: 0.9108 - val_loss: 0.3189 - val_accuracy: 0.9009\n",
      "Epoch 166/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2597 - accuracy: 0.9121 - val_loss: 0.3312 - val_accuracy: 0.8983\n",
      "Epoch 167/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2575 - accuracy: 0.9119 - val_loss: 0.3384 - val_accuracy: 0.8969\n",
      "Epoch 168/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2595 - accuracy: 0.9109 - val_loss: 0.3378 - val_accuracy: 0.8929\n",
      "Epoch 169/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2590 - accuracy: 0.9117 - val_loss: 0.3393 - val_accuracy: 0.8960\n",
      "Epoch 170/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2570 - accuracy: 0.9119 - val_loss: 0.3141 - val_accuracy: 0.9022\n",
      "Epoch 171/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2594 - accuracy: 0.9115 - val_loss: 0.3316 - val_accuracy: 0.8978\n",
      "Epoch 172/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2631 - accuracy: 0.9106 - val_loss: 0.3162 - val_accuracy: 0.9023\n",
      "Epoch 173/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2560 - accuracy: 0.9121 - val_loss: 0.3405 - val_accuracy: 0.8928\n",
      "Epoch 174/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2602 - accuracy: 0.9116 - val_loss: 0.3351 - val_accuracy: 0.8984\n",
      "Epoch 175/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2607 - accuracy: 0.9120 - val_loss: 0.3317 - val_accuracy: 0.8954\n",
      "Epoch 176/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2548 - accuracy: 0.9130 - val_loss: 0.3375 - val_accuracy: 0.8958\n",
      "Epoch 177/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2536 - accuracy: 0.9135 - val_loss: 0.3480 - val_accuracy: 0.8908\n",
      "Epoch 178/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2554 - accuracy: 0.9133 - val_loss: 0.3519 - val_accuracy: 0.8896\n",
      "Epoch 179/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2579 - accuracy: 0.9125 - val_loss: 0.3466 - val_accuracy: 0.8934\n",
      "Epoch 180/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2584 - accuracy: 0.9128 - val_loss: 0.3694 - val_accuracy: 0.8876\n",
      "Epoch 181/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2547 - accuracy: 0.9135 - val_loss: 0.3515 - val_accuracy: 0.8920\n",
      "Epoch 182/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2555 - accuracy: 0.9124 - val_loss: 0.3238 - val_accuracy: 0.9009\n",
      "Epoch 183/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2574 - accuracy: 0.9129 - val_loss: 0.3641 - val_accuracy: 0.8916\n",
      "Epoch 184/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2558 - accuracy: 0.9137 - val_loss: 0.3377 - val_accuracy: 0.8979\n",
      "Epoch 185/400\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.2564 - accuracy: 0.9132 - val_loss: 0.3202 - val_accuracy: 0.9006\n",
      "Epoch 186/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2508 - accuracy: 0.9146 - val_loss: 0.3353 - val_accuracy: 0.8950\n",
      "Epoch 187/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2524 - accuracy: 0.9137 - val_loss: 0.3300 - val_accuracy: 0.9003\n",
      "Epoch 188/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2535 - accuracy: 0.9130 - val_loss: 0.3295 - val_accuracy: 0.8982\n",
      "Epoch 189/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2502 - accuracy: 0.9144 - val_loss: 0.3392 - val_accuracy: 0.8948\n",
      "Epoch 190/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2541 - accuracy: 0.9140 - val_loss: 0.3365 - val_accuracy: 0.8948\n",
      "Epoch 191/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2520 - accuracy: 0.9142 - val_loss: 0.3296 - val_accuracy: 0.8994\n",
      "Epoch 192/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2536 - accuracy: 0.9135 - val_loss: 0.3348 - val_accuracy: 0.9018\n",
      "Epoch 193/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2496 - accuracy: 0.9137 - val_loss: 0.3473 - val_accuracy: 0.8929\n",
      "Epoch 194/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2505 - accuracy: 0.9154 - val_loss: 0.3417 - val_accuracy: 0.8943\n",
      "Epoch 195/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2495 - accuracy: 0.9149 - val_loss: 0.4072 - val_accuracy: 0.8772\n",
      "Epoch 196/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2521 - accuracy: 0.9138 - val_loss: 0.3573 - val_accuracy: 0.8956\n",
      "Epoch 197/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2531 - accuracy: 0.9134 - val_loss: 0.3392 - val_accuracy: 0.8964\n",
      "Epoch 198/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2481 - accuracy: 0.9142 - val_loss: 0.3820 - val_accuracy: 0.8883\n",
      "Epoch 199/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2517 - accuracy: 0.9144 - val_loss: 0.3606 - val_accuracy: 0.8896\n",
      "Epoch 200/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2501 - accuracy: 0.9145 - val_loss: 0.3342 - val_accuracy: 0.8956\n",
      "Epoch 201/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2474 - accuracy: 0.9154 - val_loss: 0.3301 - val_accuracy: 0.8991\n",
      "Epoch 202/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2458 - accuracy: 0.9154 - val_loss: 0.3497 - val_accuracy: 0.8939\n",
      "Epoch 203/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2465 - accuracy: 0.9161 - val_loss: 0.3426 - val_accuracy: 0.8997\n",
      "Epoch 204/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2484 - accuracy: 0.9144 - val_loss: 0.3521 - val_accuracy: 0.8928\n",
      "Epoch 205/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2441 - accuracy: 0.9166 - val_loss: 0.3377 - val_accuracy: 0.8945\n",
      "Epoch 206/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2492 - accuracy: 0.9143 - val_loss: 0.4073 - val_accuracy: 0.8797\n",
      "Epoch 207/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2481 - accuracy: 0.9148 - val_loss: 0.3211 - val_accuracy: 0.9020\n",
      "Epoch 208/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2517 - accuracy: 0.9148 - val_loss: 0.3110 - val_accuracy: 0.9028\n",
      "Epoch 209/400\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.2438 - accuracy: 0.9166 - val_loss: 0.3149 - val_accuracy: 0.9009\n",
      "Epoch 210/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2433 - accuracy: 0.9166 - val_loss: 0.3225 - val_accuracy: 0.9029\n",
      "Epoch 211/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2443 - accuracy: 0.9182 - val_loss: 0.3287 - val_accuracy: 0.8985\n",
      "Epoch 212/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2414 - accuracy: 0.9159 - val_loss: 0.3487 - val_accuracy: 0.8960\n",
      "Epoch 213/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2470 - accuracy: 0.9162 - val_loss: 0.3014 - val_accuracy: 0.9060\n",
      "Epoch 214/400\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.2428 - accuracy: 0.9174 - val_loss: 0.3368 - val_accuracy: 0.9001\n",
      "Epoch 215/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2507 - accuracy: 0.9151 - val_loss: 0.3537 - val_accuracy: 0.8939\n",
      "Epoch 216/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2426 - accuracy: 0.9177 - val_loss: 0.3570 - val_accuracy: 0.8951\n",
      "Epoch 217/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2429 - accuracy: 0.9169 - val_loss: 0.3503 - val_accuracy: 0.8967\n",
      "Epoch 218/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2448 - accuracy: 0.9154 - val_loss: 0.3348 - val_accuracy: 0.8967\n",
      "Epoch 219/400\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.2423 - accuracy: 0.9174 - val_loss: 0.3159 - val_accuracy: 0.9030\n",
      "Epoch 220/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2429 - accuracy: 0.9175 - val_loss: 0.3331 - val_accuracy: 0.8980\n",
      "Epoch 221/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2374 - accuracy: 0.9185 - val_loss: 0.3161 - val_accuracy: 0.9021\n",
      "Epoch 222/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2416 - accuracy: 0.9175 - val_loss: 0.3158 - val_accuracy: 0.9009\n",
      "Epoch 223/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2416 - accuracy: 0.9183 - val_loss: 0.3420 - val_accuracy: 0.8930\n",
      "Epoch 224/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2427 - accuracy: 0.9184 - val_loss: 0.3166 - val_accuracy: 0.9065\n",
      "Epoch 225/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2448 - accuracy: 0.9166 - val_loss: 0.3224 - val_accuracy: 0.9009\n",
      "Epoch 226/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2362 - accuracy: 0.9184 - val_loss: 0.3551 - val_accuracy: 0.8930\n",
      "Epoch 227/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2434 - accuracy: 0.9165 - val_loss: 0.3156 - val_accuracy: 0.9006\n",
      "Epoch 228/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2461 - accuracy: 0.9156 - val_loss: 0.3435 - val_accuracy: 0.8964\n",
      "Epoch 229/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2437 - accuracy: 0.9175 - val_loss: 0.3308 - val_accuracy: 0.8997\n",
      "Epoch 230/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2427 - accuracy: 0.9166 - val_loss: 0.3617 - val_accuracy: 0.8911\n",
      "Epoch 231/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2388 - accuracy: 0.9185 - val_loss: 0.3659 - val_accuracy: 0.8889\n",
      "Epoch 232/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2404 - accuracy: 0.9193 - val_loss: 0.3516 - val_accuracy: 0.8935\n",
      "Epoch 233/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2397 - accuracy: 0.9197 - val_loss: 0.3203 - val_accuracy: 0.9033\n",
      "Epoch 234/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2406 - accuracy: 0.9175 - val_loss: 0.3129 - val_accuracy: 0.9049\n",
      "Epoch 235/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2340 - accuracy: 0.9190 - val_loss: 0.3393 - val_accuracy: 0.8980\n",
      "Epoch 236/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2386 - accuracy: 0.9200 - val_loss: 0.3321 - val_accuracy: 0.8993\n",
      "Epoch 237/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2381 - accuracy: 0.9189 - val_loss: 0.3156 - val_accuracy: 0.9064\n",
      "Epoch 238/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2401 - accuracy: 0.9181 - val_loss: 0.3329 - val_accuracy: 0.8991\n",
      "Epoch 239/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2358 - accuracy: 0.9192 - val_loss: 0.3405 - val_accuracy: 0.8975\n",
      "Epoch 240/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2333 - accuracy: 0.9196 - val_loss: 0.3098 - val_accuracy: 0.9062\n",
      "Epoch 241/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2326 - accuracy: 0.9204 - val_loss: 0.3649 - val_accuracy: 0.8922\n",
      "Epoch 242/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2364 - accuracy: 0.9187 - val_loss: 0.3865 - val_accuracy: 0.8843\n",
      "Epoch 243/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2344 - accuracy: 0.9196 - val_loss: 0.3700 - val_accuracy: 0.8893\n",
      "Epoch 244/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2383 - accuracy: 0.9191 - val_loss: 0.3574 - val_accuracy: 0.8951\n",
      "Epoch 245/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2348 - accuracy: 0.9208 - val_loss: 0.3373 - val_accuracy: 0.8972\n",
      "Epoch 246/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2339 - accuracy: 0.9205 - val_loss: 0.3709 - val_accuracy: 0.8935\n",
      "Epoch 247/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2318 - accuracy: 0.9209 - val_loss: 0.3886 - val_accuracy: 0.8876\n",
      "Epoch 248/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2344 - accuracy: 0.9205 - val_loss: 0.3509 - val_accuracy: 0.8976\n",
      "Epoch 249/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2346 - accuracy: 0.9197 - val_loss: 0.3374 - val_accuracy: 0.8989\n",
      "Epoch 250/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2335 - accuracy: 0.9202 - val_loss: 0.3368 - val_accuracy: 0.8988\n",
      "Epoch 251/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2360 - accuracy: 0.9209 - val_loss: 0.3204 - val_accuracy: 0.8989\n",
      "Epoch 252/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2353 - accuracy: 0.9195 - val_loss: 0.3383 - val_accuracy: 0.8984\n",
      "Epoch 253/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2300 - accuracy: 0.9213 - val_loss: 0.3297 - val_accuracy: 0.8993\n",
      "Epoch 254/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2362 - accuracy: 0.9196 - val_loss: 0.3212 - val_accuracy: 0.9002\n",
      "Epoch 255/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2354 - accuracy: 0.9198 - val_loss: 0.3649 - val_accuracy: 0.8936\n",
      "Epoch 256/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2292 - accuracy: 0.9217 - val_loss: 0.3440 - val_accuracy: 0.8986\n",
      "Epoch 257/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2343 - accuracy: 0.9201 - val_loss: 0.3409 - val_accuracy: 0.9004\n",
      "Epoch 258/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2329 - accuracy: 0.9197 - val_loss: 0.3095 - val_accuracy: 0.9072\n",
      "Epoch 259/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2373 - accuracy: 0.9189 - val_loss: 0.3348 - val_accuracy: 0.8979\n",
      "Epoch 260/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2321 - accuracy: 0.9204 - val_loss: 0.3202 - val_accuracy: 0.9008\n",
      "Epoch 261/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2333 - accuracy: 0.9201 - val_loss: 0.3215 - val_accuracy: 0.9018\n",
      "Epoch 262/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2328 - accuracy: 0.9207 - val_loss: 0.3319 - val_accuracy: 0.8968\n",
      "Epoch 263/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2317 - accuracy: 0.9213 - val_loss: 0.3397 - val_accuracy: 0.8976\n",
      "Epoch 264/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2333 - accuracy: 0.9202 - val_loss: 0.3357 - val_accuracy: 0.9007\n",
      "Epoch 265/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2326 - accuracy: 0.9205 - val_loss: 0.3273 - val_accuracy: 0.9010\n",
      "Epoch 266/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2284 - accuracy: 0.9225 - val_loss: 0.3174 - val_accuracy: 0.9056\n",
      "Epoch 267/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2339 - accuracy: 0.9207 - val_loss: 0.3024 - val_accuracy: 0.9052\n",
      "Epoch 268/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2346 - accuracy: 0.9201 - val_loss: 0.3154 - val_accuracy: 0.9011\n",
      "Epoch 269/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2285 - accuracy: 0.9210 - val_loss: 0.3238 - val_accuracy: 0.9023\n",
      "Epoch 270/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2320 - accuracy: 0.9219 - val_loss: 0.3370 - val_accuracy: 0.8974\n",
      "Epoch 271/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2286 - accuracy: 0.9221 - val_loss: 0.3246 - val_accuracy: 0.9013\n",
      "Epoch 272/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2277 - accuracy: 0.9217 - val_loss: 0.3724 - val_accuracy: 0.8898\n",
      "Epoch 273/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2300 - accuracy: 0.9218 - val_loss: 0.3261 - val_accuracy: 0.9005\n",
      "Epoch 274/400\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.2266 - accuracy: 0.9233 - val_loss: 0.3891 - val_accuracy: 0.8903\n",
      "Epoch 275/400\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.2298 - accuracy: 0.9214 - val_loss: 0.3297 - val_accuracy: 0.9017\n",
      "Epoch 276/400\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.2261 - accuracy: 0.9233 - val_loss: 0.3372 - val_accuracy: 0.8985\n",
      "Epoch 277/400\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.2285 - accuracy: 0.9217 - val_loss: 0.3217 - val_accuracy: 0.9029\n",
      "Epoch 278/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2300 - accuracy: 0.9213 - val_loss: 0.3490 - val_accuracy: 0.8969\n",
      "Epoch 279/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2275 - accuracy: 0.9220 - val_loss: 0.3619 - val_accuracy: 0.8943\n",
      "Epoch 280/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2254 - accuracy: 0.9235 - val_loss: 0.3390 - val_accuracy: 0.9005\n",
      "Epoch 281/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2254 - accuracy: 0.9227 - val_loss: 0.3729 - val_accuracy: 0.8910\n",
      "Epoch 282/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2263 - accuracy: 0.9235 - val_loss: 0.3341 - val_accuracy: 0.8993\n",
      "Epoch 283/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2250 - accuracy: 0.9230 - val_loss: 0.3297 - val_accuracy: 0.9006\n",
      "Epoch 284/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2308 - accuracy: 0.9212 - val_loss: 0.3269 - val_accuracy: 0.9029\n",
      "Epoch 285/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2274 - accuracy: 0.9231 - val_loss: 0.3222 - val_accuracy: 0.9051\n",
      "Epoch 286/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2274 - accuracy: 0.9230 - val_loss: 0.3195 - val_accuracy: 0.9033\n",
      "Epoch 287/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2262 - accuracy: 0.9230 - val_loss: 0.3329 - val_accuracy: 0.9008\n",
      "Epoch 288/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2263 - accuracy: 0.9216 - val_loss: 0.3210 - val_accuracy: 0.9011\n",
      "Epoch 289/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2263 - accuracy: 0.9241 - val_loss: 0.3524 - val_accuracy: 0.8984\n",
      "Epoch 290/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2256 - accuracy: 0.9227 - val_loss: 0.3202 - val_accuracy: 0.9038\n",
      "Epoch 291/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2257 - accuracy: 0.9226 - val_loss: 0.3296 - val_accuracy: 0.8995\n",
      "Epoch 292/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2212 - accuracy: 0.9241 - val_loss: 0.3335 - val_accuracy: 0.8986\n",
      "Epoch 293/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2237 - accuracy: 0.9236 - val_loss: 0.3208 - val_accuracy: 0.9011\n",
      "Epoch 294/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2275 - accuracy: 0.9231 - val_loss: 0.3599 - val_accuracy: 0.8945\n",
      "Epoch 295/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2263 - accuracy: 0.9221 - val_loss: 0.3387 - val_accuracy: 0.8977\n",
      "Epoch 296/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2247 - accuracy: 0.9237 - val_loss: 0.3339 - val_accuracy: 0.9008\n",
      "Epoch 297/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2219 - accuracy: 0.9235 - val_loss: 0.3352 - val_accuracy: 0.9035\n",
      "Epoch 298/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2237 - accuracy: 0.9229 - val_loss: 0.3236 - val_accuracy: 0.9054\n",
      "Epoch 299/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2247 - accuracy: 0.9235 - val_loss: 0.3502 - val_accuracy: 0.8993\n",
      "Epoch 300/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2267 - accuracy: 0.9218 - val_loss: 0.3125 - val_accuracy: 0.9056\n",
      "Epoch 301/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2226 - accuracy: 0.9239 - val_loss: 0.3054 - val_accuracy: 0.9075\n",
      "Epoch 302/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2192 - accuracy: 0.9258 - val_loss: 0.3166 - val_accuracy: 0.9023\n",
      "Epoch 303/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2237 - accuracy: 0.9229 - val_loss: 0.3448 - val_accuracy: 0.8984\n",
      "Epoch 304/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2237 - accuracy: 0.9230 - val_loss: 0.3196 - val_accuracy: 0.9031\n",
      "Epoch 305/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2239 - accuracy: 0.9238 - val_loss: 0.3291 - val_accuracy: 0.9055\n",
      "Epoch 306/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2214 - accuracy: 0.9238 - val_loss: 0.3236 - val_accuracy: 0.9012\n",
      "Epoch 307/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2219 - accuracy: 0.9240 - val_loss: 0.3602 - val_accuracy: 0.8927\n",
      "Epoch 308/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2232 - accuracy: 0.9243 - val_loss: 0.3442 - val_accuracy: 0.8969\n",
      "Epoch 309/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2166 - accuracy: 0.9261 - val_loss: 0.3311 - val_accuracy: 0.9024\n",
      "Epoch 310/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2170 - accuracy: 0.9246 - val_loss: 0.3233 - val_accuracy: 0.9045\n",
      "Epoch 311/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2213 - accuracy: 0.9254 - val_loss: 0.3210 - val_accuracy: 0.9034\n",
      "Epoch 312/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2190 - accuracy: 0.9250 - val_loss: 0.3181 - val_accuracy: 0.9028\n",
      "Epoch 313/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2228 - accuracy: 0.9250 - val_loss: 0.3392 - val_accuracy: 0.9007\n",
      "Epoch 314/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2225 - accuracy: 0.9243 - val_loss: 0.3246 - val_accuracy: 0.9031\n",
      "Epoch 315/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2200 - accuracy: 0.9252 - val_loss: 0.3304 - val_accuracy: 0.9008\n",
      "Epoch 316/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2186 - accuracy: 0.9257 - val_loss: 0.3130 - val_accuracy: 0.9050\n",
      "Epoch 317/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2192 - accuracy: 0.9237 - val_loss: 0.3351 - val_accuracy: 0.9001\n",
      "Epoch 318/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2200 - accuracy: 0.9241 - val_loss: 0.3182 - val_accuracy: 0.9047\n",
      "Epoch 319/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2221 - accuracy: 0.9247 - val_loss: 0.3166 - val_accuracy: 0.9030\n",
      "Epoch 320/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2165 - accuracy: 0.9258 - val_loss: 0.3553 - val_accuracy: 0.8984\n",
      "Epoch 321/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2174 - accuracy: 0.9248 - val_loss: 0.3356 - val_accuracy: 0.9025\n",
      "Epoch 322/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2238 - accuracy: 0.9249 - val_loss: 0.3048 - val_accuracy: 0.9076\n",
      "Epoch 323/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2198 - accuracy: 0.9254 - val_loss: 0.3145 - val_accuracy: 0.9028\n",
      "Epoch 324/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2183 - accuracy: 0.9254 - val_loss: 0.3263 - val_accuracy: 0.9036\n",
      "Epoch 325/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2181 - accuracy: 0.9257 - val_loss: 0.3499 - val_accuracy: 0.8976\n",
      "Epoch 326/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2188 - accuracy: 0.9262 - val_loss: 0.3462 - val_accuracy: 0.8967\n",
      "Epoch 327/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2161 - accuracy: 0.9266 - val_loss: 0.3572 - val_accuracy: 0.8984\n",
      "Epoch 328/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2221 - accuracy: 0.9244 - val_loss: 0.3028 - val_accuracy: 0.9061\n",
      "Epoch 329/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2181 - accuracy: 0.9256 - val_loss: 0.3386 - val_accuracy: 0.9001\n",
      "Epoch 330/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2180 - accuracy: 0.9252 - val_loss: 0.3094 - val_accuracy: 0.9053\n",
      "Epoch 331/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2148 - accuracy: 0.9261 - val_loss: 0.3281 - val_accuracy: 0.9011\n",
      "Epoch 332/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2220 - accuracy: 0.9240 - val_loss: 0.2962 - val_accuracy: 0.9092\n",
      "Epoch 333/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2187 - accuracy: 0.9263 - val_loss: 0.3314 - val_accuracy: 0.9032\n",
      "Epoch 334/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2125 - accuracy: 0.9266 - val_loss: 0.3554 - val_accuracy: 0.8985\n",
      "Epoch 335/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2190 - accuracy: 0.9258 - val_loss: 0.3257 - val_accuracy: 0.9012\n",
      "Epoch 336/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2171 - accuracy: 0.9256 - val_loss: 0.3259 - val_accuracy: 0.9045\n",
      "Epoch 337/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2166 - accuracy: 0.9257 - val_loss: 0.3478 - val_accuracy: 0.9014\n",
      "Epoch 338/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2154 - accuracy: 0.9263 - val_loss: 0.3494 - val_accuracy: 0.8963\n",
      "Epoch 339/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2156 - accuracy: 0.9255 - val_loss: 0.3141 - val_accuracy: 0.9022\n",
      "Epoch 340/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2086 - accuracy: 0.9291 - val_loss: 0.3384 - val_accuracy: 0.9000\n",
      "Epoch 341/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2123 - accuracy: 0.9273 - val_loss: 0.3229 - val_accuracy: 0.9049\n",
      "Epoch 342/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2172 - accuracy: 0.9266 - val_loss: 0.3711 - val_accuracy: 0.8922\n",
      "Epoch 343/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2144 - accuracy: 0.9265 - val_loss: 0.3233 - val_accuracy: 0.9045\n",
      "Epoch 344/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2195 - accuracy: 0.9245 - val_loss: 0.3366 - val_accuracy: 0.8992\n",
      "Epoch 345/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2141 - accuracy: 0.9263 - val_loss: 0.3165 - val_accuracy: 0.9016\n",
      "Epoch 346/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2195 - accuracy: 0.9242 - val_loss: 0.3468 - val_accuracy: 0.8997\n",
      "Epoch 347/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2141 - accuracy: 0.9270 - val_loss: 0.3109 - val_accuracy: 0.9034\n",
      "Epoch 348/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2104 - accuracy: 0.9278 - val_loss: 0.3097 - val_accuracy: 0.9092\n",
      "Epoch 349/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2139 - accuracy: 0.9277 - val_loss: 0.3490 - val_accuracy: 0.8957\n",
      "Epoch 350/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2130 - accuracy: 0.9282 - val_loss: 0.3084 - val_accuracy: 0.9069\n",
      "Epoch 351/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2110 - accuracy: 0.9277 - val_loss: 0.3218 - val_accuracy: 0.9018\n",
      "Epoch 352/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2180 - accuracy: 0.9265 - val_loss: 0.3165 - val_accuracy: 0.9036\n",
      "Epoch 353/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2105 - accuracy: 0.9280 - val_loss: 0.3555 - val_accuracy: 0.8992\n",
      "Epoch 354/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2119 - accuracy: 0.9271 - val_loss: 0.3293 - val_accuracy: 0.8993\n",
      "Epoch 355/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2102 - accuracy: 0.9276 - val_loss: 0.3734 - val_accuracy: 0.8911\n",
      "Epoch 356/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2085 - accuracy: 0.9277 - val_loss: 0.3280 - val_accuracy: 0.9032\n",
      "Epoch 357/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2097 - accuracy: 0.9281 - val_loss: 0.3510 - val_accuracy: 0.9009\n",
      "Epoch 358/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2080 - accuracy: 0.9293 - val_loss: 0.3375 - val_accuracy: 0.9021\n",
      "Epoch 359/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2107 - accuracy: 0.9277 - val_loss: 0.3289 - val_accuracy: 0.9024\n",
      "Epoch 360/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2117 - accuracy: 0.9271 - val_loss: 0.3309 - val_accuracy: 0.9028\n",
      "Epoch 361/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2115 - accuracy: 0.9272 - val_loss: 0.2976 - val_accuracy: 0.9092\n",
      "Epoch 362/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2124 - accuracy: 0.9277 - val_loss: 0.3232 - val_accuracy: 0.9049\n",
      "Epoch 363/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2082 - accuracy: 0.9277 - val_loss: 0.3344 - val_accuracy: 0.9009\n",
      "Epoch 364/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2099 - accuracy: 0.9282 - val_loss: 0.3196 - val_accuracy: 0.9061\n",
      "Epoch 365/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2110 - accuracy: 0.9267 - val_loss: 0.3215 - val_accuracy: 0.9096\n",
      "Epoch 366/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2104 - accuracy: 0.9268 - val_loss: 0.3327 - val_accuracy: 0.9009\n",
      "Epoch 367/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2111 - accuracy: 0.9282 - val_loss: 0.3520 - val_accuracy: 0.8950\n",
      "Epoch 368/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2091 - accuracy: 0.9277 - val_loss: 0.3373 - val_accuracy: 0.9025\n",
      "Epoch 369/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2079 - accuracy: 0.9289 - val_loss: 0.3155 - val_accuracy: 0.9052\n",
      "Epoch 370/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2099 - accuracy: 0.9289 - val_loss: 0.3266 - val_accuracy: 0.9034\n",
      "Epoch 371/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2121 - accuracy: 0.9278 - val_loss: 0.3084 - val_accuracy: 0.9084\n",
      "Epoch 372/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2044 - accuracy: 0.9313 - val_loss: 0.3451 - val_accuracy: 0.8975\n",
      "Epoch 373/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2070 - accuracy: 0.9287 - val_loss: 0.3303 - val_accuracy: 0.9055\n",
      "Epoch 374/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2120 - accuracy: 0.9286 - val_loss: 0.3492 - val_accuracy: 0.9013\n",
      "Epoch 375/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2133 - accuracy: 0.9273 - val_loss: 0.3095 - val_accuracy: 0.9038\n",
      "Epoch 376/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2104 - accuracy: 0.9271 - val_loss: 0.3319 - val_accuracy: 0.9011\n",
      "Epoch 377/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2077 - accuracy: 0.9282 - val_loss: 0.3115 - val_accuracy: 0.9055\n",
      "Epoch 378/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2093 - accuracy: 0.9281 - val_loss: 0.3268 - val_accuracy: 0.9032\n",
      "Epoch 379/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2065 - accuracy: 0.9295 - val_loss: 0.3357 - val_accuracy: 0.9048\n",
      "Epoch 380/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2130 - accuracy: 0.9273 - val_loss: 0.3049 - val_accuracy: 0.9086\n",
      "Epoch 381/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2075 - accuracy: 0.9294 - val_loss: 0.3172 - val_accuracy: 0.9063\n",
      "Epoch 382/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2094 - accuracy: 0.9287 - val_loss: 0.3408 - val_accuracy: 0.8976\n",
      "Epoch 383/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2053 - accuracy: 0.9299 - val_loss: 0.3555 - val_accuracy: 0.8971\n",
      "Epoch 384/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2052 - accuracy: 0.9294 - val_loss: 0.3444 - val_accuracy: 0.9007\n",
      "Epoch 385/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2117 - accuracy: 0.9277 - val_loss: 0.3459 - val_accuracy: 0.9002\n",
      "Epoch 386/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2083 - accuracy: 0.9290 - val_loss: 0.3209 - val_accuracy: 0.9052\n",
      "Epoch 387/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2077 - accuracy: 0.9291 - val_loss: 0.3330 - val_accuracy: 0.9001\n",
      "Epoch 388/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2103 - accuracy: 0.9281 - val_loss: 0.3456 - val_accuracy: 0.8995\n",
      "Epoch 389/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2056 - accuracy: 0.9298 - val_loss: 0.3087 - val_accuracy: 0.9072\n",
      "Epoch 390/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2062 - accuracy: 0.9294 - val_loss: 0.3014 - val_accuracy: 0.9089\n",
      "Epoch 391/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2090 - accuracy: 0.9292 - val_loss: 0.3378 - val_accuracy: 0.9002\n",
      "Epoch 392/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2085 - accuracy: 0.9285 - val_loss: 0.3142 - val_accuracy: 0.9068\n",
      "Epoch 393/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2109 - accuracy: 0.9277 - val_loss: 0.3039 - val_accuracy: 0.9056\n",
      "Epoch 394/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2039 - accuracy: 0.9314 - val_loss: 0.3398 - val_accuracy: 0.8986\n",
      "Epoch 395/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2070 - accuracy: 0.9286 - val_loss: 0.3674 - val_accuracy: 0.8952\n",
      "Epoch 396/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2090 - accuracy: 0.9287 - val_loss: 0.3117 - val_accuracy: 0.9043\n",
      "Epoch 397/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2052 - accuracy: 0.9286 - val_loss: 0.3779 - val_accuracy: 0.8931\n",
      "Epoch 398/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2082 - accuracy: 0.9291 - val_loss: 0.3204 - val_accuracy: 0.9058\n",
      "Epoch 399/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2067 - accuracy: 0.9287 - val_loss: 0.3357 - val_accuracy: 0.9001\n",
      "Epoch 400/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2088 - accuracy: 0.9279 - val_loss: 0.3433 - val_accuracy: 0.9005\n",
      "\n",
      "Best score (highest validation accuracy) found via grid search: accuracy=0.900500 from model iteration #2\n",
      "The best modeling parameters are: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f28fc29bc50>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f28fc248a20>, epochs=400, batch_size=64\n",
      "Total time for performing grid-search of the best parameters: 13:24:59.348892\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Set up grid search using different epochs, batch sizes, and optimizers\n",
    "optz_1 = tf.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "optz_2 = tf.optimizers.Adam(learning_rate=0.001)\n",
    "optz_3 = tf.optimizers.RMSprop(learning_rate=0.001)\n",
    "optz_4 = tf.optimizers.SGD(learning_rate=0.0005, momentum=0.9)\n",
    "optz_5 = tf.optimizers.Adam(learning_rate=0.0005)\n",
    "optz_6 = tf.optimizers.RMSprop(learning_rate=0.0005)\n",
    "optimizer_grid = [optz_1, optz_2, optz_3]\n",
    "print('Optimizer candidate #1 has the object ID of', optz_1)\n",
    "print('Optimizer candidate #2 has the object ID of', optz_2)\n",
    "print('Optimizer candidate #3 has the object ID of', optz_3)\n",
    "print('Optimizer candidate #4 has the object ID of', optz_1)\n",
    "print('Optimizer candidate #5 has the object ID of', optz_2)\n",
    "print('Optimizer candidate #6 has the object ID of', optz_3)\n",
    "\n",
    "init_1 = tf.initializers.he_uniform(seed=seedNum)\n",
    "init_grid = [init_1]\n",
    "print('Initializer candidate #1 has the object ID of', init_1)\n",
    "\n",
    "epoch_grid = [default_epoch]\n",
    "batch_grid = [default_batch]\n",
    "\n",
    "best_score = 0\n",
    "grid_iteration = 0\n",
    "best_iteration = 0\n",
    "best_optimizer = default_optimizer\n",
    "best_kernel_init = default_kernel_init\n",
    "best_epoch = default_epoch\n",
    "best_batch = default_batch\n",
    "\n",
    "for optimizer in optimizer_grid:\n",
    "    for kernel_init in init_grid:\n",
    "        for epoch_num in epoch_grid:\n",
    "            for batch_num in batch_grid:\n",
    "                print('\\nForming the grid-search model #%d using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "                      % (grid_iteration, optimizer, kernel_init, epoch_num, batch_num))\n",
    "                reset_random(seedNum)\n",
    "                grid_model = create_customized_model(optimizer, kernel_init)\n",
    "                grid_hist = grid_model.fit(X_train_aug, steps_per_epoch=steps, epochs=epoch_num, validation_data=(X_test, y_test), verbose=1)\n",
    "                if(grid_hist.history['val_accuracy'][-1] > best_score):\n",
    "                    best_score = grid_hist.history['val_accuracy'][-1]\n",
    "                    best_iteration = grid_iteration\n",
    "                    best_optimizer = optimizer\n",
    "                    best_kernel_init = kernel_init\n",
    "                    best_epoch = epoch_num\n",
    "                    best_batch = batch_num\n",
    "                grid_iteration = grid_iteration + 1\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest score (highest validation accuracy) found via grid search: accuracy=%f from model iteration #%d\"\n",
    "      % (best_score, best_iteration))\n",
    "print('The best modeling parameters are: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "print('Total time for performing grid-search of the best parameters:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the final model using: optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f28fc29bc50>, kernel=<tensorflow.python.ops.init_ops_v2.VarianceScaling object at 0x7f28fc248a20>, epochs=400, batch_size=64\n",
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 1.7007 - accuracy: 0.4231 - val_loss: 1.2337 - val_accuracy: 0.5769\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 1.1315 - accuracy: 0.5982 - val_loss: 0.8734 - val_accuracy: 0.6894\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.9568 - accuracy: 0.6634 - val_loss: 0.7749 - val_accuracy: 0.7260\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.8645 - accuracy: 0.6973 - val_loss: 0.7080 - val_accuracy: 0.7498\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.8004 - accuracy: 0.7212 - val_loss: 0.6425 - val_accuracy: 0.7790\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.7545 - accuracy: 0.7403 - val_loss: 0.7422 - val_accuracy: 0.7472\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.7165 - accuracy: 0.7551 - val_loss: 0.6619 - val_accuracy: 0.7755\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6901 - accuracy: 0.7660 - val_loss: 0.6418 - val_accuracy: 0.7826\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.6528 - accuracy: 0.7783 - val_loss: 0.6394 - val_accuracy: 0.7875\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.6329 - accuracy: 0.7837 - val_loss: 0.5975 - val_accuracy: 0.7989\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.6111 - accuracy: 0.7925 - val_loss: 0.5252 - val_accuracy: 0.8193\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5897 - accuracy: 0.7990 - val_loss: 0.5485 - val_accuracy: 0.8173\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5809 - accuracy: 0.8027 - val_loss: 0.5523 - val_accuracy: 0.8122\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5613 - accuracy: 0.8083 - val_loss: 0.5184 - val_accuracy: 0.8261\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5487 - accuracy: 0.8131 - val_loss: 0.5071 - val_accuracy: 0.8255\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5415 - accuracy: 0.8164 - val_loss: 0.5884 - val_accuracy: 0.8073\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5255 - accuracy: 0.8236 - val_loss: 0.4961 - val_accuracy: 0.8349\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.5177 - accuracy: 0.8243 - val_loss: 0.4809 - val_accuracy: 0.8397\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.5094 - accuracy: 0.8279 - val_loss: 0.4729 - val_accuracy: 0.8453\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5026 - accuracy: 0.8308 - val_loss: 0.4855 - val_accuracy: 0.8398\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4923 - accuracy: 0.8346 - val_loss: 0.6583 - val_accuracy: 0.7880\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4858 - accuracy: 0.8361 - val_loss: 0.4258 - val_accuracy: 0.8607\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4744 - accuracy: 0.8404 - val_loss: 0.5243 - val_accuracy: 0.8295\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4699 - accuracy: 0.8412 - val_loss: 0.4650 - val_accuracy: 0.8447\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4660 - accuracy: 0.8419 - val_loss: 0.4379 - val_accuracy: 0.8538\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4614 - accuracy: 0.8416 - val_loss: 0.5027 - val_accuracy: 0.8402\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4554 - accuracy: 0.8459 - val_loss: 0.4361 - val_accuracy: 0.8553\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4490 - accuracy: 0.8480 - val_loss: 0.4764 - val_accuracy: 0.8438\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4422 - accuracy: 0.8503 - val_loss: 0.4508 - val_accuracy: 0.8535\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4362 - accuracy: 0.8520 - val_loss: 0.4479 - val_accuracy: 0.8515\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4352 - accuracy: 0.8521 - val_loss: 0.5307 - val_accuracy: 0.8309\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4340 - accuracy: 0.8521 - val_loss: 0.4469 - val_accuracy: 0.8530\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4270 - accuracy: 0.8542 - val_loss: 0.4452 - val_accuracy: 0.8563\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4228 - accuracy: 0.8559 - val_loss: 0.4984 - val_accuracy: 0.8380\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4197 - accuracy: 0.8592 - val_loss: 0.4456 - val_accuracy: 0.8532\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4161 - accuracy: 0.8578 - val_loss: 0.4238 - val_accuracy: 0.8610\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4108 - accuracy: 0.8617 - val_loss: 0.4720 - val_accuracy: 0.8473\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4110 - accuracy: 0.8608 - val_loss: 0.4631 - val_accuracy: 0.8547\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4063 - accuracy: 0.8616 - val_loss: 0.4389 - val_accuracy: 0.8603\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4021 - accuracy: 0.8637 - val_loss: 0.4281 - val_accuracy: 0.8638\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3984 - accuracy: 0.8655 - val_loss: 0.4059 - val_accuracy: 0.8667\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3944 - accuracy: 0.8663 - val_loss: 0.3983 - val_accuracy: 0.8669\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3894 - accuracy: 0.8694 - val_loss: 0.4578 - val_accuracy: 0.8563\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3964 - accuracy: 0.8665 - val_loss: 0.3642 - val_accuracy: 0.8798\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3858 - accuracy: 0.8683 - val_loss: 0.4000 - val_accuracy: 0.8710\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3848 - accuracy: 0.8710 - val_loss: 0.4136 - val_accuracy: 0.8648\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3840 - accuracy: 0.8692 - val_loss: 0.3979 - val_accuracy: 0.8728\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3820 - accuracy: 0.8702 - val_loss: 0.4231 - val_accuracy: 0.8620\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3763 - accuracy: 0.8724 - val_loss: 0.4450 - val_accuracy: 0.8595\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3734 - accuracy: 0.8736 - val_loss: 0.3734 - val_accuracy: 0.8768\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3719 - accuracy: 0.8734 - val_loss: 0.4072 - val_accuracy: 0.8686\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3725 - accuracy: 0.8739 - val_loss: 0.4018 - val_accuracy: 0.8676\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3693 - accuracy: 0.8747 - val_loss: 0.4244 - val_accuracy: 0.8658\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3707 - accuracy: 0.8749 - val_loss: 0.3955 - val_accuracy: 0.8708\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3667 - accuracy: 0.8749 - val_loss: 0.4544 - val_accuracy: 0.8576\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3664 - accuracy: 0.8759 - val_loss: 0.3792 - val_accuracy: 0.8752\n",
      "Epoch 57/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3626 - accuracy: 0.8781 - val_loss: 0.4323 - val_accuracy: 0.8622\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3578 - accuracy: 0.8796 - val_loss: 0.3840 - val_accuracy: 0.8737\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3560 - accuracy: 0.8807 - val_loss: 0.4253 - val_accuracy: 0.8617\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3553 - accuracy: 0.8806 - val_loss: 0.3865 - val_accuracy: 0.8793\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3519 - accuracy: 0.8811 - val_loss: 0.3905 - val_accuracy: 0.8724\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3482 - accuracy: 0.8823 - val_loss: 0.4136 - val_accuracy: 0.8721\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3463 - accuracy: 0.8817 - val_loss: 0.3827 - val_accuracy: 0.8716\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3485 - accuracy: 0.8812 - val_loss: 0.4154 - val_accuracy: 0.8723\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3477 - accuracy: 0.8829 - val_loss: 0.3608 - val_accuracy: 0.8860\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3434 - accuracy: 0.8846 - val_loss: 0.3803 - val_accuracy: 0.8772\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3466 - accuracy: 0.8824 - val_loss: 0.4174 - val_accuracy: 0.8675\n",
      "Epoch 68/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3430 - accuracy: 0.8839 - val_loss: 0.4769 - val_accuracy: 0.8538\n",
      "Epoch 69/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3388 - accuracy: 0.8845 - val_loss: 0.4245 - val_accuracy: 0.8696\n",
      "Epoch 70/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3403 - accuracy: 0.8829 - val_loss: 0.3740 - val_accuracy: 0.8800\n",
      "Epoch 71/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3393 - accuracy: 0.8852 - val_loss: 0.3798 - val_accuracy: 0.8794\n",
      "Epoch 72/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3336 - accuracy: 0.8864 - val_loss: 0.4043 - val_accuracy: 0.8716\n",
      "Epoch 73/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3301 - accuracy: 0.8886 - val_loss: 0.3927 - val_accuracy: 0.8786\n",
      "Epoch 74/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3310 - accuracy: 0.8875 - val_loss: 0.4204 - val_accuracy: 0.8698\n",
      "Epoch 75/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3334 - accuracy: 0.8873 - val_loss: 0.4204 - val_accuracy: 0.8697\n",
      "Epoch 76/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3334 - accuracy: 0.8870 - val_loss: 0.3806 - val_accuracy: 0.8791\n",
      "Epoch 77/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3289 - accuracy: 0.8872 - val_loss: 0.3689 - val_accuracy: 0.8794\n",
      "Epoch 78/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3251 - accuracy: 0.8894 - val_loss: 0.4167 - val_accuracy: 0.8727\n",
      "Epoch 79/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3258 - accuracy: 0.8887 - val_loss: 0.4065 - val_accuracy: 0.8764\n",
      "Epoch 80/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3242 - accuracy: 0.8914 - val_loss: 0.3655 - val_accuracy: 0.8837\n",
      "Epoch 81/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3276 - accuracy: 0.8883 - val_loss: 0.3649 - val_accuracy: 0.8847\n",
      "Epoch 82/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3157 - accuracy: 0.8931 - val_loss: 0.4308 - val_accuracy: 0.8690\n",
      "Epoch 83/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3231 - accuracy: 0.8909 - val_loss: 0.3920 - val_accuracy: 0.8763\n",
      "Epoch 84/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3192 - accuracy: 0.8925 - val_loss: 0.3506 - val_accuracy: 0.8923\n",
      "Epoch 85/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3205 - accuracy: 0.8935 - val_loss: 0.3813 - val_accuracy: 0.8783\n",
      "Epoch 86/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3195 - accuracy: 0.8917 - val_loss: 0.3578 - val_accuracy: 0.8869\n",
      "Epoch 87/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3187 - accuracy: 0.8925 - val_loss: 0.3733 - val_accuracy: 0.8842\n",
      "Epoch 88/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3183 - accuracy: 0.8912 - val_loss: 0.3541 - val_accuracy: 0.8851\n",
      "Epoch 89/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3127 - accuracy: 0.8943 - val_loss: 0.3855 - val_accuracy: 0.8793\n",
      "Epoch 90/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3111 - accuracy: 0.8946 - val_loss: 0.3602 - val_accuracy: 0.8894\n",
      "Epoch 91/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3152 - accuracy: 0.8946 - val_loss: 0.4229 - val_accuracy: 0.8723\n",
      "Epoch 92/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3141 - accuracy: 0.8928 - val_loss: 0.3554 - val_accuracy: 0.8863\n",
      "Epoch 93/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3146 - accuracy: 0.8925 - val_loss: 0.3779 - val_accuracy: 0.8856\n",
      "Epoch 94/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3129 - accuracy: 0.8946 - val_loss: 0.4072 - val_accuracy: 0.8714\n",
      "Epoch 95/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3113 - accuracy: 0.8944 - val_loss: 0.3689 - val_accuracy: 0.8842\n",
      "Epoch 96/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3096 - accuracy: 0.8929 - val_loss: 0.3878 - val_accuracy: 0.8813\n",
      "Epoch 97/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3071 - accuracy: 0.8954 - val_loss: 0.3402 - val_accuracy: 0.8959\n",
      "Epoch 98/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3046 - accuracy: 0.8959 - val_loss: 0.3881 - val_accuracy: 0.8824\n",
      "Epoch 99/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3048 - accuracy: 0.8966 - val_loss: 0.3773 - val_accuracy: 0.8827\n",
      "Epoch 100/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2994 - accuracy: 0.8970 - val_loss: 0.3646 - val_accuracy: 0.8863\n",
      "Epoch 101/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3037 - accuracy: 0.8976 - val_loss: 0.3802 - val_accuracy: 0.8815\n",
      "Epoch 102/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3022 - accuracy: 0.8974 - val_loss: 0.4192 - val_accuracy: 0.8694\n",
      "Epoch 103/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3013 - accuracy: 0.8981 - val_loss: 0.3827 - val_accuracy: 0.8806\n",
      "Epoch 104/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2999 - accuracy: 0.8980 - val_loss: 0.3680 - val_accuracy: 0.8851\n",
      "Epoch 105/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2983 - accuracy: 0.8985 - val_loss: 0.3762 - val_accuracy: 0.8835\n",
      "Epoch 106/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3011 - accuracy: 0.8979 - val_loss: 0.4009 - val_accuracy: 0.8802\n",
      "Epoch 107/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2956 - accuracy: 0.8989 - val_loss: 0.3644 - val_accuracy: 0.8851\n",
      "Epoch 108/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2991 - accuracy: 0.8986 - val_loss: 0.3769 - val_accuracy: 0.8817\n",
      "Epoch 109/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2936 - accuracy: 0.8999 - val_loss: 0.3750 - val_accuracy: 0.8837\n",
      "Epoch 110/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2993 - accuracy: 0.8973 - val_loss: 0.4410 - val_accuracy: 0.8611\n",
      "Epoch 111/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2906 - accuracy: 0.9014 - val_loss: 0.3424 - val_accuracy: 0.8947\n",
      "Epoch 112/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2958 - accuracy: 0.8999 - val_loss: 0.3563 - val_accuracy: 0.8880\n",
      "Epoch 113/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2911 - accuracy: 0.9013 - val_loss: 0.3823 - val_accuracy: 0.8847\n",
      "Epoch 114/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2952 - accuracy: 0.8997 - val_loss: 0.3587 - val_accuracy: 0.8863\n",
      "Epoch 115/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2920 - accuracy: 0.9016 - val_loss: 0.3755 - val_accuracy: 0.8859\n",
      "Epoch 116/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2936 - accuracy: 0.9010 - val_loss: 0.3870 - val_accuracy: 0.8837\n",
      "Epoch 117/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2886 - accuracy: 0.9030 - val_loss: 0.4016 - val_accuracy: 0.8811\n",
      "Epoch 118/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2907 - accuracy: 0.9006 - val_loss: 0.3344 - val_accuracy: 0.8973\n",
      "Epoch 119/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2873 - accuracy: 0.9041 - val_loss: 0.3647 - val_accuracy: 0.8910\n",
      "Epoch 120/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2902 - accuracy: 0.9022 - val_loss: 0.3797 - val_accuracy: 0.8839\n",
      "Epoch 121/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2859 - accuracy: 0.9028 - val_loss: 0.3572 - val_accuracy: 0.8902\n",
      "Epoch 122/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2865 - accuracy: 0.9027 - val_loss: 0.3569 - val_accuracy: 0.8927\n",
      "Epoch 123/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2847 - accuracy: 0.9038 - val_loss: 0.3831 - val_accuracy: 0.8835\n",
      "Epoch 124/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2839 - accuracy: 0.9029 - val_loss: 0.3616 - val_accuracy: 0.8897\n",
      "Epoch 125/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2803 - accuracy: 0.9048 - val_loss: 0.4495 - val_accuracy: 0.8690\n",
      "Epoch 126/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2885 - accuracy: 0.9028 - val_loss: 0.3315 - val_accuracy: 0.8949\n",
      "Epoch 127/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2810 - accuracy: 0.9035 - val_loss: 0.3479 - val_accuracy: 0.8955\n",
      "Epoch 128/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2837 - accuracy: 0.9018 - val_loss: 0.3289 - val_accuracy: 0.8973\n",
      "Epoch 129/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2816 - accuracy: 0.9040 - val_loss: 0.3445 - val_accuracy: 0.8942\n",
      "Epoch 130/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2840 - accuracy: 0.9029 - val_loss: 0.3678 - val_accuracy: 0.8854\n",
      "Epoch 131/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2821 - accuracy: 0.9036 - val_loss: 0.3919 - val_accuracy: 0.8847\n",
      "Epoch 132/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2819 - accuracy: 0.9039 - val_loss: 0.3567 - val_accuracy: 0.8931\n",
      "Epoch 133/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2835 - accuracy: 0.9022 - val_loss: 0.3597 - val_accuracy: 0.8888\n",
      "Epoch 134/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2771 - accuracy: 0.9047 - val_loss: 0.3612 - val_accuracy: 0.8889\n",
      "Epoch 135/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2809 - accuracy: 0.9049 - val_loss: 0.3754 - val_accuracy: 0.8854\n",
      "Epoch 136/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2764 - accuracy: 0.9061 - val_loss: 0.3452 - val_accuracy: 0.8910\n",
      "Epoch 137/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2823 - accuracy: 0.9037 - val_loss: 0.3435 - val_accuracy: 0.8947\n",
      "Epoch 138/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2758 - accuracy: 0.9059 - val_loss: 0.3699 - val_accuracy: 0.8883\n",
      "Epoch 139/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2768 - accuracy: 0.9063 - val_loss: 0.3541 - val_accuracy: 0.8920\n",
      "Epoch 140/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2782 - accuracy: 0.9059 - val_loss: 0.3423 - val_accuracy: 0.8942\n",
      "Epoch 141/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2797 - accuracy: 0.9050 - val_loss: 0.3541 - val_accuracy: 0.8930\n",
      "Epoch 142/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2759 - accuracy: 0.9061 - val_loss: 0.3245 - val_accuracy: 0.8978\n",
      "Epoch 143/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2740 - accuracy: 0.9065 - val_loss: 0.3663 - val_accuracy: 0.8882\n",
      "Epoch 144/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2753 - accuracy: 0.9061 - val_loss: 0.3463 - val_accuracy: 0.8925\n",
      "Epoch 145/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2776 - accuracy: 0.9068 - val_loss: 0.3560 - val_accuracy: 0.8892\n",
      "Epoch 146/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2666 - accuracy: 0.9094 - val_loss: 0.3678 - val_accuracy: 0.8909\n",
      "Epoch 147/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2718 - accuracy: 0.9079 - val_loss: 0.3590 - val_accuracy: 0.8900\n",
      "Epoch 148/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2705 - accuracy: 0.9078 - val_loss: 0.4079 - val_accuracy: 0.8772\n",
      "Epoch 149/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2720 - accuracy: 0.9071 - val_loss: 0.3638 - val_accuracy: 0.8878\n",
      "Epoch 150/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2725 - accuracy: 0.9084 - val_loss: 0.3735 - val_accuracy: 0.8887\n",
      "Epoch 151/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2696 - accuracy: 0.9081 - val_loss: 0.3688 - val_accuracy: 0.8881\n",
      "Epoch 152/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2706 - accuracy: 0.9086 - val_loss: 0.3271 - val_accuracy: 0.8979\n",
      "Epoch 153/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2719 - accuracy: 0.9081 - val_loss: 0.3569 - val_accuracy: 0.8914\n",
      "Epoch 154/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2670 - accuracy: 0.9093 - val_loss: 0.3661 - val_accuracy: 0.8908\n",
      "Epoch 155/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2711 - accuracy: 0.9088 - val_loss: 0.3726 - val_accuracy: 0.8859\n",
      "Epoch 156/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2714 - accuracy: 0.9075 - val_loss: 0.3879 - val_accuracy: 0.8833\n",
      "Epoch 157/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2653 - accuracy: 0.9076 - val_loss: 0.3512 - val_accuracy: 0.8933\n",
      "Epoch 158/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2665 - accuracy: 0.9094 - val_loss: 0.3395 - val_accuracy: 0.8962\n",
      "Epoch 159/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2642 - accuracy: 0.9089 - val_loss: 0.3547 - val_accuracy: 0.8894\n",
      "Epoch 160/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2679 - accuracy: 0.9093 - val_loss: 0.3329 - val_accuracy: 0.8968\n",
      "Epoch 161/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2635 - accuracy: 0.9099 - val_loss: 0.3819 - val_accuracy: 0.8871\n",
      "Epoch 162/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2662 - accuracy: 0.9087 - val_loss: 0.3630 - val_accuracy: 0.8875\n",
      "Epoch 163/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2620 - accuracy: 0.9101 - val_loss: 0.3884 - val_accuracy: 0.8855\n",
      "Epoch 164/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2628 - accuracy: 0.9094 - val_loss: 0.3388 - val_accuracy: 0.8943\n",
      "Epoch 165/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2630 - accuracy: 0.9101 - val_loss: 0.3349 - val_accuracy: 0.8932\n",
      "Epoch 166/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2610 - accuracy: 0.9113 - val_loss: 0.3417 - val_accuracy: 0.8950\n",
      "Epoch 167/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2663 - accuracy: 0.9087 - val_loss: 0.3343 - val_accuracy: 0.8945\n",
      "Epoch 168/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2641 - accuracy: 0.9089 - val_loss: 0.3474 - val_accuracy: 0.8959\n",
      "Epoch 169/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2657 - accuracy: 0.9097 - val_loss: 0.3585 - val_accuracy: 0.8935\n",
      "Epoch 170/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2611 - accuracy: 0.9117 - val_loss: 0.3256 - val_accuracy: 0.8998\n",
      "Epoch 171/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2574 - accuracy: 0.9111 - val_loss: 0.3370 - val_accuracy: 0.8964\n",
      "Epoch 172/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2600 - accuracy: 0.9115 - val_loss: 0.3323 - val_accuracy: 0.8975\n",
      "Epoch 173/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2596 - accuracy: 0.9122 - val_loss: 0.3484 - val_accuracy: 0.8951\n",
      "Epoch 174/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2586 - accuracy: 0.9123 - val_loss: 0.3504 - val_accuracy: 0.8949\n",
      "Epoch 175/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2596 - accuracy: 0.9126 - val_loss: 0.3742 - val_accuracy: 0.8876\n",
      "Epoch 176/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2580 - accuracy: 0.9105 - val_loss: 0.3596 - val_accuracy: 0.8943\n",
      "Epoch 177/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2583 - accuracy: 0.9134 - val_loss: 0.4028 - val_accuracy: 0.8853\n",
      "Epoch 178/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2562 - accuracy: 0.9134 - val_loss: 0.3843 - val_accuracy: 0.8858\n",
      "Epoch 179/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2610 - accuracy: 0.9113 - val_loss: 0.3490 - val_accuracy: 0.8969\n",
      "Epoch 180/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2598 - accuracy: 0.9122 - val_loss: 0.3302 - val_accuracy: 0.8993\n",
      "Epoch 181/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2546 - accuracy: 0.9122 - val_loss: 0.3354 - val_accuracy: 0.8968\n",
      "Epoch 182/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2552 - accuracy: 0.9129 - val_loss: 0.3774 - val_accuracy: 0.8844\n",
      "Epoch 183/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2566 - accuracy: 0.9123 - val_loss: 0.3471 - val_accuracy: 0.8969\n",
      "Epoch 184/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2587 - accuracy: 0.9123 - val_loss: 0.3678 - val_accuracy: 0.8906\n",
      "Epoch 185/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2589 - accuracy: 0.9119 - val_loss: 0.3562 - val_accuracy: 0.8939\n",
      "Epoch 186/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2527 - accuracy: 0.9133 - val_loss: 0.3287 - val_accuracy: 0.9002\n",
      "Epoch 187/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2540 - accuracy: 0.9135 - val_loss: 0.3536 - val_accuracy: 0.8953\n",
      "Epoch 188/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2540 - accuracy: 0.9133 - val_loss: 0.3548 - val_accuracy: 0.8936\n",
      "Epoch 189/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2565 - accuracy: 0.9128 - val_loss: 0.3360 - val_accuracy: 0.8968\n",
      "Epoch 190/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2536 - accuracy: 0.9140 - val_loss: 0.3309 - val_accuracy: 0.8978\n",
      "Epoch 191/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2526 - accuracy: 0.9135 - val_loss: 0.3642 - val_accuracy: 0.8926\n",
      "Epoch 192/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2550 - accuracy: 0.9139 - val_loss: 0.3239 - val_accuracy: 0.9013\n",
      "Epoch 193/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2451 - accuracy: 0.9148 - val_loss: 0.3761 - val_accuracy: 0.8926\n",
      "Epoch 194/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2542 - accuracy: 0.9131 - val_loss: 0.3782 - val_accuracy: 0.8898\n",
      "Epoch 195/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2517 - accuracy: 0.9141 - val_loss: 0.3495 - val_accuracy: 0.8956\n",
      "Epoch 196/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2525 - accuracy: 0.9139 - val_loss: 0.3555 - val_accuracy: 0.8950\n",
      "Epoch 197/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2540 - accuracy: 0.9139 - val_loss: 0.3423 - val_accuracy: 0.8974\n",
      "Epoch 198/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2494 - accuracy: 0.9145 - val_loss: 0.3698 - val_accuracy: 0.8910\n",
      "Epoch 199/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2521 - accuracy: 0.9137 - val_loss: 0.4432 - val_accuracy: 0.8712\n",
      "Epoch 200/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2467 - accuracy: 0.9158 - val_loss: 0.3586 - val_accuracy: 0.8918\n",
      "Epoch 201/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2506 - accuracy: 0.9147 - val_loss: 0.3390 - val_accuracy: 0.8951\n",
      "Epoch 202/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2500 - accuracy: 0.9165 - val_loss: 0.4013 - val_accuracy: 0.8825\n",
      "Epoch 203/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2484 - accuracy: 0.9148 - val_loss: 0.3644 - val_accuracy: 0.8928\n",
      "Epoch 204/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2528 - accuracy: 0.9144 - val_loss: 0.3313 - val_accuracy: 0.8981\n",
      "Epoch 205/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2501 - accuracy: 0.9140 - val_loss: 0.3371 - val_accuracy: 0.8990\n",
      "Epoch 206/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2481 - accuracy: 0.9150 - val_loss: 0.3251 - val_accuracy: 0.9016\n",
      "Epoch 207/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2451 - accuracy: 0.9171 - val_loss: 0.3404 - val_accuracy: 0.8990\n",
      "Epoch 208/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2443 - accuracy: 0.9159 - val_loss: 0.3420 - val_accuracy: 0.9015\n",
      "Epoch 209/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2512 - accuracy: 0.9141 - val_loss: 0.3353 - val_accuracy: 0.9002\n",
      "Epoch 210/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2504 - accuracy: 0.9157 - val_loss: 0.3547 - val_accuracy: 0.8955\n",
      "Epoch 211/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2442 - accuracy: 0.9188 - val_loss: 0.3711 - val_accuracy: 0.8948\n",
      "Epoch 212/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2504 - accuracy: 0.9151 - val_loss: 0.3262 - val_accuracy: 0.9012\n",
      "Epoch 213/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2472 - accuracy: 0.9148 - val_loss: 0.3867 - val_accuracy: 0.8867\n",
      "Epoch 214/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2488 - accuracy: 0.9155 - val_loss: 0.3272 - val_accuracy: 0.9004\n",
      "Epoch 215/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2438 - accuracy: 0.9178 - val_loss: 0.3253 - val_accuracy: 0.9010\n",
      "Epoch 216/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2469 - accuracy: 0.9158 - val_loss: 0.3782 - val_accuracy: 0.8876\n",
      "Epoch 217/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2443 - accuracy: 0.9159 - val_loss: 0.3891 - val_accuracy: 0.8855\n",
      "Epoch 218/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2445 - accuracy: 0.9176 - val_loss: 0.3266 - val_accuracy: 0.8997\n",
      "Epoch 219/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2428 - accuracy: 0.9160 - val_loss: 0.3598 - val_accuracy: 0.8958\n",
      "Epoch 220/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2428 - accuracy: 0.9180 - val_loss: 0.3672 - val_accuracy: 0.8948\n",
      "Epoch 221/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2440 - accuracy: 0.9159 - val_loss: 0.3122 - val_accuracy: 0.9052\n",
      "Epoch 222/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2467 - accuracy: 0.9157 - val_loss: 0.3185 - val_accuracy: 0.9026\n",
      "Epoch 223/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2379 - accuracy: 0.9201 - val_loss: 0.3396 - val_accuracy: 0.8989\n",
      "Epoch 224/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2453 - accuracy: 0.9171 - val_loss: 0.3530 - val_accuracy: 0.8983\n",
      "Epoch 225/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2416 - accuracy: 0.9181 - val_loss: 0.3876 - val_accuracy: 0.8862\n",
      "Epoch 226/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2387 - accuracy: 0.9186 - val_loss: 0.3357 - val_accuracy: 0.8997\n",
      "Epoch 227/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2410 - accuracy: 0.9186 - val_loss: 0.3469 - val_accuracy: 0.8973\n",
      "Epoch 228/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2452 - accuracy: 0.9151 - val_loss: 0.3306 - val_accuracy: 0.9033\n",
      "Epoch 229/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2409 - accuracy: 0.9177 - val_loss: 0.3237 - val_accuracy: 0.9043\n",
      "Epoch 230/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2393 - accuracy: 0.9192 - val_loss: 0.3361 - val_accuracy: 0.8995\n",
      "Epoch 231/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2428 - accuracy: 0.9182 - val_loss: 0.3269 - val_accuracy: 0.9040\n",
      "Epoch 232/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2437 - accuracy: 0.9169 - val_loss: 0.3327 - val_accuracy: 0.9016\n",
      "Epoch 233/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2414 - accuracy: 0.9194 - val_loss: 0.3375 - val_accuracy: 0.9006\n",
      "Epoch 234/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2393 - accuracy: 0.9179 - val_loss: 0.3671 - val_accuracy: 0.8915\n",
      "Epoch 235/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2425 - accuracy: 0.9162 - val_loss: 0.3162 - val_accuracy: 0.9029\n",
      "Epoch 236/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2408 - accuracy: 0.9176 - val_loss: 0.3782 - val_accuracy: 0.8902\n",
      "Epoch 237/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2356 - accuracy: 0.9197 - val_loss: 0.3457 - val_accuracy: 0.8963\n",
      "Epoch 238/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2374 - accuracy: 0.9187 - val_loss: 0.3292 - val_accuracy: 0.9017\n",
      "Epoch 239/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2347 - accuracy: 0.9198 - val_loss: 0.3736 - val_accuracy: 0.8895\n",
      "Epoch 240/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2361 - accuracy: 0.9196 - val_loss: 0.3470 - val_accuracy: 0.8961\n",
      "Epoch 241/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2285 - accuracy: 0.9215 - val_loss: 0.3602 - val_accuracy: 0.8913\n",
      "Epoch 242/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2418 - accuracy: 0.9181 - val_loss: 0.3629 - val_accuracy: 0.8925\n",
      "Epoch 243/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2409 - accuracy: 0.9169 - val_loss: 0.3449 - val_accuracy: 0.8980\n",
      "Epoch 244/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2367 - accuracy: 0.9187 - val_loss: 0.3939 - val_accuracy: 0.8888\n",
      "Epoch 245/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2350 - accuracy: 0.9194 - val_loss: 0.3298 - val_accuracy: 0.8992\n",
      "Epoch 246/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2394 - accuracy: 0.9185 - val_loss: 0.3648 - val_accuracy: 0.8925\n",
      "Epoch 247/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2385 - accuracy: 0.9190 - val_loss: 0.3769 - val_accuracy: 0.8894\n",
      "Epoch 248/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2380 - accuracy: 0.9186 - val_loss: 0.3264 - val_accuracy: 0.9018\n",
      "Epoch 249/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2315 - accuracy: 0.9211 - val_loss: 0.3179 - val_accuracy: 0.9048\n",
      "Epoch 250/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2329 - accuracy: 0.9213 - val_loss: 0.3342 - val_accuracy: 0.8988\n",
      "Epoch 251/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2342 - accuracy: 0.9192 - val_loss: 0.3435 - val_accuracy: 0.8988\n",
      "Epoch 252/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2369 - accuracy: 0.9197 - val_loss: 0.3485 - val_accuracy: 0.8987\n",
      "Epoch 253/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2328 - accuracy: 0.9201 - val_loss: 0.3477 - val_accuracy: 0.9016\n",
      "Epoch 254/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2348 - accuracy: 0.9204 - val_loss: 0.3690 - val_accuracy: 0.8904\n",
      "Epoch 255/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2357 - accuracy: 0.9202 - val_loss: 0.3424 - val_accuracy: 0.9003\n",
      "Epoch 256/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2292 - accuracy: 0.9232 - val_loss: 0.3378 - val_accuracy: 0.8997\n",
      "Epoch 257/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2350 - accuracy: 0.9201 - val_loss: 0.3690 - val_accuracy: 0.8943\n",
      "Epoch 258/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2291 - accuracy: 0.9221 - val_loss: 0.3552 - val_accuracy: 0.8974\n",
      "Epoch 259/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2354 - accuracy: 0.9188 - val_loss: 0.3519 - val_accuracy: 0.8997\n",
      "Epoch 260/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2337 - accuracy: 0.9208 - val_loss: 0.3406 - val_accuracy: 0.8992\n",
      "Epoch 261/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2327 - accuracy: 0.9216 - val_loss: 0.3321 - val_accuracy: 0.9030\n",
      "Epoch 262/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2329 - accuracy: 0.9216 - val_loss: 0.3209 - val_accuracy: 0.9024\n",
      "Epoch 263/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2334 - accuracy: 0.9200 - val_loss: 0.3204 - val_accuracy: 0.9008\n",
      "Epoch 264/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2261 - accuracy: 0.9227 - val_loss: 0.3479 - val_accuracy: 0.8983\n",
      "Epoch 265/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2302 - accuracy: 0.9219 - val_loss: 0.3549 - val_accuracy: 0.8957\n",
      "Epoch 266/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2315 - accuracy: 0.9215 - val_loss: 0.3599 - val_accuracy: 0.8952\n",
      "Epoch 267/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2311 - accuracy: 0.9217 - val_loss: 0.3518 - val_accuracy: 0.8999\n",
      "Epoch 268/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2319 - accuracy: 0.9212 - val_loss: 0.3377 - val_accuracy: 0.8995\n",
      "Epoch 269/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2347 - accuracy: 0.9197 - val_loss: 0.3520 - val_accuracy: 0.8946\n",
      "Epoch 270/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2299 - accuracy: 0.9214 - val_loss: 0.3425 - val_accuracy: 0.8988\n",
      "Epoch 271/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2330 - accuracy: 0.9209 - val_loss: 0.3404 - val_accuracy: 0.9034\n",
      "Epoch 272/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2311 - accuracy: 0.9203 - val_loss: 0.3460 - val_accuracy: 0.9008\n",
      "Epoch 273/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2283 - accuracy: 0.9210 - val_loss: 0.3283 - val_accuracy: 0.9048\n",
      "Epoch 274/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2248 - accuracy: 0.9230 - val_loss: 0.3823 - val_accuracy: 0.8890\n",
      "Epoch 275/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2316 - accuracy: 0.9203 - val_loss: 0.3405 - val_accuracy: 0.9000\n",
      "Epoch 276/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2281 - accuracy: 0.9218 - val_loss: 0.3499 - val_accuracy: 0.8968\n",
      "Epoch 277/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2310 - accuracy: 0.9212 - val_loss: 0.3447 - val_accuracy: 0.9006\n",
      "Epoch 278/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2297 - accuracy: 0.9218 - val_loss: 0.3435 - val_accuracy: 0.9008\n",
      "Epoch 279/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2262 - accuracy: 0.9225 - val_loss: 0.3664 - val_accuracy: 0.8957\n",
      "Epoch 280/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2256 - accuracy: 0.9229 - val_loss: 0.3382 - val_accuracy: 0.9030\n",
      "Epoch 281/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2237 - accuracy: 0.9225 - val_loss: 0.3169 - val_accuracy: 0.9026\n",
      "Epoch 282/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2289 - accuracy: 0.9206 - val_loss: 0.3301 - val_accuracy: 0.9026\n",
      "Epoch 283/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2248 - accuracy: 0.9237 - val_loss: 0.3297 - val_accuracy: 0.9014\n",
      "Epoch 284/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2289 - accuracy: 0.9213 - val_loss: 0.3342 - val_accuracy: 0.9014\n",
      "Epoch 285/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2192 - accuracy: 0.9246 - val_loss: 0.3378 - val_accuracy: 0.9014\n",
      "Epoch 286/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2275 - accuracy: 0.9235 - val_loss: 0.3389 - val_accuracy: 0.8995\n",
      "Epoch 287/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2217 - accuracy: 0.9235 - val_loss: 0.3407 - val_accuracy: 0.8977\n",
      "Epoch 288/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2305 - accuracy: 0.9218 - val_loss: 0.3199 - val_accuracy: 0.9035\n",
      "Epoch 289/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2253 - accuracy: 0.9223 - val_loss: 0.3334 - val_accuracy: 0.9041\n",
      "Epoch 290/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2246 - accuracy: 0.9229 - val_loss: 0.3296 - val_accuracy: 0.9034\n",
      "Epoch 291/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2241 - accuracy: 0.9237 - val_loss: 0.3389 - val_accuracy: 0.8992\n",
      "Epoch 292/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2252 - accuracy: 0.9247 - val_loss: 0.3349 - val_accuracy: 0.9031\n",
      "Epoch 293/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2239 - accuracy: 0.9245 - val_loss: 0.3242 - val_accuracy: 0.9031\n",
      "Epoch 294/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2255 - accuracy: 0.9230 - val_loss: 0.3629 - val_accuracy: 0.8985\n",
      "Epoch 295/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2214 - accuracy: 0.9229 - val_loss: 0.3287 - val_accuracy: 0.8998\n",
      "Epoch 296/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2274 - accuracy: 0.9222 - val_loss: 0.3388 - val_accuracy: 0.9027\n",
      "Epoch 297/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2217 - accuracy: 0.9243 - val_loss: 0.3330 - val_accuracy: 0.9050\n",
      "Epoch 298/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2200 - accuracy: 0.9257 - val_loss: 0.3568 - val_accuracy: 0.8949\n",
      "Epoch 299/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2212 - accuracy: 0.9235 - val_loss: 0.3599 - val_accuracy: 0.8942\n",
      "Epoch 300/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2227 - accuracy: 0.9249 - val_loss: 0.3240 - val_accuracy: 0.9049\n",
      "Epoch 301/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2174 - accuracy: 0.9261 - val_loss: 0.3307 - val_accuracy: 0.9019\n",
      "Epoch 302/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2227 - accuracy: 0.9243 - val_loss: 0.3523 - val_accuracy: 0.9000\n",
      "Epoch 303/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2219 - accuracy: 0.9239 - val_loss: 0.3241 - val_accuracy: 0.9052\n",
      "Epoch 304/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2212 - accuracy: 0.9246 - val_loss: 0.3679 - val_accuracy: 0.8960\n",
      "Epoch 305/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2218 - accuracy: 0.9238 - val_loss: 0.3239 - val_accuracy: 0.9067\n",
      "Epoch 306/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2234 - accuracy: 0.9237 - val_loss: 0.3267 - val_accuracy: 0.9029\n",
      "Epoch 307/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2220 - accuracy: 0.9246 - val_loss: 0.3512 - val_accuracy: 0.8980\n",
      "Epoch 308/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2196 - accuracy: 0.9242 - val_loss: 0.3686 - val_accuracy: 0.8920\n",
      "Epoch 309/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2210 - accuracy: 0.9249 - val_loss: 0.3317 - val_accuracy: 0.9003\n",
      "Epoch 310/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2223 - accuracy: 0.9237 - val_loss: 0.3202 - val_accuracy: 0.9037\n",
      "Epoch 311/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2211 - accuracy: 0.9240 - val_loss: 0.3198 - val_accuracy: 0.9070\n",
      "Epoch 312/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2180 - accuracy: 0.9269 - val_loss: 0.3618 - val_accuracy: 0.8944\n",
      "Epoch 313/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2211 - accuracy: 0.9236 - val_loss: 0.3218 - val_accuracy: 0.9068\n",
      "Epoch 314/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2243 - accuracy: 0.9234 - val_loss: 0.3702 - val_accuracy: 0.8961\n",
      "Epoch 315/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2218 - accuracy: 0.9250 - val_loss: 0.3222 - val_accuracy: 0.9067\n",
      "Epoch 316/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2246 - accuracy: 0.9227 - val_loss: 0.3061 - val_accuracy: 0.9082\n",
      "Epoch 317/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2233 - accuracy: 0.9246 - val_loss: 0.3249 - val_accuracy: 0.9026\n",
      "Epoch 318/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2246 - accuracy: 0.9229 - val_loss: 0.3402 - val_accuracy: 0.9011\n",
      "Epoch 319/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2212 - accuracy: 0.9256 - val_loss: 0.3403 - val_accuracy: 0.9006\n",
      "Epoch 320/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2170 - accuracy: 0.9262 - val_loss: 0.3460 - val_accuracy: 0.9024\n",
      "Epoch 321/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2151 - accuracy: 0.9273 - val_loss: 0.3336 - val_accuracy: 0.9020\n",
      "Epoch 322/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2218 - accuracy: 0.9246 - val_loss: 0.3471 - val_accuracy: 0.8981\n",
      "Epoch 323/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2241 - accuracy: 0.9239 - val_loss: 0.3157 - val_accuracy: 0.9045\n",
      "Epoch 324/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2220 - accuracy: 0.9242 - val_loss: 0.3234 - val_accuracy: 0.9020\n",
      "Epoch 325/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2200 - accuracy: 0.9255 - val_loss: 0.3581 - val_accuracy: 0.8992\n",
      "Epoch 326/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2177 - accuracy: 0.9257 - val_loss: 0.3197 - val_accuracy: 0.9037\n",
      "Epoch 327/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2199 - accuracy: 0.9244 - val_loss: 0.3450 - val_accuracy: 0.8998\n",
      "Epoch 328/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2214 - accuracy: 0.9252 - val_loss: 0.3169 - val_accuracy: 0.9047\n",
      "Epoch 329/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2203 - accuracy: 0.9243 - val_loss: 0.3230 - val_accuracy: 0.9031\n",
      "Epoch 330/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2193 - accuracy: 0.9254 - val_loss: 0.3278 - val_accuracy: 0.9031\n",
      "Epoch 331/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2193 - accuracy: 0.9263 - val_loss: 0.3623 - val_accuracy: 0.8962\n",
      "Epoch 332/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2170 - accuracy: 0.9265 - val_loss: 0.3107 - val_accuracy: 0.9072\n",
      "Epoch 333/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2156 - accuracy: 0.9264 - val_loss: 0.3733 - val_accuracy: 0.8936\n",
      "Epoch 334/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2142 - accuracy: 0.9271 - val_loss: 0.3549 - val_accuracy: 0.9021\n",
      "Epoch 335/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2185 - accuracy: 0.9250 - val_loss: 0.3330 - val_accuracy: 0.9042\n",
      "Epoch 336/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2187 - accuracy: 0.9247 - val_loss: 0.3352 - val_accuracy: 0.9014\n",
      "Epoch 337/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2156 - accuracy: 0.9266 - val_loss: 0.3411 - val_accuracy: 0.9004\n",
      "Epoch 338/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2162 - accuracy: 0.9269 - val_loss: 0.3448 - val_accuracy: 0.9009\n",
      "Epoch 339/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2139 - accuracy: 0.9258 - val_loss: 0.3269 - val_accuracy: 0.9034\n",
      "Epoch 340/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2145 - accuracy: 0.9271 - val_loss: 0.3481 - val_accuracy: 0.9005\n",
      "Epoch 341/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2176 - accuracy: 0.9255 - val_loss: 0.3505 - val_accuracy: 0.8982\n",
      "Epoch 342/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2168 - accuracy: 0.9252 - val_loss: 0.3536 - val_accuracy: 0.8986\n",
      "Epoch 343/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2158 - accuracy: 0.9270 - val_loss: 0.3484 - val_accuracy: 0.8995\n",
      "Epoch 344/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2169 - accuracy: 0.9254 - val_loss: 0.3409 - val_accuracy: 0.9007\n",
      "Epoch 345/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2153 - accuracy: 0.9260 - val_loss: 0.3796 - val_accuracy: 0.8938\n",
      "Epoch 346/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2159 - accuracy: 0.9267 - val_loss: 0.3380 - val_accuracy: 0.9015\n",
      "Epoch 347/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2151 - accuracy: 0.9268 - val_loss: 0.3324 - val_accuracy: 0.9020\n",
      "Epoch 348/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2153 - accuracy: 0.9266 - val_loss: 0.3343 - val_accuracy: 0.9025\n",
      "Epoch 349/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2134 - accuracy: 0.9272 - val_loss: 0.3856 - val_accuracy: 0.8918\n",
      "Epoch 350/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2137 - accuracy: 0.9275 - val_loss: 0.3273 - val_accuracy: 0.9041\n",
      "Epoch 351/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2171 - accuracy: 0.9256 - val_loss: 0.3527 - val_accuracy: 0.8990\n",
      "Epoch 352/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2166 - accuracy: 0.9261 - val_loss: 0.3252 - val_accuracy: 0.9019\n",
      "Epoch 353/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2139 - accuracy: 0.9272 - val_loss: 0.3248 - val_accuracy: 0.9027\n",
      "Epoch 354/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2134 - accuracy: 0.9262 - val_loss: 0.3519 - val_accuracy: 0.8984\n",
      "Epoch 355/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2149 - accuracy: 0.9269 - val_loss: 0.3605 - val_accuracy: 0.8957\n",
      "Epoch 356/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2160 - accuracy: 0.9262 - val_loss: 0.3307 - val_accuracy: 0.9039\n",
      "Epoch 357/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2148 - accuracy: 0.9275 - val_loss: 0.3185 - val_accuracy: 0.9052\n",
      "Epoch 358/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2159 - accuracy: 0.9268 - val_loss: 0.3314 - val_accuracy: 0.9005\n",
      "Epoch 359/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2130 - accuracy: 0.9282 - val_loss: 0.3375 - val_accuracy: 0.9024\n",
      "Epoch 360/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2089 - accuracy: 0.9286 - val_loss: 0.3294 - val_accuracy: 0.9051\n",
      "Epoch 361/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2139 - accuracy: 0.9272 - val_loss: 0.3299 - val_accuracy: 0.9002\n",
      "Epoch 362/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2125 - accuracy: 0.9272 - val_loss: 0.3338 - val_accuracy: 0.9050\n",
      "Epoch 363/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2098 - accuracy: 0.9277 - val_loss: 0.3371 - val_accuracy: 0.9027\n",
      "Epoch 364/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2140 - accuracy: 0.9265 - val_loss: 0.3247 - val_accuracy: 0.9057\n",
      "Epoch 365/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2115 - accuracy: 0.9262 - val_loss: 0.3345 - val_accuracy: 0.9051\n",
      "Epoch 366/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2102 - accuracy: 0.9270 - val_loss: 0.3241 - val_accuracy: 0.9055\n",
      "Epoch 367/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2112 - accuracy: 0.9262 - val_loss: 0.3663 - val_accuracy: 0.8936\n",
      "Epoch 368/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2155 - accuracy: 0.9265 - val_loss: 0.3162 - val_accuracy: 0.9061\n",
      "Epoch 369/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2097 - accuracy: 0.9285 - val_loss: 0.3206 - val_accuracy: 0.9069\n",
      "Epoch 370/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2094 - accuracy: 0.9288 - val_loss: 0.3399 - val_accuracy: 0.9003\n",
      "Epoch 371/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2088 - accuracy: 0.9294 - val_loss: 0.3482 - val_accuracy: 0.8996\n",
      "Epoch 372/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2113 - accuracy: 0.9287 - val_loss: 0.3298 - val_accuracy: 0.9026\n",
      "Epoch 373/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2146 - accuracy: 0.9265 - val_loss: 0.3380 - val_accuracy: 0.9041\n",
      "Epoch 374/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2102 - accuracy: 0.9280 - val_loss: 0.3444 - val_accuracy: 0.9005\n",
      "Epoch 375/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2113 - accuracy: 0.9280 - val_loss: 0.3194 - val_accuracy: 0.9048\n",
      "Epoch 376/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2118 - accuracy: 0.9287 - val_loss: 0.3204 - val_accuracy: 0.9065\n",
      "Epoch 377/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2099 - accuracy: 0.9280 - val_loss: 0.3440 - val_accuracy: 0.8995\n",
      "Epoch 378/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2123 - accuracy: 0.9281 - val_loss: 0.3109 - val_accuracy: 0.9070\n",
      "Epoch 379/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2130 - accuracy: 0.9277 - val_loss: 0.3322 - val_accuracy: 0.9040\n",
      "Epoch 380/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2075 - accuracy: 0.9289 - val_loss: 0.3373 - val_accuracy: 0.9003\n",
      "Epoch 381/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2089 - accuracy: 0.9284 - val_loss: 0.3383 - val_accuracy: 0.9020\n",
      "Epoch 382/400\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2084 - accuracy: 0.9293 - val_loss: 0.3194 - val_accuracy: 0.9053\n",
      "Epoch 383/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2079 - accuracy: 0.9292 - val_loss: 0.3579 - val_accuracy: 0.8989\n",
      "Epoch 384/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2068 - accuracy: 0.9288 - val_loss: 0.3405 - val_accuracy: 0.9055\n",
      "Epoch 385/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2104 - accuracy: 0.9274 - val_loss: 0.3332 - val_accuracy: 0.9050\n",
      "Epoch 386/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2066 - accuracy: 0.9294 - val_loss: 0.3390 - val_accuracy: 0.8993\n",
      "Epoch 387/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2115 - accuracy: 0.9278 - val_loss: 0.3300 - val_accuracy: 0.9033\n",
      "Epoch 388/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2081 - accuracy: 0.9278 - val_loss: 0.3691 - val_accuracy: 0.8984\n",
      "Epoch 389/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2061 - accuracy: 0.9290 - val_loss: 0.3246 - val_accuracy: 0.9065\n",
      "Epoch 390/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2073 - accuracy: 0.9293 - val_loss: 0.3327 - val_accuracy: 0.9023\n",
      "Epoch 391/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2091 - accuracy: 0.9284 - val_loss: 0.3332 - val_accuracy: 0.9003\n",
      "Epoch 392/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2061 - accuracy: 0.9303 - val_loss: 0.3229 - val_accuracy: 0.9046\n",
      "Epoch 393/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2082 - accuracy: 0.9284 - val_loss: 0.3223 - val_accuracy: 0.9056\n",
      "Epoch 394/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2094 - accuracy: 0.9288 - val_loss: 0.3218 - val_accuracy: 0.9054\n",
      "Epoch 395/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2071 - accuracy: 0.9295 - val_loss: 0.3446 - val_accuracy: 0.9024\n",
      "Epoch 396/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2059 - accuracy: 0.9307 - val_loss: 0.3425 - val_accuracy: 0.8980\n",
      "Epoch 397/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2133 - accuracy: 0.9273 - val_loss: 0.3458 - val_accuracy: 0.8976\n",
      "Epoch 398/400\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2067 - accuracy: 0.9291 - val_loss: 0.3606 - val_accuracy: 0.8937\n",
      "Epoch 399/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2051 - accuracy: 0.9300 - val_loss: 0.3283 - val_accuracy: 0.9067\n",
      "Epoch 400/400\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.2064 - accuracy: 0.9292 - val_loss: 0.3261 - val_accuracy: 0.9036\n",
      "Total time for training the final model: 4:38:13.503686\n"
     ]
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "startTimeModule = datetime.now()\n",
    "print('Forming the final model using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "reset_random(seedNum)\n",
    "final_model = create_customized_model(best_optimizer, best_kernel_init)\n",
    "final_hist = final_model.fit(X_train_aug, steps_per_epoch=steps, epochs=epoch_num, validation_data=(X_test, y_test), verbose=1)\n",
    "print('Total time for training the final model:', (datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_4', 'layers': [{'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'batch_input_shape': (None, 32, 32, 3), 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_28', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_29', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_30', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_31', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.3, 'noise_shape': None, 'seed': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_32', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_33', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.4, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_34', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([1]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'uniform', 'seed': 888}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "# Display the configuration of the final model\n",
    "print(final_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize model training hisotry for accuracy and loss\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12,12))\n",
    "plt.subplot(211)\n",
    "plt.plot(final_hist.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_accuracy'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Accuracy)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.subplot(212)\n",
    "plt.plot(final_hist.history['loss'], color='blue', label='train')\n",
    "plt.plot(final_hist.history['val_loss'], color='red', label='test')\n",
    "plt.title('Final Model Training Performance (Loss)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data item #0 predicted to be [3] (expected [3])\n",
      "Data item #1 predicted to be [8] (expected [8])\n",
      "Data item #2 predicted to be [8] (expected [8])\n",
      "Data item #3 predicted to be [0] (expected [0])\n",
      "Data item #4 predicted to be [6] (expected [6])\n",
      "Data item #5 predicted to be [6] (expected [6])\n",
      "Data item #6 predicted to be [1] (expected [1])\n",
      "Data item #7 predicted to be [6] (expected [6])\n",
      "Data item #8 predicted to be [3] (expected [3])\n",
      "Data item #9 predicted to be [1] (expected [1])\n",
      "Data item #10 predicted to be [0] (expected [0])\n",
      "Data item #11 predicted to be [9] (expected [9])\n",
      "Data item #12 predicted to be [5] (expected [5])\n",
      "Data item #13 predicted to be [7] (expected [7])\n",
      "Data item #14 predicted to be [9] (expected [9])\n",
      "Data item #15 predicted to be [8] (expected [8])\n",
      "Data item #16 predicted to be [5] (expected [5])\n",
      "Data item #17 predicted to be [7] (expected [7])\n",
      "Data item #18 predicted to be [8] (expected [8])\n",
      "Data item #19 predicted to be [6] (expected [6])\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_test)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('Data item #%d predicted to be %s (expected %s)' % (i, encoder.inverse_transform([predictions[i]]), encoder.inverse_transform([np.argmax(y_test[i])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 22:26:08.536612\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
