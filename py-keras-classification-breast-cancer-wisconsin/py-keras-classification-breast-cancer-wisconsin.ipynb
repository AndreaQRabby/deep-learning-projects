{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Deep Learning Model for Breast Cancer Wisconsin (Original) Using Keras\n",
    "### David Lowe\n",
    "### November 4, 2019\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The Breast Cancer Wisconsin dataset is a binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: The dataset contains various measurements of breast tissue samples for cancer diagnosis. It contains measurements such as the thickness of the clump, the uniformity of cell size and shape, the marginal adhesion, and so on. Dr. William H. Wolberg of the University of Wisconsin Hospitals in Madison is the original provider of this dataset.\n",
    "\n",
    "ANALYSIS: The baseline performance of the model achieved an average accuracy score of 97.13%. Using the same training parameters, the model processed the test dataset with an accuracy of 97.71%, which was consistent with the result from the training data.\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using Keras and TensorFlow achieved a satisfactory result and should be considered for future modeling activities\n",
    "\n",
    "Dataset Used: Breast Cancer Wisconsin (Original) Data Set\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about six major tasks:\n",
    "0. Prepare Environment\n",
    "1. Load Data\n",
    "2. Define Model\n",
    "3. Fit and Evaluate Model\n",
    "4. Optimize Model\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seed numbers for reproducible results\n",
    "seedNum = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seedNum)\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import smtplib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Configure a new global `tensorflow` session\n",
    "import keras as K\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_kernel_init = K.initializers.RandomNormal(seed=seedNum)\n",
    "default_loss = 'binary_crossentropy'\n",
    "default_optimizer = 'adam'\n",
    "default_epochs = 100\n",
    "default_batches = 5\n",
    "default_metrics = ['accuracy']\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1018099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1018561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1033078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1033078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  attr01  attr02  attr03  attr04  attr05  attr06  attr07  attr08  \\\n",
       "0  1000025       5       1       1       1       2     1.0       3       1   \n",
       "1  1002945       5       4       4       5       7    10.0       3       2   \n",
       "2  1015425       3       1       1       1       2     2.0       3       1   \n",
       "3  1016277       6       8       8       1       3     4.0       3       7   \n",
       "4  1017023       4       1       1       3       2     1.0       3       1   \n",
       "5  1017122       8      10      10       8       7    10.0       9       7   \n",
       "6  1018099       1       1       1       1       2    10.0       3       1   \n",
       "7  1018561       2       1       2       1       2     1.0       3       1   \n",
       "8  1033078       2       1       1       1       2     1.0       1       1   \n",
       "9  1033078       4       2       1       1       2     1.0       2       1   \n",
       "\n",
       "   attr09  target  \n",
       "0       1       2  \n",
       "1       1       2  \n",
       "2       1       2  \n",
       "3       1       2  \n",
       "4       1       2  \n",
       "5       1       4  \n",
       "6       1       2  \n",
       "7       1       2  \n",
       "8       5       2  \n",
       "9       1       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "dest_file = os.path.basename(dataset_path)\n",
    "if (os.path.isfile(dest_file) == False) :\n",
    "    print('Downloading ' + dataset_path + ' as ' + dest_file)\n",
    "    with urllib.request.urlopen(dataset_path) as in_resp, open(dest_file, 'wb') as out_file:\n",
    "        shutil.copyfileobj(in_resp, out_file)\n",
    "    print(dest_file + 'downloaded!')\n",
    "#     print('Unpacking ' + dest_file)\n",
    "#     with zipfile.ZipFile(dest_file, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('.')\n",
    "#     print(dest_file + 'unpacked!')\n",
    "\n",
    "inputFile = dest_file\n",
    "attrNames = ['attr' + str(i).zfill(2) for i in range(1,10)]\n",
    "colNames = ['id'] + attrNames + ['target']\n",
    "Xy_original = pd.read_csv(inputFile, names=colNames, sep=',', header=None, index_col=False, na_values=['?'])\n",
    "\n",
    "# Take a peek at the dataframe after the import\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "id        699 non-null int64\n",
      "attr01    699 non-null int64\n",
      "attr02    699 non-null int64\n",
      "attr03    699 non-null int64\n",
      "attr04    699 non-null int64\n",
      "attr05    699 non-null int64\n",
      "attr06    683 non-null float64\n",
      "attr07    699 non-null int64\n",
      "attr08    699 non-null int64\n",
      "attr09    699 non-null int64\n",
      "target    699 non-null int64\n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 60.2 KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      attr01      attr02      attr03      attr04  \\\n",
       "count  6.990000e+02  699.000000  699.000000  699.000000  699.000000   \n",
       "mean   1.071704e+06    4.417740    3.134478    3.207439    2.806867   \n",
       "std    6.170957e+05    2.815741    3.051459    2.971913    2.855379   \n",
       "min    6.163400e+04    1.000000    1.000000    1.000000    1.000000   \n",
       "25%    8.706885e+05    2.000000    1.000000    1.000000    1.000000   \n",
       "50%    1.171710e+06    4.000000    1.000000    1.000000    1.000000   \n",
       "75%    1.238298e+06    6.000000    5.000000    5.000000    4.000000   \n",
       "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "           attr05      attr06      attr07      attr08      attr09      target  \n",
       "count  699.000000  683.000000  699.000000  699.000000  699.000000  699.000000  \n",
       "mean     3.216023    3.544656    3.437768    2.866953    1.589413    2.689557  \n",
       "std      2.214300    3.643857    2.438364    3.053634    1.715078    0.951273  \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    2.000000  \n",
       "25%      2.000000    1.000000    2.000000    1.000000    1.000000    2.000000  \n",
       "50%      2.000000    1.000000    3.000000    1.000000    1.000000    2.000000  \n",
       "75%      4.000000    6.000000    5.000000    4.000000    1.000000    4.000000  \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "attr01     0\n",
      "attr02     0\n",
      "attr03     0\n",
      "attr04     0\n",
      "attr05     0\n",
      "attr06    16\n",
      "attr07     0\n",
      "attr08     0\n",
      "attr09     0\n",
      "target     0\n",
      "dtype: int64\n",
      "Total number of NaN in the dataframe:  16\n"
     ]
    }
   ],
   "source": [
    "print(Xy_original.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attr01  attr02  attr03  attr04  attr05  attr06  attr07  attr08  attr09  \\\n",
       "0       5       1       1       1       2     1.0       3       1       1   \n",
       "1       5       4       4       5       7    10.0       3       2       1   \n",
       "2       3       1       1       1       2     2.0       3       1       1   \n",
       "3       6       8       8       1       3     4.0       3       7       1   \n",
       "4       4       1       1       3       2     1.0       3       1       1   \n",
       "5       8      10      10       8       7    10.0       9       7       1   \n",
       "6       1       1       1       1       2    10.0       3       1       1   \n",
       "7       2       1       2       1       2     1.0       3       1       1   \n",
       "8       2       1       1       1       2     1.0       1       1       5   \n",
       "9       4       2       1       1       2     1.0       2       1       1   \n",
       "\n",
       "   targetVar  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          1  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the class column to the name of targetVar if required\n",
    "# Xy_original = Xy_original.rename(columns={'old_name': 'targetVar'})\n",
    "\n",
    "# Dropping non-essential features\n",
    "Xy_original.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Impute missing values\n",
    "# Xy_original['col_name'].fillna('someValue', inplace=True)\n",
    "Xy_original['attr06'].fillna(value=Xy_original['attr06'].median(), inplace=True)\n",
    "\n",
    "# Convert columns from one data type to another\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('int')\n",
    "# Xy_original.column_name = Xy_original.column_name.astype('category')\n",
    "\n",
    "# Convert features with 2/4 (benign/malignant) levels into categorical feature of 0/1\n",
    "def reClassSomecol(target):\n",
    "    if (target == 4): return 1\n",
    "    else: return 0\n",
    "Xy_original['targetVar'] = Xy_original['target'].apply(reClassSomecol)\n",
    "Xy_original.drop(columns=['target'], inplace=True)\n",
    "\n",
    "# Take a peek at the dataframe after the cleaning\n",
    "Xy_original.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      "attr01       699 non-null int64\n",
      "attr02       699 non-null int64\n",
      "attr03       699 non-null int64\n",
      "attr04       699 non-null int64\n",
      "attr05       699 non-null int64\n",
      "attr06       699 non-null float64\n",
      "attr07       699 non-null int64\n",
      "attr08       699 non-null int64\n",
      "attr09       699 non-null int64\n",
      "targetVar    699 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "Xy_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr01</th>\n",
       "      <th>attr02</th>\n",
       "      <th>attr03</th>\n",
       "      <th>attr04</th>\n",
       "      <th>attr05</th>\n",
       "      <th>attr06</th>\n",
       "      <th>attr07</th>\n",
       "      <th>attr08</th>\n",
       "      <th>attr09</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.486409</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>0.344778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.621929</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.475636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           attr01      attr02      attr03      attr04      attr05      attr06  \\\n",
       "count  699.000000  699.000000  699.000000  699.000000  699.000000  699.000000   \n",
       "mean     4.417740    3.134478    3.207439    2.806867    3.216023    3.486409   \n",
       "std      2.815741    3.051459    2.971913    2.855379    2.214300    3.621929   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      4.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "75%      6.000000    5.000000    5.000000    4.000000    4.000000    5.000000   \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "           attr07      attr08      attr09   targetVar  \n",
       "count  699.000000  699.000000  699.000000  699.000000  \n",
       "mean     3.437768    2.866953    1.589413    0.344778  \n",
       "std      2.438364    3.053634    1.715078    0.475636  \n",
       "min      1.000000    1.000000    1.000000    0.000000  \n",
       "25%      2.000000    1.000000    1.000000    0.000000  \n",
       "50%      3.000000    1.000000    1.000000    0.000000  \n",
       "75%      5.000000    4.000000    1.000000    1.000000  \n",
       "max     10.000000   10.000000   10.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr01       0\n",
      "attr02       0\n",
      "attr03       0\n",
      "attr04       0\n",
      "attr05       0\n",
      "attr06       0\n",
      "attr07       0\n",
      "attr08       0\n",
      "attr09       0\n",
      "targetVar    0\n",
      "dtype: int64\n",
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print(Xy_original.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(Xy_original.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1\n",
    "\n",
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = totCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xy_original.shape: (699, 10) X_original.shape: (699, 9) y_original.shape: (699,)\n"
     ]
    }
   ],
   "source": [
    "# We create attribute-only and target-only datasets (X_original and y_original)\n",
    "# for various visualization and cleaning/transformation operations\n",
    "\n",
    "if targetCol == totCol:\n",
    "    X_original = Xy_original.iloc[:,0:totAttr]\n",
    "    y_original = Xy_original.iloc[:,totAttr]\n",
    "else:\n",
    "    X_original = Xy_original.iloc[:,1:totCol]\n",
    "    y_original = Xy_original.iloc[:,0]\n",
    "\n",
    "print(\"Xy_original.shape: {} X_original.shape: {} y_original.shape: {}\".format(Xy_original.shape, X_original.shape, y_original.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature scaling techniques\n",
    "\n",
    "X_colNames = list(X_original.columns)\n",
    "X_original[X_colNames] = preprocessing.scale(X_original[X_colNames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 4\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to display the data visualization plots\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = dispCol*4\n",
    "fig_size[1] = dispRow*4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms for each attribute\n",
    "X_original.hist(layout=(dispRow,dispCol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1\n",
      " 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1\n",
      " 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
      " 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_original)\n",
    "y_encoded = encoder.transform(y_original)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (524, 9) X_train.type: <class 'numpy.ndarray'>\n",
      "y_train.shape: (524,) y_train.type: <class 'numpy.ndarray'>\n",
      "X_test.shape: (175, 9) X_test.shape: <class 'numpy.ndarray'>\n",
      "y_test.shape: (175,) y_test.shape: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Finalize the training and testing datasets for the modeling activities\n",
    "X_encoded = X_original.to_numpy()\n",
    "\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=splitPercentage, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_encoded, y_encoded\n",
    "    X_test, y_test = X_encoded, y_encoded\n",
    "print(\"X_train.shape: {} X_train.type: {}\".format(X_train.shape, type(X_train)))\n",
    "print(\"y_train.shape: {} y_train.type: {}\".format(y_train.shape, type(y_train)))\n",
    "print(\"X_test.shape: {} X_test.shape: {}\".format(X_test.shape, type(X_test)))\n",
    "print(\"y_test.shape: {} y_test.shape: {}\".format(y_test.shape, type(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_default_model():\n",
    "    default_model = K.models.Sequential()\n",
    "    default_model.add(Dense(9, input_dim=9, kernel_initializer=default_kernel_init, activation='relu'))\n",
    "    default_model.add(Dense(1, kernel_initializer=default_kernel_init, activation='sigmoid'))\n",
    "    default_model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Keras model\n",
    "cv_model = KerasClassifier(build_fn=create_default_model, epochs=default_epochs, batch_size=default_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Generating results using the metrics of ['accuracy']\n",
      "All cross-Validate results: [0.92452831 0.98113208 0.90566038 1.         0.98076923 0.98076923\n",
      " 0.96153846 0.9423077  0.98076923 0.96153846]\n",
      "Baseline results [mean (std)]: 96.19% (2.80%)\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate the Keras model using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seedNum)\n",
    "results = cross_val_score(cv_model, X_train, y_train, cv=kfold)\n",
    "print('Generating results using the metrics of', default_metrics)\n",
    "print('All cross-Validate results:', results)\n",
    "print('Baseline results [mean (std)]: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pb01NDTS44-"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_customized_model(optimizer, kernel_init):\n",
    "    customized_model = K.models.Sequential()\n",
    "    customized_model.add(Dense(9, input_dim=9, kernel_initializer=kernel_init, activation='relu'))\n",
    "    customized_model.add(Dense(1, kernel_initializer=kernel_init, activation='sigmoid'))\n",
    "    customized_model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return customized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.971374 using {'batch_size': 15, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.016685) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.963740 (0.016458) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.961832 (0.008619) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.967557 (0.019690) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.012952) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.963740 (0.015314) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.963740 (0.014021) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.959924 (0.019477) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.963740 (0.015314) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.965649 (0.016685) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.969466 (0.014047) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.961832 (0.017100) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.961832 (0.016001) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.959924 (0.019477) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.011532) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.961832 (0.017100) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.011532) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.959924 (0.011176) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.969466 (0.015337) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.965649 (0.015507) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.020586) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.971374 (0.013527) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.015507) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.965649 (0.013013) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.963740 (0.016458) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.963740 (0.016410) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.967557 (0.012962) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.963740 (0.015262) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.967557 (0.014295) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.961832 (0.017100) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.015507) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.961832 (0.017100) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.959924 (0.014125) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.969466 (0.012687) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.963740 (0.011201) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.963740 (0.016458) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.969466 (0.016432) with: {'batch_size': 20, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.967557 (0.017748) with: {'batch_size': 20, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.967557 (0.015515) with: {'batch_size': 20, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.967557 (0.017748) with: {'batch_size': 20, 'epochs': 100, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.959924 (0.012698) with: {'batch_size': 20, 'epochs': 100, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.967557 (0.016645) with: {'batch_size': 20, 'epochs': 100, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.017741) with: {'batch_size': 20, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.961832 (0.019108) with: {'batch_size': 20, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.961832 (0.019108) with: {'batch_size': 20, 'epochs': 150, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.965649 (0.016685) with: {'batch_size': 20, 'epochs': 150, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.015507) with: {'batch_size': 20, 'epochs': 150, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.961832 (0.012124) with: {'batch_size': 20, 'epochs': 150, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n",
      "0.965649 (0.015507) with: {'batch_size': 20, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.965649 (0.015507) with: {'batch_size': 20, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.967557 (0.015515) with: {'batch_size': 20, 'epochs': 200, 'kernel_init': 'glorot_normal', 'optimizer': 'adam'}\n",
      "0.965649 (0.017696) with: {'batch_size': 20, 'epochs': 200, 'kernel_init': 'glorot_normal', 'optimizer': 'rmsprop'}\n",
      "0.967557 (0.014295) with: {'batch_size': 20, 'epochs': 200, 'kernel_init': 'Orthogonal', 'optimizer': 'adam'}\n",
      "0.969466 (0.015337) with: {'batch_size': 20, 'epochs': 200, 'kernel_init': 'Orthogonal', 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "grid_model = KerasClassifier(build_fn=create_customized_model, verbose=0)\n",
    "\n",
    "# Perform grid search using different epochs, batch sizes, and optimizers\n",
    "optimizer_grid = ['adam', 'rmsprop']\n",
    "init_grid = ['RandomNormal', 'glorot_normal', 'Orthogonal']\n",
    "epoch_grid = [100, 150, 200]\n",
    "batch_grid = [10, 15, 20]\n",
    "param_grid = dict(optimizer=optimizer_grid, kernel_init=init_grid, epochs=epoch_grid, batch_size=batch_grid)\n",
    "grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = grid_result.best_params_[\"optimizer\"]\n",
    "best_kernel_init = grid_result.best_params_[\"kernel_init\"]\n",
    "best_epoch = grid_result.best_params_[\"epochs\"]\n",
    "best_batch = grid_result.best_params_[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming the final model using: optimizer=rmsprop, kernel=glorot_normal, epochs=100, batch_size=15\n",
      "Epoch 1/100\n",
      "524/524 [==============================] - 27s 52ms/step - loss: 0.5126 - acc: 0.9198\n",
      "Epoch 2/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.4105 - acc: 0.9504\n",
      "Epoch 3/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.3274 - acc: 0.9561\n",
      "Epoch 4/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.2595 - acc: 0.9637\n",
      "Epoch 5/100\n",
      "524/524 [==============================] - 0s 898us/step - loss: 0.2087 - acc: 0.9676\n",
      "Epoch 6/100\n",
      "524/524 [==============================] - 0s 910us/step - loss: 0.1707 - acc: 0.9676\n",
      "Epoch 7/100\n",
      "524/524 [==============================] - 0s 936us/step - loss: 0.1437 - acc: 0.9656\n",
      "Epoch 8/100\n",
      "524/524 [==============================] - 0s 920us/step - loss: 0.1246 - acc: 0.9676\n",
      "Epoch 9/100\n",
      "524/524 [==============================] - 0s 923us/step - loss: 0.1113 - acc: 0.9656\n",
      "Epoch 10/100\n",
      "524/524 [==============================] - 0s 913us/step - loss: 0.1028 - acc: 0.9656\n",
      "Epoch 11/100\n",
      "524/524 [==============================] - 0s 833us/step - loss: 0.0971 - acc: 0.9656\n",
      "Epoch 12/100\n",
      "524/524 [==============================] - 1s 969us/step - loss: 0.0928 - acc: 0.9656\n",
      "Epoch 13/100\n",
      "524/524 [==============================] - 0s 901us/step - loss: 0.0899 - acc: 0.9656\n",
      "Epoch 14/100\n",
      "524/524 [==============================] - 0s 857us/step - loss: 0.0878 - acc: 0.9676\n",
      "Epoch 15/100\n",
      "524/524 [==============================] - 1s 967us/step - loss: 0.0855 - acc: 0.9656\n",
      "Epoch 16/100\n",
      "524/524 [==============================] - 0s 925us/step - loss: 0.0841 - acc: 0.9676\n",
      "Epoch 17/100\n",
      "524/524 [==============================] - 0s 858us/step - loss: 0.0829 - acc: 0.9656\n",
      "Epoch 18/100\n",
      "524/524 [==============================] - 0s 828us/step - loss: 0.0818 - acc: 0.9695\n",
      "Epoch 19/100\n",
      "524/524 [==============================] - 0s 833us/step - loss: 0.0810 - acc: 0.9695\n",
      "Epoch 20/100\n",
      "524/524 [==============================] - 0s 868us/step - loss: 0.0800 - acc: 0.9714\n",
      "Epoch 21/100\n",
      "524/524 [==============================] - 0s 840us/step - loss: 0.0792 - acc: 0.9714\n",
      "Epoch 22/100\n",
      "524/524 [==============================] - 0s 832us/step - loss: 0.0785 - acc: 0.9714\n",
      "Epoch 23/100\n",
      "524/524 [==============================] - 0s 815us/step - loss: 0.0778 - acc: 0.9714\n",
      "Epoch 24/100\n",
      "524/524 [==============================] - 0s 864us/step - loss: 0.0775 - acc: 0.9714\n",
      "Epoch 25/100\n",
      "524/524 [==============================] - 0s 867us/step - loss: 0.0767 - acc: 0.9714\n",
      "Epoch 26/100\n",
      "524/524 [==============================] - 1s 967us/step - loss: 0.0763 - acc: 0.9714\n",
      "Epoch 27/100\n",
      "524/524 [==============================] - 0s 948us/step - loss: 0.0757 - acc: 0.9714\n",
      "Epoch 28/100\n",
      "524/524 [==============================] - 0s 916us/step - loss: 0.0756 - acc: 0.9714\n",
      "Epoch 29/100\n",
      "524/524 [==============================] - 0s 873us/step - loss: 0.0748 - acc: 0.9714\n",
      "Epoch 30/100\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0744 - acc: 0.9695\n",
      "Epoch 31/100\n",
      "524/524 [==============================] - 0s 838us/step - loss: 0.0740 - acc: 0.9714\n",
      "Epoch 32/100\n",
      "524/524 [==============================] - 0s 827us/step - loss: 0.0741 - acc: 0.9695\n",
      "Epoch 33/100\n",
      "524/524 [==============================] - 0s 832us/step - loss: 0.0733 - acc: 0.9695\n",
      "Epoch 34/100\n",
      "524/524 [==============================] - 0s 923us/step - loss: 0.0732 - acc: 0.9695\n",
      "Epoch 35/100\n",
      "524/524 [==============================] - 0s 834us/step - loss: 0.0725 - acc: 0.9714\n",
      "Epoch 36/100\n",
      "524/524 [==============================] - 0s 846us/step - loss: 0.0725 - acc: 0.9695\n",
      "Epoch 37/100\n",
      "524/524 [==============================] - 0s 856us/step - loss: 0.0720 - acc: 0.9695\n",
      "Epoch 38/100\n",
      "524/524 [==============================] - 1s 959us/step - loss: 0.0716 - acc: 0.9714\n",
      "Epoch 39/100\n",
      "524/524 [==============================] - 0s 901us/step - loss: 0.0713 - acc: 0.9695\n",
      "Epoch 40/100\n",
      "524/524 [==============================] - 1s 981us/step - loss: 0.0708 - acc: 0.9695\n",
      "Epoch 41/100\n",
      "524/524 [==============================] - 0s 896us/step - loss: 0.0707 - acc: 0.9733\n",
      "Epoch 42/100\n",
      "524/524 [==============================] - 0s 834us/step - loss: 0.0706 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "524/524 [==============================] - 0s 930us/step - loss: 0.0700 - acc: 0.9733\n",
      "Epoch 44/100\n",
      "524/524 [==============================] - 0s 925us/step - loss: 0.0699 - acc: 0.9733\n",
      "Epoch 45/100\n",
      "524/524 [==============================] - 0s 889us/step - loss: 0.0697 - acc: 0.9733\n",
      "Epoch 46/100\n",
      "524/524 [==============================] - 0s 952us/step - loss: 0.0693 - acc: 0.9733\n",
      "Epoch 47/100\n",
      "524/524 [==============================] - 0s 950us/step - loss: 0.0690 - acc: 0.9733\n",
      "Epoch 48/100\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0689 - acc: 0.9733\n",
      "Epoch 49/100\n",
      "524/524 [==============================] - 0s 821us/step - loss: 0.0685 - acc: 0.9733\n",
      "Epoch 50/100\n",
      "524/524 [==============================] - 0s 922us/step - loss: 0.0684 - acc: 0.9733\n",
      "Epoch 51/100\n",
      "524/524 [==============================] - 0s 854us/step - loss: 0.0682 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "524/524 [==============================] - 0s 856us/step - loss: 0.0681 - acc: 0.9733\n",
      "Epoch 53/100\n",
      "524/524 [==============================] - 0s 911us/step - loss: 0.0677 - acc: 0.9733\n",
      "Epoch 54/100\n",
      "524/524 [==============================] - 0s 936us/step - loss: 0.0678 - acc: 0.9733\n",
      "Epoch 55/100\n",
      "524/524 [==============================] - 0s 866us/step - loss: 0.0675 - acc: 0.9733\n",
      "Epoch 56/100\n",
      "524/524 [==============================] - 0s 927us/step - loss: 0.0671 - acc: 0.9733\n",
      "Epoch 57/100\n",
      "524/524 [==============================] - 0s 883us/step - loss: 0.0674 - acc: 0.9733\n",
      "Epoch 58/100\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.0668 - acc: 0.9733\n",
      "Epoch 59/100\n",
      "524/524 [==============================] - 0s 911us/step - loss: 0.0671 - acc: 0.9733\n",
      "Epoch 60/100\n",
      "524/524 [==============================] - 0s 880us/step - loss: 0.0669 - acc: 0.9733\n",
      "Epoch 61/100\n",
      "524/524 [==============================] - 0s 884us/step - loss: 0.0666 - acc: 0.9733\n",
      "Epoch 62/100\n",
      "524/524 [==============================] - 1s 992us/step - loss: 0.0664 - acc: 0.9733\n",
      "Epoch 63/100\n",
      "524/524 [==============================] - 0s 862us/step - loss: 0.0663 - acc: 0.9752\n",
      "Epoch 64/100\n",
      "524/524 [==============================] - 0s 897us/step - loss: 0.0663 - acc: 0.9733\n",
      "Epoch 65/100\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.0661 - acc: 0.9733\n",
      "Epoch 66/100\n",
      "524/524 [==============================] - 0s 849us/step - loss: 0.0658 - acc: 0.9733\n",
      "Epoch 67/100\n",
      "524/524 [==============================] - 0s 844us/step - loss: 0.0657 - acc: 0.9752\n",
      "Epoch 68/100\n",
      "524/524 [==============================] - 0s 812us/step - loss: 0.0657 - acc: 0.9752\n",
      "Epoch 69/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0654 - acc: 0.9752\n",
      "Epoch 70/100\n",
      "524/524 [==============================] - 0s 935us/step - loss: 0.0652 - acc: 0.9752\n",
      "Epoch 71/100\n",
      "524/524 [==============================] - 0s 881us/step - loss: 0.0652 - acc: 0.9752\n",
      "Epoch 72/100\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.0652 - acc: 0.9752\n",
      "Epoch 73/100\n",
      "524/524 [==============================] - 0s 898us/step - loss: 0.0648 - acc: 0.9752\n",
      "Epoch 74/100\n",
      "524/524 [==============================] - 0s 880us/step - loss: 0.0649 - acc: 0.9752\n",
      "Epoch 75/100\n",
      "524/524 [==============================] - 0s 855us/step - loss: 0.0646 - acc: 0.9752\n",
      "Epoch 76/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0645 - acc: 0.9752\n",
      "Epoch 77/100\n",
      "524/524 [==============================] - 0s 892us/step - loss: 0.0645 - acc: 0.9752\n",
      "Epoch 78/100\n",
      "524/524 [==============================] - 0s 876us/step - loss: 0.0641 - acc: 0.9752\n",
      "Epoch 79/100\n",
      "524/524 [==============================] - 0s 897us/step - loss: 0.0641 - acc: 0.9752\n",
      "Epoch 80/100\n",
      "524/524 [==============================] - 1s 994us/step - loss: 0.0641 - acc: 0.9752\n",
      "Epoch 81/100\n",
      "524/524 [==============================] - 0s 871us/step - loss: 0.0638 - acc: 0.9752\n",
      "Epoch 82/100\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0638 - acc: 0.9752\n",
      "Epoch 83/100\n",
      "524/524 [==============================] - 0s 929us/step - loss: 0.0635 - acc: 0.9752\n",
      "Epoch 84/100\n",
      "524/524 [==============================] - 0s 926us/step - loss: 0.0634 - acc: 0.9752\n",
      "Epoch 85/100\n",
      "524/524 [==============================] - 0s 887us/step - loss: 0.0633 - acc: 0.9752\n",
      "Epoch 86/100\n",
      "524/524 [==============================] - 0s 910us/step - loss: 0.0631 - acc: 0.9752\n",
      "Epoch 87/100\n",
      "524/524 [==============================] - 0s 805us/step - loss: 0.0631 - acc: 0.9752\n",
      "Epoch 88/100\n",
      "524/524 [==============================] - 0s 799us/step - loss: 0.0629 - acc: 0.9752\n",
      "Epoch 89/100\n",
      "524/524 [==============================] - 1s 958us/step - loss: 0.0628 - acc: 0.9752\n",
      "Epoch 90/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0627 - acc: 0.9752\n",
      "Epoch 91/100\n",
      "524/524 [==============================] - 0s 919us/step - loss: 0.0626 - acc: 0.9752\n",
      "Epoch 92/100\n",
      "524/524 [==============================] - 0s 920us/step - loss: 0.0623 - acc: 0.9752\n",
      "Epoch 93/100\n",
      "524/524 [==============================] - 0s 839us/step - loss: 0.0622 - acc: 0.9752\n",
      "Epoch 94/100\n",
      "524/524 [==============================] - 0s 884us/step - loss: 0.0621 - acc: 0.9752\n",
      "Epoch 95/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0619 - acc: 0.9752\n",
      "Epoch 96/100\n",
      "524/524 [==============================] - 0s 907us/step - loss: 0.0616 - acc: 0.9752\n",
      "Epoch 97/100\n",
      "524/524 [==============================] - 0s 870us/step - loss: 0.0616 - acc: 0.9752\n",
      "Epoch 98/100\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0615 - acc: 0.9752\n",
      "Epoch 99/100\n",
      "524/524 [==============================] - 0s 947us/step - loss: 0.0613 - acc: 0.9752\n",
      "Epoch 100/100\n",
      "524/524 [==============================] - 0s 828us/step - loss: 0.0610 - acc: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fb9f6f410>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "print('Forming the final model using: optimizer=%s, kernel=%s, epochs=%d, batch_size=%d'\n",
    "      % (best_optimizer, best_kernel_init, best_epoch, best_batch))\n",
    "final_model = create_customized_model(best_optimizer, best_kernel_init)\n",
    "final_model.fit(X_train, y_train, epochs=best_epoch, batch_size=best_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_563 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_564 (Dense)            (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 12s 69ms/step\n",
      "\n",
      "acc: 97.71%\n",
      "\n",
      "loss: 6.45%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[0], scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5038655932410934, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, 0.41819560385677423, 0.6411472095809492, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[-0.1484649376653878, -0.6999950505092654, -0.7432990353709374, 0.06768675155122376, -1.001494758686986, -0.6869791677722814, -0.590066800026423, -0.6118250369454719, -0.3439117826575238] => 1 (expected 0)\n",
      "[0.20693571791031778, -0.6999950505092654, 0.2668747022653916, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.17966213015729893, -0.28411185623674784, -0.3439117826575238] => 0 (expected 0)\n",
      "[-0.1484649376653878, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.17966213015729893, 1.026740866598148, -0.3439117826575238] => 1 (expected 0)\n",
      "[0.9177370290617288, 1.595632149317702, 1.2770484399017208, 1.119087625646899, 0.35430544077499576, -0.13439178195775361, 1.8723612191883217, 1.682167228015596, 1.4065324120823484] => 0 (expected 1)\n",
      "[-0.5038655932410934, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.590066800026423, -0.6118250369454719, -0.3439117826575238] => 1 (expected 0)\n",
      "[-0.8592662488167989, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.590066800026423, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[0.20693571791031778, -0.04410156484441759, -0.06984987694671807, -0.6332471645125597, -0.0976279590456648, -0.13439178195775361, -0.17966213015729893, 0.04360132447197608, 0.8230510138357243] => 0 (expected 1)\n",
      "[-1.2146669043925045, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.17966213015729893, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[-0.1484649376653878, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -1.001494758686986, -0.6869791677722814, -0.590066800026423, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[1.62853834021314, -0.6999950505092654, -0.40657445615882776, 1.119087625646899, 0.35430544077499576, 1.7996640683930936, 1.4619565493191973, 1.3544540473068718, 0.23956961558910025] => 0 (expected 1)\n",
      "[-1.2146669043925045, -0.6999950505092654, -0.7432990353709374, -0.282780206480668, -0.5495613588663254, -0.6869791677722814, -0.590066800026423, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[0.20693571791031778, -0.3720483076768415, -0.40657445615882776, 0.4181537095831155, -0.5495613588663254, 0.1419019109495103, -1.000471469895547, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[-1.2146669043925045, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.17966213015729893, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[-0.5038655932410934, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -1.000471469895547, -0.6118250369454719, -0.3439117826575238] => 1 (expected 0)\n",
      "[-0.1484649376653878, 1.595632149317702, 0.940323860689611, 0.06768675155122376, 0.35430544077499576, 1.7996640683930936, 1.4619565493191973, -0.6118250369454719, -0.3439117826575238] => 1 (expected 1)\n",
      "[-1.2146669043925045, -0.6999950505092654, -0.7432990353709374, -0.6332471645125597, -0.5495613588663254, -0.6869791677722814, -0.590066800026423, -0.6118250369454719, -0.3439117826575238] => 0 (expected 0)\n",
      "[1.2731376846374345, 2.2515256349825497, -0.06984987694671807, -0.282780206480668, 1.258172240416317, 0.1419019109495103, -0.17966213015729893, 2.3375935894330437, -0.3439117826575238] => 0 (expected 1)\n",
      "[-0.1484649376653878, -0.6999950505092654, -0.06984987694671807, 0.06768675155122376, -0.5495613588663254, -0.6869791677722814, -1.000471469895547, -0.6118250369454719, -0.3439117826575238] => 1 (expected 0)\n",
      "[0.20693571791031778, 2.2515256349825497, 2.28722217753805, 2.520955457774466, 1.258172240416317, 1.7996640683930936, 1.0515518794500733, 0.699027685889424, 0.23956961558910025] => 0 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_original)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 3:55:40.825066\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
