{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJ2xTLgBIuLe"
   },
   "source": [
    "# Binary Classification Deep Learning Model for the Sonar Dataset Using Keras\n",
    "### David Lowe\n",
    "### October 14, 2019\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The Sonar Dataset is a binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: The Sonar Dataset involves the prediction of whether an object is a mine or a rock given the strength of sonar returns at different angles. The dataset contains the patterns obtained by bouncing sonar signals off a metal cylinder or a rock at various angles and under various conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.\n",
    "\n",
    "ANALYSIS: The baseline performance of the model achieved an average accuracy score of 79.48%. Using the same training parameters, the model processed the test dataset with an accuracy of 82.69%, which was even better than results from the training data.\n",
    "\n",
    "CONCLUSION: For this dataset, the model built using Keras and TensorFlow achieved a satisfactory result and should be considered for future modeling activities.\n",
    "\n",
    "Dataset Used: Connectionist Bench (Sonar, Mines vs. Rocks) Data Set\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar,+Mines+vs.+Rocks%29\n",
    "\n",
    "One potential source of performance benchmarks: https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "\n",
    "Any deep-learning modeling project genrally can be broken down into about seven major tasks:\n",
    "0. Prepare Environment\n",
    "1. Load Data\n",
    "2. Define Model\n",
    "3. Compile Model\n",
    "4. Fit Model\n",
    "5. Evaluate Model\n",
    "6. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EqF7WxlHHPKr"
   },
   "source": [
    "# Section 0. Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seed numbers for reproducible results\n",
    "seedNum = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "X_BXx9P4HJGn",
    "outputId": "b19fcb52-1d53-4f4c-cd33-9298e58bcc5e"
   },
   "outputs": [],
   "source": [
    "# Load libraries and packages\n",
    "import random\n",
    "random.seed(seedNum)\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import pandas as pd\n",
    "import os\n",
    "import smtplib\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Configure a new global `tensorflow` session\n",
    "import keras as K\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seedNum)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbIqw1TBR0P2"
   },
   "outputs": [],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False\n",
    "\n",
    "# Set the flag for splitting the dataset\n",
    "splitDataset = True\n",
    "splitPercentage = 0.25\n",
    "\n",
    "# Set various default Keras modeling parameters\n",
    "default_kernel_init = K.initializers.glorot_uniform(seed=seedNum)\n",
    "default_loss = 'binary_crossentropy'\n",
    "default_optimizer = 'adam'\n",
    "default_metrics = ['accuracy']\n",
    "default_epochs = 100\n",
    "default_batches = 5\n",
    "\n",
    "# Set the number of folds for cross validation\n",
    "folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Un3ZnxByRhDV"
   },
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Keras Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehVMNSM6VnRE"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 0 Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hb0U0RL8Hdhy"
   },
   "source": [
    "# Section 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5G5M20LSG9i"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "F27fJh8CAWb6",
    "outputId": "772d7d84-0f99-4fe9-8a84-becd51b3919e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02 0.0371 0.0428 ... 0.009 0.0032 'R']\n",
      " [0.0453 0.0523 0.0843 ... 0.0052 0.0044 'R']\n",
      " [0.0262 0.0582 0.1099 ... 0.0095 0.0078 'R']\n",
      " ...\n",
      " [0.0522 0.0437 0.018 ... 0.0077 0.0031 'M']\n",
      " [0.0303 0.0353 0.049 ... 0.0036 0.0048 'M']\n",
      " [0.026 0.0363 0.0136 ... 0.0061 0.0115 'M']]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_original = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\", header=None)\n",
    "dataset = df_original.values\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKbZhVyPAZfX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_original: (208, 60) | Shape of y_original: (208,)\n"
     ]
    }
   ],
   "source": [
    "# Split the original dataset into input (X) and output (y) variables\n",
    "X_original = dataset[:,0:60].astype(float)\n",
    "y_original = dataset[:,60]\n",
    "print('Shape of X_original:', X_original.shape, '| Shape of y_original:', y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode class values as integers and perform one-hot-encoding\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_original)\n",
    "y_encoded = encoder.transform(y_original)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (156, 60) | Shape of y_train: (156,)\n",
      "Shape of X_test: (52, 60) | Shape of y_test: (52,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data further into training and test datasets\n",
    "if (splitDataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_original, y_encoded, test_size=splitPercentage, random_state=seedNum)\n",
    "else:\n",
    "    X_train, y_train = X_original, y_encoded\n",
    "    X_test, y_test = X_original, y_encoded\n",
    "print('Shape of X_train:', X_train.shape, '| Shape of y_train:', y_train.shape)\n",
    "print('Shape of X_test:', X_test.shape, '| Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4bUiYdhSara"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 1 Load Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljQSSE06Hkj0"
   },
   "source": [
    "# Section 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCo4dP5zSdib"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "AMBRuJibAefO",
    "outputId": "40716f3e-693b-475c-90e6-5a51cbe535dc"
   },
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_model():\n",
    "    model = K.models.Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer=default_kernel_init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=default_kernel_init, activation='sigmoid'))\n",
    "    model.compile(loss=default_loss, optimizer=default_optimizer, metrics=default_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "6XG4pa74AgTr",
    "outputId": "f31c5a67-bbd9-4ad8-e02e-dc62326b5eb3"
   },
   "outputs": [],
   "source": [
    "# Initialize the Keras model\n",
    "cv_model = KerasClassifier(build_fn=create_model, epochs=default_epochs, batch_size=default_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTbNwS6NSx2C"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 2 Define Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utyCDnHTIJzX"
   },
   "source": [
    "# Section 3. Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qobEj0hlS0xM"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AEreg3esAiW3",
    "outputId": "3d77cc8d-b5f4-4cde-d682-146f7d64447b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Generating results using the metrics of ['accuracy']\n",
      "All cross-validated results: [0.70588237 0.81250001 0.87500001 0.62500001 0.75000001 0.86666667\n",
      " 0.73333335 0.80000001 0.66666668 1.        ]\n",
      "Baseline results [mean(std)]: 78.35% (10.57%)\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate the Keras model using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seedNum)\n",
    "results = cross_val_score(cv_model, X_train, y_train, cv=kfold)\n",
    "print('Generating results using the metrics of', default_metrics)\n",
    "print('All cross-validated results:', results)\n",
    "print('Baseline results [mean(std)]: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pb01NDTS44-"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 3 Fit and Evaluate Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6Di1y9BIXey"
   },
   "source": [
    "# Section 4. Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waSYHP94S-JU"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model required for KerasClassifier\n",
    "def create_grid_model(optimizer, kernel_init):\n",
    "    model = K.models.Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer=kernel_init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=kernel_init, activation='sigmoid'))\n",
    "    model.compile(loss=default_loss, optimizer=optimizer, metrics=default_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.794872 using {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 5, 'epochs': 100, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 5, 'epochs': 100, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.794872 (0.067802) with: {'batch_size': 5, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.782051 (0.062939) with: {'batch_size': 5, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.762821 (0.045867) with: {'batch_size': 5, 'epochs': 100, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.769231 (0.080938) with: {'batch_size': 5, 'epochs': 100, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 5, 'epochs': 150, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 5, 'epochs': 150, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.782051 (0.074937) with: {'batch_size': 5, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.788462 (0.044255) with: {'batch_size': 5, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.782051 (0.055984) with: {'batch_size': 5, 'epochs': 150, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.762821 (0.048603) with: {'batch_size': 5, 'epochs': 150, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 5, 'epochs': 200, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 5, 'epochs': 200, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.782051 (0.052837) with: {'batch_size': 5, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.775641 (0.062332) with: {'batch_size': 5, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.782051 (0.025550) with: {'batch_size': 5, 'epochs': 200, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.775641 (0.058921) with: {'batch_size': 5, 'epochs': 200, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.762821 (0.088846) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.794872 (0.070786) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.794872 (0.049253) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.762821 (0.061775) with: {'batch_size': 10, 'epochs': 100, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.794872 (0.039984) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.775641 (0.054654) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.794872 (0.053286) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.775641 (0.071596) with: {'batch_size': 10, 'epochs': 150, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.788462 (0.044255) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.782051 (0.063501) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.775641 (0.040772) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.782051 (0.055984) with: {'batch_size': 10, 'epochs': 200, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.794872 (0.067468) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.775641 (0.087553) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.756410 (0.098112) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.750000 (0.070401) with: {'batch_size': 15, 'epochs': 100, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.762821 (0.088846) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.788462 (0.067164) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.782051 (0.078763) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.788462 (0.060694) with: {'batch_size': 15, 'epochs': 150, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n",
      "0.544872 (0.054248) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'Constant', 'optimizer': 'rmsprop'}\n",
      "0.544872 (0.054248) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'Constant', 'optimizer': 'adam'}\n",
      "0.775641 (0.079791) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'rmsprop'}\n",
      "0.788462 (0.067164) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'RandomNormal', 'optimizer': 'adam'}\n",
      "0.762821 (0.073568) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'RandomUniform', 'optimizer': 'rmsprop'}\n",
      "0.769231 (0.063233) with: {'batch_size': 15, 'epochs': 200, 'kernel_init': 'RandomUniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Create model for grid search\n",
    "grid_model = KerasClassifier(build_fn=create_grid_model, verbose=0)\n",
    "\n",
    "# Perform grid search using different epochs, batch sizes, and optimizers\n",
    "optimizer_grid = ['rmsprop', 'adam']\n",
    "init_grid = ['Constant', 'RandomNormal', 'RandomUniform']\n",
    "epoch_grid = [100, 150, 200]\n",
    "batch_grid = [5, 10, 15]\n",
    "param_grid = dict(optimizer=optimizer_grid, kernel_init=init_grid, epochs=epoch_grid, batch_size=batch_grid)\n",
    "grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer = 'rmsprop'\n",
    "best_kernel_init = 'RandomNormal'\n",
    "best_epochs = 150\n",
    "best_batches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "156/156 [==============================] - 2s 13ms/step - loss: 0.6917 - acc: 0.5192\n",
      "Epoch 2/150\n",
      "156/156 [==============================] - 0s 369us/step - loss: 0.6823 - acc: 0.5449\n",
      "Epoch 3/150\n",
      "156/156 [==============================] - 0s 344us/step - loss: 0.6740 - acc: 0.5449\n",
      "Epoch 4/150\n",
      "156/156 [==============================] - 0s 343us/step - loss: 0.6672 - acc: 0.5449\n",
      "Epoch 5/150\n",
      "156/156 [==============================] - 0s 347us/step - loss: 0.6596 - acc: 0.5449\n",
      "Epoch 6/150\n",
      "156/156 [==============================] - 0s 328us/step - loss: 0.6504 - acc: 0.5769\n",
      "Epoch 7/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.6415 - acc: 0.5897\n",
      "Epoch 8/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.6245 - acc: 0.6795\n",
      "Epoch 9/150\n",
      "156/156 [==============================] - 0s 350us/step - loss: 0.6130 - acc: 0.6731\n",
      "Epoch 10/150\n",
      "156/156 [==============================] - 0s 347us/step - loss: 0.5938 - acc: 0.7436\n",
      "Epoch 11/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.5809 - acc: 0.7179\n",
      "Epoch 12/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.5667 - acc: 0.7692\n",
      "Epoch 13/150\n",
      "156/156 [==============================] - 0s 352us/step - loss: 0.5435 - acc: 0.8077\n",
      "Epoch 14/150\n",
      "156/156 [==============================] - 0s 351us/step - loss: 0.5349 - acc: 0.7500\n",
      "Epoch 15/150\n",
      "156/156 [==============================] - 0s 345us/step - loss: 0.5262 - acc: 0.7821\n",
      "Epoch 16/150\n",
      "156/156 [==============================] - 0s 342us/step - loss: 0.5079 - acc: 0.8077\n",
      "Epoch 17/150\n",
      "156/156 [==============================] - 0s 355us/step - loss: 0.4961 - acc: 0.8205\n",
      "Epoch 18/150\n",
      "156/156 [==============================] - 0s 361us/step - loss: 0.4857 - acc: 0.8269\n",
      "Epoch 19/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.4802 - acc: 0.8013\n",
      "Epoch 20/150\n",
      "156/156 [==============================] - 0s 356us/step - loss: 0.4688 - acc: 0.8397\n",
      "Epoch 21/150\n",
      "156/156 [==============================] - 0s 346us/step - loss: 0.4639 - acc: 0.8205\n",
      "Epoch 22/150\n",
      "156/156 [==============================] - 0s 358us/step - loss: 0.4550 - acc: 0.8205\n",
      "Epoch 23/150\n",
      "156/156 [==============================] - 0s 364us/step - loss: 0.4485 - acc: 0.8269\n",
      "Epoch 24/150\n",
      "156/156 [==============================] - 0s 348us/step - loss: 0.4414 - acc: 0.8333\n",
      "Epoch 25/150\n",
      "156/156 [==============================] - 0s 348us/step - loss: 0.4406 - acc: 0.8333\n",
      "Epoch 26/150\n",
      "156/156 [==============================] - 0s 350us/step - loss: 0.4328 - acc: 0.8141\n",
      "Epoch 27/150\n",
      "156/156 [==============================] - 0s 355us/step - loss: 0.4301 - acc: 0.8205\n",
      "Epoch 28/150\n",
      "156/156 [==============================] - 0s 346us/step - loss: 0.4293 - acc: 0.8333\n",
      "Epoch 29/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.4218 - acc: 0.8205\n",
      "Epoch 30/150\n",
      "156/156 [==============================] - 0s 362us/step - loss: 0.4170 - acc: 0.8269\n",
      "Epoch 31/150\n",
      "156/156 [==============================] - 0s 374us/step - loss: 0.4105 - acc: 0.8269\n",
      "Epoch 32/150\n",
      "156/156 [==============================] - 0s 359us/step - loss: 0.4107 - acc: 0.8269\n",
      "Epoch 33/150\n",
      "156/156 [==============================] - 0s 345us/step - loss: 0.4067 - acc: 0.8141\n",
      "Epoch 34/150\n",
      "156/156 [==============================] - 0s 409us/step - loss: 0.4049 - acc: 0.8333\n",
      "Epoch 35/150\n",
      "156/156 [==============================] - 0s 337us/step - loss: 0.4013 - acc: 0.8205\n",
      "Epoch 36/150\n",
      "156/156 [==============================] - 0s 350us/step - loss: 0.3970 - acc: 0.8205\n",
      "Epoch 37/150\n",
      "156/156 [==============================] - 0s 344us/step - loss: 0.3976 - acc: 0.8205\n",
      "Epoch 38/150\n",
      "156/156 [==============================] - 0s 356us/step - loss: 0.3969 - acc: 0.8141\n",
      "Epoch 39/150\n",
      "156/156 [==============================] - 0s 361us/step - loss: 0.3928 - acc: 0.8269\n",
      "Epoch 40/150\n",
      "156/156 [==============================] - 0s 337us/step - loss: 0.3915 - acc: 0.8077\n",
      "Epoch 41/150\n",
      "156/156 [==============================] - 0s 342us/step - loss: 0.3895 - acc: 0.8205\n",
      "Epoch 42/150\n",
      "156/156 [==============================] - 0s 362us/step - loss: 0.3910 - acc: 0.8141\n",
      "Epoch 43/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.3818 - acc: 0.8205\n",
      "Epoch 44/150\n",
      "156/156 [==============================] - 0s 358us/step - loss: 0.3792 - acc: 0.8141\n",
      "Epoch 45/150\n",
      "156/156 [==============================] - 0s 358us/step - loss: 0.3898 - acc: 0.8141\n",
      "Epoch 46/150\n",
      "156/156 [==============================] - 0s 371us/step - loss: 0.3752 - acc: 0.8269\n",
      "Epoch 47/150\n",
      "156/156 [==============================] - 0s 340us/step - loss: 0.3719 - acc: 0.8141\n",
      "Epoch 48/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.3833 - acc: 0.8205\n",
      "Epoch 49/150\n",
      "156/156 [==============================] - 0s 345us/step - loss: 0.3795 - acc: 0.8269\n",
      "Epoch 50/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.3676 - acc: 0.8333\n",
      "Epoch 51/150\n",
      "156/156 [==============================] - 0s 334us/step - loss: 0.3671 - acc: 0.8462\n",
      "Epoch 52/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.3664 - acc: 0.8269\n",
      "Epoch 53/150\n",
      "156/156 [==============================] - 0s 338us/step - loss: 0.3737 - acc: 0.8077\n",
      "Epoch 54/150\n",
      "156/156 [==============================] - 0s 353us/step - loss: 0.3736 - acc: 0.8654\n",
      "Epoch 55/150\n",
      "156/156 [==============================] - 0s 424us/step - loss: 0.3665 - acc: 0.8397\n",
      "Epoch 56/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.3640 - acc: 0.8526\n",
      "Epoch 57/150\n",
      "156/156 [==============================] - 0s 344us/step - loss: 0.3558 - acc: 0.8397\n",
      "Epoch 58/150\n",
      "156/156 [==============================] - 0s 348us/step - loss: 0.3594 - acc: 0.8397\n",
      "Epoch 59/150\n",
      "156/156 [==============================] - 0s 368us/step - loss: 0.3674 - acc: 0.8141\n",
      "Epoch 60/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.3589 - acc: 0.8269\n",
      "Epoch 61/150\n",
      "156/156 [==============================] - 0s 377us/step - loss: 0.3514 - acc: 0.8397\n",
      "Epoch 62/150\n",
      "156/156 [==============================] - 0s 354us/step - loss: 0.3530 - acc: 0.8397\n",
      "Epoch 63/150\n",
      "156/156 [==============================] - 0s 356us/step - loss: 0.3487 - acc: 0.8462\n",
      "Epoch 64/150\n",
      "156/156 [==============================] - 0s 354us/step - loss: 0.3446 - acc: 0.8462\n",
      "Epoch 65/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.3461 - acc: 0.8397\n",
      "Epoch 66/150\n",
      "156/156 [==============================] - 0s 375us/step - loss: 0.3466 - acc: 0.8397\n",
      "Epoch 67/150\n",
      "156/156 [==============================] - 0s 362us/step - loss: 0.3406 - acc: 0.8333\n",
      "Epoch 68/150\n",
      "156/156 [==============================] - 0s 400us/step - loss: 0.3391 - acc: 0.8397\n",
      "Epoch 69/150\n",
      "156/156 [==============================] - 0s 401us/step - loss: 0.3390 - acc: 0.8526\n",
      "Epoch 70/150\n",
      "156/156 [==============================] - 0s 353us/step - loss: 0.3415 - acc: 0.8462\n",
      "Epoch 71/150\n",
      "156/156 [==============================] - 0s 364us/step - loss: 0.3354 - acc: 0.8462\n",
      "Epoch 72/150\n",
      "156/156 [==============================] - 0s 341us/step - loss: 0.3364 - acc: 0.8397\n",
      "Epoch 73/150\n",
      "156/156 [==============================] - 0s 340us/step - loss: 0.3316 - acc: 0.8462\n",
      "Epoch 74/150\n",
      "156/156 [==============================] - 0s 333us/step - loss: 0.3352 - acc: 0.8526\n",
      "Epoch 75/150\n",
      "156/156 [==============================] - 0s 352us/step - loss: 0.3349 - acc: 0.8718\n",
      "Epoch 76/150\n",
      "156/156 [==============================] - 0s 343us/step - loss: 0.3331 - acc: 0.8526\n",
      "Epoch 77/150\n",
      "156/156 [==============================] - 0s 334us/step - loss: 0.3375 - acc: 0.8654\n",
      "Epoch 78/150\n",
      "156/156 [==============================] - 0s 332us/step - loss: 0.3228 - acc: 0.8526\n",
      "Epoch 79/150\n",
      "156/156 [==============================] - 0s 356us/step - loss: 0.3236 - acc: 0.8654\n",
      "Epoch 80/150\n",
      "156/156 [==============================] - 0s 320us/step - loss: 0.3173 - acc: 0.8654\n",
      "Epoch 81/150\n",
      "156/156 [==============================] - 0s 338us/step - loss: 0.3239 - acc: 0.8462\n",
      "Epoch 82/150\n",
      "156/156 [==============================] - 0s 341us/step - loss: 0.3209 - acc: 0.8526\n",
      "Epoch 83/150\n",
      "156/156 [==============================] - 0s 351us/step - loss: 0.3230 - acc: 0.8910\n",
      "Epoch 84/150\n",
      "156/156 [==============================] - 0s 334us/step - loss: 0.3157 - acc: 0.8654\n",
      "Epoch 85/150\n",
      "156/156 [==============================] - 0s 339us/step - loss: 0.3154 - acc: 0.8590\n",
      "Epoch 86/150\n",
      "156/156 [==============================] - 0s 322us/step - loss: 0.3166 - acc: 0.8462\n",
      "Epoch 87/150\n",
      "156/156 [==============================] - 0s 336us/step - loss: 0.3106 - acc: 0.8718\n",
      "Epoch 88/150\n",
      "156/156 [==============================] - 0s 339us/step - loss: 0.3116 - acc: 0.8654\n",
      "Epoch 89/150\n",
      "156/156 [==============================] - 0s 358us/step - loss: 0.3074 - acc: 0.8654\n",
      "Epoch 90/150\n",
      "156/156 [==============================] - 0s 339us/step - loss: 0.3143 - acc: 0.8590\n",
      "Epoch 91/150\n",
      "156/156 [==============================] - 0s 325us/step - loss: 0.3167 - acc: 0.8526\n",
      "Epoch 92/150\n",
      "156/156 [==============================] - 0s 338us/step - loss: 0.3056 - acc: 0.8590\n",
      "Epoch 93/150\n",
      "156/156 [==============================] - 0s 333us/step - loss: 0.3038 - acc: 0.8590\n",
      "Epoch 94/150\n",
      "156/156 [==============================] - 0s 337us/step - loss: 0.3044 - acc: 0.8654\n",
      "Epoch 95/150\n",
      "156/156 [==============================] - 0s 346us/step - loss: 0.3025 - acc: 0.8654\n",
      "Epoch 96/150\n",
      "156/156 [==============================] - 0s 355us/step - loss: 0.3003 - acc: 0.8718\n",
      "Epoch 97/150\n",
      "156/156 [==============================] - 0s 369us/step - loss: 0.2975 - acc: 0.8654\n",
      "Epoch 98/150\n",
      "156/156 [==============================] - 0s 364us/step - loss: 0.2967 - acc: 0.8782\n",
      "Epoch 99/150\n",
      "156/156 [==============================] - 0s 368us/step - loss: 0.2975 - acc: 0.8718\n",
      "Epoch 100/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.2978 - acc: 0.8590\n",
      "Epoch 101/150\n",
      "156/156 [==============================] - 0s 356us/step - loss: 0.2970 - acc: 0.8654\n",
      "Epoch 102/150\n",
      "156/156 [==============================] - 0s 359us/step - loss: 0.2878 - acc: 0.8526\n",
      "Epoch 103/150\n",
      "156/156 [==============================] - 0s 361us/step - loss: 0.2988 - acc: 0.8718\n",
      "Epoch 104/150\n",
      "156/156 [==============================] - 0s 403us/step - loss: 0.2932 - acc: 0.8782\n",
      "Epoch 105/150\n",
      "156/156 [==============================] - 0s 350us/step - loss: 0.2860 - acc: 0.8718\n",
      "Epoch 106/150\n",
      "156/156 [==============================] - 0s 358us/step - loss: 0.2960 - acc: 0.8654\n",
      "Epoch 107/150\n",
      "156/156 [==============================] - 0s 340us/step - loss: 0.2888 - acc: 0.8782\n",
      "Epoch 108/150\n",
      "156/156 [==============================] - 0s 355us/step - loss: 0.2843 - acc: 0.8718\n",
      "Epoch 109/150\n",
      "156/156 [==============================] - 0s 359us/step - loss: 0.2885 - acc: 0.8846\n",
      "Epoch 110/150\n",
      "156/156 [==============================] - 0s 354us/step - loss: 0.2842 - acc: 0.8718\n",
      "Epoch 111/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.2845 - acc: 0.8910\n",
      "Epoch 112/150\n",
      "156/156 [==============================] - 0s 354us/step - loss: 0.2796 - acc: 0.8782\n",
      "Epoch 113/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.2759 - acc: 0.8782\n",
      "Epoch 114/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.2800 - acc: 0.8654\n",
      "Epoch 115/150\n",
      "156/156 [==============================] - 0s 351us/step - loss: 0.2814 - acc: 0.8654\n",
      "Epoch 116/150\n",
      "156/156 [==============================] - 0s 355us/step - loss: 0.2711 - acc: 0.8782\n",
      "Epoch 117/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.2770 - acc: 0.8846\n",
      "Epoch 118/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.2732 - acc: 0.8846\n",
      "Epoch 119/150\n",
      "156/156 [==============================] - 0s 346us/step - loss: 0.2689 - acc: 0.8846\n",
      "Epoch 120/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.2732 - acc: 0.8974\n",
      "Epoch 121/150\n",
      "156/156 [==============================] - 0s 347us/step - loss: 0.2734 - acc: 0.8910\n",
      "Epoch 122/150\n",
      "156/156 [==============================] - 0s 372us/step - loss: 0.2692 - acc: 0.8718\n",
      "Epoch 123/150\n",
      "156/156 [==============================] - 0s 347us/step - loss: 0.2695 - acc: 0.8910\n",
      "Epoch 124/150\n",
      "156/156 [==============================] - 0s 350us/step - loss: 0.2628 - acc: 0.8910\n",
      "Epoch 125/150\n",
      "156/156 [==============================] - 0s 399us/step - loss: 0.2614 - acc: 0.8910\n",
      "Epoch 126/150\n",
      "156/156 [==============================] - 0s 350us/step - loss: 0.2617 - acc: 0.9038\n",
      "Epoch 127/150\n",
      "156/156 [==============================] - 0s 349us/step - loss: 0.2690 - acc: 0.8782\n",
      "Epoch 128/150\n",
      "156/156 [==============================] - 0s 357us/step - loss: 0.2566 - acc: 0.8974\n",
      "Epoch 129/150\n",
      "156/156 [==============================] - 0s 355us/step - loss: 0.2621 - acc: 0.8910\n",
      "Epoch 130/150\n",
      "156/156 [==============================] - 0s 344us/step - loss: 0.2558 - acc: 0.9038\n",
      "Epoch 131/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.2618 - acc: 0.8910\n",
      "Epoch 132/150\n",
      "156/156 [==============================] - 0s 360us/step - loss: 0.2567 - acc: 0.8910\n",
      "Epoch 133/150\n",
      "156/156 [==============================] - 0s 351us/step - loss: 0.2521 - acc: 0.8974\n",
      "Epoch 134/150\n",
      "156/156 [==============================] - 0s 344us/step - loss: 0.2512 - acc: 0.9038\n",
      "Epoch 135/150\n",
      "156/156 [==============================] - 0s 359us/step - loss: 0.2569 - acc: 0.8910\n",
      "Epoch 136/150\n",
      "156/156 [==============================] - 0s 363us/step - loss: 0.2561 - acc: 0.8974\n",
      "Epoch 137/150\n",
      "156/156 [==============================] - 0s 359us/step - loss: 0.2472 - acc: 0.9038\n",
      "Epoch 138/150\n",
      "156/156 [==============================] - 0s 408us/step - loss: 0.2434 - acc: 0.9038\n",
      "Epoch 139/150\n",
      "156/156 [==============================] - 0s 399us/step - loss: 0.2468 - acc: 0.8974\n",
      "Epoch 140/150\n",
      "156/156 [==============================] - 0s 374us/step - loss: 0.2482 - acc: 0.8910\n",
      "Epoch 141/150\n",
      "156/156 [==============================] - 0s 339us/step - loss: 0.2471 - acc: 0.9038\n",
      "Epoch 142/150\n",
      "156/156 [==============================] - 0s 348us/step - loss: 0.2417 - acc: 0.8910\n",
      "Epoch 143/150\n",
      "156/156 [==============================] - 0s 343us/step - loss: 0.2567 - acc: 0.8846\n",
      "Epoch 144/150\n",
      "156/156 [==============================] - 0s 336us/step - loss: 0.2416 - acc: 0.9103\n",
      "Epoch 145/150\n",
      "156/156 [==============================] - 0s 330us/step - loss: 0.2454 - acc: 0.8846\n",
      "Epoch 146/150\n",
      "156/156 [==============================] - 0s 321us/step - loss: 0.2524 - acc: 0.8782\n",
      "Epoch 147/150\n",
      "156/156 [==============================] - 0s 330us/step - loss: 0.2437 - acc: 0.9038\n",
      "Epoch 148/150\n",
      "156/156 [==============================] - 0s 356us/step - loss: 0.2384 - acc: 0.9038\n",
      "Epoch 149/150\n",
      "156/156 [==============================] - 0s 347us/step - loss: 0.2421 - acc: 0.8974\n",
      "Epoch 150/150\n",
      "156/156 [==============================] - 0s 325us/step - loss: 0.2327 - acc: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2537e75048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final model for evaluating the test dataset\n",
    "final_model = create_grid_model(best_optimizer, best_kernel_init)\n",
    "final_model.fit(X_train, y_train, epochs=best_epochs, batch_size=best_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 3,721\n",
      "Trainable params: 3,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the final model\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "-H_7ah8gPRmw",
    "outputId": "52212ba7-304e-46ac-e6de-a30afa3dc6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 11ms/step\n",
      "\n",
      "acc: 82.69%\n",
      "\n",
      "loss: 40.65%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Keras model on previously unseen data\n",
    "scores = final_model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (final_model.metrics_names[0], scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0r4rJRXHTBTv"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 4 Optimize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohwYIizSIfPG"
   },
   "source": [
    "# Section 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh14j7v8TFPe"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "oUhkDCG8AkUC",
    "outputId": "fb87e85d-6fee-4a5b-9b5f-c2a9fe91099e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0365, 0.1632, 0.1636, 0.1421, 0.113, 0.1306, 0.2112, 0.2268, 0.2992, 0.3735, 0.3042, 0.0387, 0.2679, 0.5397, 0.6204, 0.7257, 0.835, 0.6888, 0.445, 0.3921, 0.5605, 0.7545, 0.8311, 1.0, 0.8762, 0.7092, 0.7009, 0.5014, 0.3942, 0.4456, 0.4072, 0.0773, 0.1423, 0.0401, 0.3597, 0.6847, 0.7076, 0.3597, 0.0612, 0.3027, 0.3966, 0.3868, 0.238, 0.2059, 0.2288, 0.1704, 0.1587, 0.1792, 0.1022, 0.0151, 0.0223, 0.011, 0.0071, 0.0205, 0.0164, 0.0063, 0.0078, 0.0094, 0.011, 0.0068] => 1 (expected 1)\n",
      "[0.0099, 0.0484, 0.0299, 0.0297, 0.0652, 0.1077, 0.2363, 0.2385, 0.0075, 0.1882, 0.1456, 0.1892, 0.3176, 0.134, 0.2169, 0.2458, 0.2589, 0.2786, 0.2298, 0.0656, 0.1441, 0.1179, 0.1668, 0.1783, 0.2476, 0.257, 0.1036, 0.5356, 0.7124, 0.6291, 0.4756, 0.6015, 0.7208, 0.6234, 0.5725, 0.7523, 0.8712, 0.9252, 0.9709, 0.9297, 0.8995, 0.7911, 0.56, 0.2838, 0.4407, 0.5507, 0.4331, 0.2905, 0.1981, 0.0779, 0.0396, 0.0173, 0.0149, 0.0115, 0.0202, 0.0139, 0.0029, 0.016, 0.0106, 0.0134] => 0 (expected 1)\n",
      "[0.0308, 0.0339, 0.0202, 0.0889, 0.157, 0.175, 0.092, 0.1353, 0.1593, 0.2795, 0.3336, 0.294, 0.1608, 0.3335, 0.4985, 0.7295, 0.735, 0.8253, 0.8793, 0.9657, 1.0, 0.8707, 0.6471, 0.5973, 0.8218, 0.7755, 0.6111, 0.4195, 0.299, 0.1354, 0.2438, 0.5624, 0.5555, 0.6963, 0.7298, 0.7022, 0.5468, 0.1421, 0.4738, 0.641, 0.4375, 0.3178, 0.2377, 0.2808, 0.1374, 0.1136, 0.1034, 0.0688, 0.0422, 0.0117, 0.007, 0.0167, 0.0127, 0.0138, 0.009, 0.0051, 0.0029, 0.0122, 0.0056, 0.002] => 1 (expected 1)\n",
      "[0.013, 0.0006, 0.0088, 0.0456, 0.0525, 0.0778, 0.0931, 0.0941, 0.1711, 0.1483, 0.1532, 0.11, 0.089, 0.1236, 0.1197, 0.1145, 0.2137, 0.2838, 0.364, 0.543, 0.6673, 0.7979, 0.9273, 0.9027, 0.9192, 1.0, 0.9821, 0.9092, 0.8184, 0.6962, 0.59, 0.5447, 0.5142, 0.5389, 0.5531, 0.5318, 0.4826, 0.379, 0.1831, 0.175, 0.1679, 0.0674, 0.0609, 0.0375, 0.0533, 0.0278, 0.0179, 0.0114, 0.0073, 0.0116, 0.0092, 0.0078, 0.0041, 0.0013, 0.0011, 0.0045, 0.0039, 0.0022, 0.0023, 0.0016] => 1 (expected 1)\n",
      "[0.0664, 0.0575, 0.0842, 0.0372, 0.0458, 0.0771, 0.0771, 0.113, 0.2353, 0.1838, 0.2869, 0.4129, 0.3647, 0.1984, 0.284, 0.4039, 0.5837, 0.6792, 0.6086, 0.4858, 0.3246, 0.2013, 0.2082, 0.1686, 0.2484, 0.2736, 0.2984, 0.4655, 0.699, 0.7474, 0.7956, 0.7981, 0.6715, 0.6942, 0.744, 0.8169, 0.8912, 1.0, 0.8753, 0.7061, 0.6803, 0.5898, 0.4618, 0.3639, 0.1492, 0.1216, 0.1306, 0.1198, 0.0578, 0.0235, 0.0135, 0.0141, 0.019, 0.0043, 0.0036, 0.0026, 0.0024, 0.0162, 0.0109, 0.0079] => 1 (expected 1)\n",
      "[0.031, 0.0221, 0.0433, 0.0191, 0.0964, 0.1827, 0.1106, 0.1702, 0.2804, 0.4432, 0.5222, 0.5611, 0.5379, 0.4048, 0.2245, 0.1784, 0.2297, 0.272, 0.5209, 0.6898, 0.8202, 0.878, 0.76, 0.7616, 0.7152, 0.7288, 0.8686, 0.9509, 0.8348, 0.573, 0.4363, 0.4289, 0.424, 0.3156, 0.1287, 0.1477, 0.2062, 0.24, 0.5173, 0.5168, 0.1491, 0.2407, 0.3415, 0.4494, 0.4624, 0.2001, 0.0775, 0.1232, 0.0783, 0.0089, 0.0249, 0.0204, 0.0059, 0.0053, 0.0079, 0.0037, 0.0015, 0.0056, 0.0067, 0.0054] => 0 (expected 0)\n",
      "[0.0329, 0.0216, 0.0386, 0.0627, 0.1158, 0.1482, 0.2054, 0.1605, 0.2532, 0.2672, 0.3056, 0.3161, 0.2314, 0.2067, 0.1804, 0.2808, 0.4423, 0.5947, 0.6601, 0.5844, 0.4539, 0.4789, 0.5646, 0.5281, 0.7115, 1.0, 0.9564, 0.609, 0.5112, 0.4, 0.0482, 0.1852, 0.2186, 0.1436, 0.1757, 0.1428, 0.1644, 0.3089, 0.3648, 0.4441, 0.3859, 0.2813, 0.1238, 0.0953, 0.1201, 0.0825, 0.0618, 0.0141, 0.0108, 0.0124, 0.0104, 0.0095, 0.0151, 0.0059, 0.0015, 0.0053, 0.0016, 0.0042, 0.0053, 0.0074] => 0 (expected 0)\n",
      "[0.0211, 0.0319, 0.0415, 0.0286, 0.0121, 0.0438, 0.1299, 0.139, 0.0695, 0.0568, 0.0869, 0.1935, 0.1478, 0.1871, 0.1994, 0.3283, 0.6861, 0.5814, 0.25, 0.1734, 0.3363, 0.5588, 0.6592, 0.7012, 0.8099, 0.8901, 0.8745, 0.7887, 0.8725, 0.9376, 0.892, 0.7508, 0.6832, 0.761, 0.9017, 1.0, 0.9123, 0.7388, 0.5915, 0.4057, 0.3019, 0.2331, 0.2931, 0.2298, 0.2391, 0.191, 0.1096, 0.03, 0.0171, 0.0383, 0.0053, 0.009, 0.0042, 0.0153, 0.0106, 0.002, 0.0105, 0.0049, 0.007, 0.008] => 1 (expected 1)\n",
      "[0.026, 0.0192, 0.0254, 0.0061, 0.0352, 0.0701, 0.1263, 0.108, 0.1523, 0.163, 0.103, 0.2187, 0.1542, 0.263, 0.294, 0.2978, 0.0699, 0.1401, 0.299, 0.3915, 0.3598, 0.2403, 0.4208, 0.5675, 0.6094, 0.6323, 0.6549, 0.7673, 1.0, 0.8463, 0.5509, 0.4444, 0.5169, 0.4268, 0.1802, 0.0791, 0.0535, 0.1906, 0.2561, 0.2153, 0.2769, 0.2841, 0.1733, 0.0815, 0.0335, 0.0933, 0.1018, 0.0309, 0.0208, 0.0318, 0.0132, 0.0118, 0.012, 0.0051, 0.007, 0.0015, 0.0035, 0.0008, 0.0044, 0.0077] => 1 (expected 1)\n",
      "[0.1313, 0.2339, 0.3059, 0.4264, 0.401, 0.1791, 0.1853, 0.0055, 0.1929, 0.2231, 0.2907, 0.2259, 0.3136, 0.3302, 0.366, 0.3956, 0.4386, 0.467, 0.5255, 0.3735, 0.2243, 0.1973, 0.4337, 0.6532, 0.507, 0.2796, 0.4163, 0.595, 0.5242, 0.4178, 0.3714, 0.2375, 0.0863, 0.1437, 0.2896, 0.4577, 0.3725, 0.3372, 0.3803, 0.4181, 0.3603, 0.2711, 0.1653, 0.1951, 0.2811, 0.2246, 0.1921, 0.15, 0.0665, 0.0193, 0.0156, 0.0362, 0.021, 0.0154, 0.018, 0.0013, 0.0106, 0.0127, 0.0178, 0.0231] => 0 (expected 0)\n",
      "[0.0261, 0.0266, 0.0223, 0.0749, 0.1364, 0.1513, 0.1316, 0.1654, 0.1864, 0.2013, 0.289, 0.365, 0.351, 0.3495, 0.4325, 0.5398, 0.6237, 0.6876, 0.7329, 0.8107, 0.8396, 0.8632, 0.8747, 0.9607, 0.9716, 0.9121, 0.8576, 0.8798, 0.772, 0.5711, 0.4264, 0.286, 0.3114, 0.2066, 0.1165, 0.0185, 0.1302, 0.248, 0.1637, 0.1103, 0.2144, 0.2033, 0.1887, 0.137, 0.1376, 0.0307, 0.0373, 0.0606, 0.0399, 0.0169, 0.0135, 0.0222, 0.0175, 0.0127, 0.0022, 0.0124, 0.0054, 0.0021, 0.0028, 0.0023] => 0 (expected 0)\n",
      "[0.0262, 0.0582, 0.1099, 0.1083, 0.0974, 0.228, 0.2431, 0.3771, 0.5598, 0.6194, 0.6333, 0.706, 0.5544, 0.532, 0.6479, 0.6931, 0.6759, 0.7551, 0.8929, 0.8619, 0.7974, 0.6737, 0.4293, 0.3648, 0.5331, 0.2413, 0.507, 0.8533, 0.6036, 0.8514, 0.8512, 0.5045, 0.1862, 0.2709, 0.4232, 0.3043, 0.6116, 0.6756, 0.5375, 0.4719, 0.4647, 0.2587, 0.2129, 0.2222, 0.2111, 0.0176, 0.1348, 0.0744, 0.013, 0.0106, 0.0033, 0.0232, 0.0166, 0.0095, 0.018, 0.0244, 0.0316, 0.0164, 0.0095, 0.0078] => 0 (expected 1)\n",
      "[0.0197, 0.0394, 0.0384, 0.0076, 0.0251, 0.0629, 0.0747, 0.0578, 0.1357, 0.1695, 0.1734, 0.247, 0.3141, 0.3297, 0.2759, 0.2056, 0.1162, 0.1884, 0.339, 0.3926, 0.4282, 0.5418, 0.6448, 0.7223, 0.7853, 0.7984, 0.8847, 0.9582, 0.899, 0.6831, 0.6108, 0.548, 0.5058, 0.4476, 0.2401, 0.1405, 0.1772, 0.1742, 0.3326, 0.4021, 0.3009, 0.2075, 0.1206, 0.0255, 0.0298, 0.0691, 0.0781, 0.0777, 0.0369, 0.0057, 0.0091, 0.0134, 0.0097, 0.0042, 0.0058, 0.0072, 0.0041, 0.0045, 0.0047, 0.0054] => 1 (expected 0)\n",
      "[0.0368, 0.0279, 0.0103, 0.0566, 0.0759, 0.0679, 0.097, 0.1473, 0.2164, 0.2544, 0.2936, 0.2935, 0.2657, 0.3187, 0.2794, 0.2534, 0.198, 0.1929, 0.2826, 0.3245, 0.3504, 0.3324, 0.4217, 0.4774, 0.4808, 0.6325, 0.8334, 0.9458, 1.0, 0.8425, 0.5524, 0.4795, 0.52, 0.3968, 0.194, 0.1519, 0.201, 0.1736, 0.1029, 0.2244, 0.3717, 0.4449, 0.3939, 0.203, 0.201, 0.2187, 0.184, 0.1477, 0.0971, 0.0224, 0.0151, 0.0105, 0.0024, 0.0018, 0.0057, 0.0092, 0.0009, 0.0086, 0.011, 0.0052] => 0 (expected 0)\n",
      "[0.0231, 0.0315, 0.017, 0.0226, 0.041, 0.0116, 0.0223, 0.0805, 0.2365, 0.2461, 0.2245, 0.152, 0.1732, 0.3099, 0.438, 0.5595, 0.682, 0.6164, 0.6803, 0.8435, 0.9921, 1.0, 0.7983, 0.5426, 0.3952, 0.5179, 0.565, 0.3042, 0.1881, 0.396, 0.2286, 0.3544, 0.4187, 0.2398, 0.1847, 0.376, 0.4331, 0.3626, 0.2519, 0.187, 0.1046, 0.2339, 0.1991, 0.11, 0.0684, 0.0303, 0.0674, 0.0785, 0.0455, 0.0246, 0.0151, 0.0125, 0.0036, 0.0123, 0.0043, 0.0114, 0.0052, 0.0091, 0.0008, 0.0092] => 0 (expected 0)\n",
      "[0.0335, 0.0258, 0.0398, 0.057, 0.0529, 0.1091, 0.1709, 0.1684, 0.1865, 0.266, 0.3188, 0.3553, 0.3116, 0.1965, 0.178, 0.2794, 0.287, 0.3969, 0.5599, 0.6936, 0.7969, 0.7452, 0.8203, 0.9261, 0.881, 0.8814, 0.9301, 0.9955, 0.8576, 0.6069, 0.3934, 0.2464, 0.1645, 0.114, 0.0956, 0.008, 0.0702, 0.0936, 0.0894, 0.1127, 0.0873, 0.102, 0.1964, 0.2256, 0.1814, 0.2012, 0.1688, 0.1037, 0.0501, 0.0136, 0.013, 0.012, 0.0039, 0.0053, 0.0062, 0.0046, 0.0045, 0.0022, 0.0005, 0.0031] => 0 (expected 0)\n",
      "[0.0235, 0.022, 0.0167, 0.0516, 0.0746, 0.1121, 0.1258, 0.1717, 0.3074, 0.3199, 0.2946, 0.2484, 0.251, 0.1806, 0.1413, 0.3019, 0.3635, 0.3887, 0.298, 0.2219, 0.1624, 0.1343, 0.2046, 0.3791, 0.5771, 0.7545, 0.8406, 0.8547, 0.9036, 1.0, 0.9646, 0.7912, 0.6412, 0.5986, 0.6835, 0.7771, 0.8084, 0.7426, 0.6295, 0.5708, 0.4433, 0.3361, 0.3795, 0.495, 0.4373, 0.2404, 0.1128, 0.1654, 0.0933, 0.0225, 0.0214, 0.0221, 0.0152, 0.0083, 0.0058, 0.0023, 0.0057, 0.0052, 0.0027, 0.0021] => 1 (expected 0)\n",
      "[0.027, 0.0163, 0.0341, 0.0247, 0.0822, 0.1256, 0.1323, 0.1584, 0.2017, 0.2122, 0.221, 0.2399, 0.2964, 0.4061, 0.5095, 0.5512, 0.6613, 0.6804, 0.652, 0.6788, 0.7811, 0.8369, 0.8969, 0.9856, 1.0, 0.9395, 0.8917, 0.8105, 0.6828, 0.5572, 0.4301, 0.3339, 0.2035, 0.0798, 0.0809, 0.1525, 0.2626, 0.2456, 0.198, 0.2412, 0.2409, 0.1901, 0.2077, 0.1767, 0.1119, 0.0779, 0.1344, 0.096, 0.0598, 0.033, 0.0197, 0.0189, 0.0204, 0.0085, 0.0043, 0.0092, 0.0138, 0.0094, 0.0105, 0.0093] => 0 (expected 0)\n",
      "[0.0408, 0.0653, 0.0397, 0.0604, 0.0496, 0.1817, 0.1178, 0.1024, 0.0583, 0.2176, 0.2459, 0.3332, 0.3087, 0.2613, 0.3232, 0.3731, 0.4203, 0.5364, 0.7062, 0.8196, 0.8835, 0.8299, 0.7609, 0.7605, 0.8367, 0.8905, 0.7652, 0.5897, 0.3037, 0.0823, 0.2787, 0.7241, 0.8032, 0.805, 0.7676, 0.7468, 0.6253, 0.173, 0.2916, 0.5003, 0.522, 0.4824, 0.4004, 0.3877, 0.1651, 0.0442, 0.0663, 0.0418, 0.0475, 0.0235, 0.0066, 0.0062, 0.0129, 0.0184, 0.0069, 0.0198, 0.0199, 0.0102, 0.007, 0.0055] => 1 (expected 1)\n",
      "[0.0221, 0.0065, 0.0164, 0.0487, 0.0519, 0.0849, 0.0812, 0.1833, 0.2228, 0.181, 0.2549, 0.2984, 0.2624, 0.1893, 0.0668, 0.2666, 0.4274, 0.6291, 0.7782, 0.7686, 0.8099, 0.8493, 0.944, 0.945, 0.9655, 0.8045, 0.4969, 0.396, 0.3856, 0.5574, 0.7309, 0.8549, 0.9425, 0.8726, 0.6673, 0.4694, 0.1546, 0.1748, 0.3607, 0.5208, 0.5177, 0.3702, 0.224, 0.0816, 0.0395, 0.0785, 0.1052, 0.1034, 0.0764, 0.0216, 0.0167, 0.0089, 0.0051, 0.0015, 0.0075, 0.0058, 0.0016, 0.007, 0.0074, 0.0038] => 1 (expected 0)\n"
     ]
    }
   ],
   "source": [
    "# Make class predictions with the model\n",
    "predictions = final_model.predict_classes(X_test)\n",
    "\n",
    "# Summarize the first 20 cases\n",
    "for i in range(20):\n",
    "\tprint('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkgS_dVLTIIi"
   },
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Phase 5 Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Qb7Ry_60TMOl",
    "outputId": "08177fca-8793-418e-a88c-131f35590eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:22:49.205085\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "py-keras-classification-binary-class-example.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
